{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da5064c9ed8cd1fec0f36b714c345b0b",
     "grade": false,
     "grade_id": "cell-4d87ae78fb4caf9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# NLP and the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1145e2ba69b3e56620106550f0984e0",
     "grade": false,
     "grade_id": "cell-8b531762670192f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 0 ~ 0P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "__Task 0 is only relevant for the homework.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d4cef5c9a404a5516183e6ce9bf2128",
     "grade": false,
     "grade_id": "cell-6eca7b6c6c224dde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### a) Please enter your group number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75470a4986487fdb40d73fa368335c95",
     "grade": true,
     "grade_id": "cell-cccfbf605a28a18a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6fdb993af1b0b63ec0df26dca558cdd0",
     "grade": false,
     "grade_id": "cell-2ed8ca1b9e5204c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "_**Regarding types, documentation, and output:**_\n",
    "\n",
    "_We tried to make the description of the parameters as clear as possible. However, if you believe that something is missing, please reach out to us in Moodle. We provide type hints for the function parameters and return values of the functions that you have to implement._\n",
    "\n",
    "_Nevertheless, your code must use the provided method stubs and parameters. Furthermore, make sure that your code runs without errors and in a reasonable amount of time, for example by using \"Kernel/Restart & Run All\" before submitting._\n",
    "\n",
    "_Please use comments where appropriate to help the tutors understand your code. This is especially important for the more extensive exercises later on. Finally, please pay attention to how you output the results. We highly recommend using `display(df)` for displaying data frames._\n",
    "\n",
    "_**Please only modify the template in the specified markdown and code cells (e.g. YOUR CODE / ANSWER / IMPORTS HERE). Some cells are left blank on purpose. Please do not modify these cells, because they are used to autograde your submission. If these cells are modified, the automatic grading for your submission will fail and we might deduct points. Please do not modify the cells containing public and private tests. If you want to do your own tests, please use the code cell containing your code solution (YOUR CODE HERE).**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e8b001f775d19d5ae16b9a2db7de0b3",
     "grade": false,
     "grade_id": "cell-7183bbd6b3d256ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Home Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d868fe53564e802562225f3496878bba",
     "grade": false,
     "grade_id": "cell-599ef02f29d86cb6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Mapping\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from typing import Tuple, List\n",
    "import collections\n",
    "import random\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21cf8cdf1d35ec905f08813a91fcf827",
     "grade": false,
     "grade_id": "cell-01a6e6d0c61ed8c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 1: PageRank Algorithm (12 Points)\n",
    "\n",
    "In this task, you will implement and execute the [PageRank algorithm](https://en.wikipedia.org/wiki/PageRank)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1aa081507853301e476becffb2dd3b0d",
     "grade": false,
     "grade_id": "cell-ec0b1fc2104308bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "__About the data__:\n",
    "\n",
    "The data for this task is stored in `page_links.csv` and comprises links between 15 webpages (with ids from 0 to 14).,Each row represents a link from the webpage with the id in the `source` column to the webpage with the id in the `destination` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45d5e1ba1374c9f6a74be2fe4a586d2c",
     "grade": false,
     "grade_id": "cell-cec56e5579715270",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Computing the Matrices (5.5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f16888d8dd6806a8b03bf60864dc895",
     "grade": false,
     "grade_id": "cell-6ae39fb4261c4ee2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23 5.68 0.0 \n",
      "1.0  2.0  3.0 \n",
      "2.22 3.33 4.44\n"
     ]
    }
   ],
   "source": [
    "# Whenever you are asked to output a matrix, use this function.\n",
    "def print_matrix(matrix: np.ndarray, leave_out_zeros: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Print the given matrix.\n",
    "    \n",
    "    :param matrix: matrix to print\n",
    "    :param leave_out_zeros: whether to leave out zeros\n",
    "    \"\"\"\n",
    "    \n",
    "    def stringify_number(num: float) -> str:\n",
    "        rounded_num: float = round(num, 2)\n",
    "        if leave_out_zeros and rounded_num == 0:\n",
    "            return \" \"\n",
    "        else:\n",
    "            return str(rounded_num)\n",
    "    \n",
    "    string_values: list = [[stringify_number(e) for e in row] for row in matrix]\n",
    "    lens: list = [max(map(len, col)) for col in zip(*string_values)]\n",
    "    fmt: str = \" \".join(\"{{:{}}}\".format(x) for x in lens)\n",
    "    print(\"\\n\".join([fmt.format(*row) for row in string_values]))\n",
    "\n",
    "matrix = np.array([[1.234, 5.678, 0.0], [1,2,3], [2.222, 3.333, 4.444]])\n",
    "print_matrix(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c278f1d08d7f841af967560ae0147ba",
     "grade": false,
     "grade_id": "cell-01715738328e66d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "__a) Implement the function `compute_link_matrix(...)`, which computes the link matrix $m$. The value of $m_{i,j}=0$ if no link from $i$ to $j$ exists and $m_{i,j}=1$ if such a link exists. Load the data and execute the function on it. Display the resulting link matrix using `print_matrix(...)`.__\n",
    "\n",
    "The data is in the following format:\n",
    "Each row contains two integer: the source and destination of a link.\n",
    "\n",
    "__Hint:__ You can assume that the webpage ids range from 0 to `num_pages` - 1. (1P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31d758d3d7d4e6159cce5669aa45c7d5",
     "grade": true,
     "grade_id": "cell-3a4cb788cec4ea3e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0 1.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0\n",
      "0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0\n",
      "0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0\n",
      "0.0 1.0 1.0 1.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "0.0 0.0 0.0 1.0 1.0 0.0 1.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0\n",
      "0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "0.0 1.0 1.0 1.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "0.0 0.0 1.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0\n",
      "0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0\n",
      "0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 1.0 0.0 0.0 1.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "def compute_link_matrix(data: pd.DataFrame, num_pages: int = 15) -> npt.NDArray[np.int64]:\n",
    "    \"\"\"\n",
    "    Compute the link matrix.\n",
    "    \n",
    "    :param data: links loaded from the dataset\n",
    "    :param num_pages: number of webpages\n",
    "    :return: link_matrix\n",
    "    \"\"\"\n",
    "    matrix: npt.NDArray = np.array([1])\n",
    "    \n",
    "    # Create matrix with 0s with the size of m x m where m is the size of data\n",
    "    matrix = np.zeros((num_pages, num_pages))\n",
    "    # Run lambda function for each row in data\n",
    "    data.apply(lambda row: matrix.__setitem__((row['source'], row['destination']), 1), axis=1)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "data = pd.read_csv(\"page_links.csv\")\n",
    "link_matrix = compute_link_matrix(data)\n",
    "print_matrix(link_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5847c25fccb62bcb0102e4a6c0b85350",
     "grade": false,
     "grade_id": "cell-565808efd6ef69e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0 0.0 0.0 1.0 1.0\n",
      "0.0 0.0 1.0 0.0 1.0 1.0 1.0\n",
      "0.0 1.0 0.0 1.0 0.0 0.0 0.0\n",
      "0.0 1.0 0.0 0.0 1.0 0.0 0.0\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# This is for you to check if your function works properly\n",
    "test_data = pd.DataFrame(\n",
    "    {\n",
    "        \"source\":       [0,0,1,2,3,1,1,1,2,3],\n",
    "        \"destination\":  [5,6,5,3,4,4,2,6,1,1],\n",
    "    }\n",
    ")\n",
    "\n",
    "test_link_matrix = compute_link_matrix(data=test_data, num_pages=7)\n",
    "print_matrix(test_link_matrix)\n",
    "\n",
    "# This is what is should look like\n",
    "true_lm = np.array([\n",
    " [0.,0.,0.,0.,0.,1.,1.],\n",
    " [0.,0.,1.,0.,1.,1.,1.],\n",
    " [0.,1.,0.,1.,0.,0.,0.],\n",
    " [0.,1.,0.,0.,1.,0.,0.],\n",
    " [0.,0.,0.,0.,0.,0.,0.],\n",
    " [0.,0.,0.,0.,0.,0.,0.],\n",
    " [0.,0.,0.,0.,0.,0.,0.]])\n",
    "\n",
    "# a test for you\n",
    "assert (test_link_matrix == true_lm).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1fbce58c7759c3a809dc6ef9926601f",
     "grade": true,
     "grade_id": "1a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hidden test cell, don’t modify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e74a5c2d5cd1cebd7c62a40c10cedf33",
     "grade": false,
     "grade_id": "cell-a7597e85c2d93cca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "__b) Implement the function `compute_link_probability_matrix(...)`, which computes the link probability matrix $p$ based on the link matrix $m$. Each $p_{i,j}$ should be the probability that a person reaches the webpage $j$ when clicking on a random link on webpage $i$ (see slide 45 of the lecture 08). Set $p_{i,j}=0$ if no link from $i$ to $j$ exists. Execute the function on the link matrix from 1a) and display the result using `print_matrix(...)`.__ (1.5P)\n",
    "\n",
    "__Hint:__ In case that there are no outgoing links, the probabilities for that webpage should all be $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c64172d0170798d7afc514829a7588c",
     "grade": true,
     "grade_id": "cell-30bb45f3c2dc745c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0  0.0  0.25 0.0 0.0  0.25 0.25 0.0  0.0  0.0 0.0  0.25 0.0  0.0 \n",
      "0.0 0.0  0.0  0.0  0.5 0.0  0.0  0.0  0.0  0.0  0.0 0.0  0.0  0.5  0.0 \n",
      "0.0 0.0  0.0  0.0  0.0 0.0  0.0  0.5  0.0  0.0  0.0 0.0  0.0  0.5  0.0 \n",
      "0.0 0.0  0.0  0.0  0.0 0.25 0.25 0.0  0.25 0.25 0.0 0.0  0.0  0.0  0.0 \n",
      "0.0 0.2  0.2  0.2  0.0 0.2  0.0  0.2  0.0  0.0  0.0 0.0  0.0  0.0  0.0 \n",
      "0.0 0.0  0.0  0.2  0.2 0.0  0.2  0.0  0.2  0.0  0.2 0.0  0.0  0.0  0.0 \n",
      "0.0 1.0  0.0  0.0  0.0 0.0  0.0  0.0  0.0  0.0  0.0 0.0  0.0  0.0  0.0 \n",
      "0.0 0.14 0.14 0.14 0.0 0.14 0.14 0.0  0.0  0.0  0.0 0.14 0.0  0.14 0.0 \n",
      "0.0 0.0  0.0  0.0  0.0 0.0  0.0  0.0  0.0  0.0  0.0 0.0  0.0  0.0  0.0 \n",
      "0.0 0.0  0.33 0.33 0.0 0.0  0.33 0.0  0.0  0.0  0.0 0.0  0.0  0.0  0.0 \n",
      "0.0 0.0  0.0  0.0  0.2 0.0  0.2  0.2  0.0  0.0  0.0 0.0  0.2  0.2  0.0 \n",
      "0.0 0.0  0.17 0.0  0.0 0.0  0.17 0.17 0.17 0.17 0.0 0.0  0.0  0.17 0.0 \n",
      "0.0 0.0  0.0  0.0  0.0 0.0  0.0  0.0  1.0  0.0  0.0 0.0  0.0  0.0  0.0 \n",
      "0.0 0.0  0.0  0.0  0.0 0.0  0.25 0.25 0.0  0.25 0.0 0.0  0.0  0.0  0.25\n",
      "0.0 0.0  0.0  0.0  0.0 0.25 0.0  0.0  0.25 0.25 0.0 0.0  0.25 0.0  0.0 \n"
     ]
    }
   ],
   "source": [
    "def compute_link_probability_matrix(link_matrix: np.ndarray) -> npt.NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Compute the link probability matrix.\n",
    "    \n",
    "    :param link_matrix: link matrix\n",
    "    :return: link probability matrix\n",
    "    \"\"\"\n",
    "    # Initialize link_propability_matrix with 0s with the size of m x m where m is the size of link_matrix\n",
    "    link_probability_matrix = np.zeros_like(link_matrix, dtype=np.float64)\n",
    "        \n",
    "    # Loop over all rows in link matrix. Set each entry with a link to 1 / number of links\n",
    "    for r_index, row in enumerate(link_matrix):\n",
    "        for c_index, element in enumerate(row):\n",
    "            if element == 1:\n",
    "                sumrow = sum(row)\n",
    "                prob = 1 / sumrow\n",
    "                link_probability_matrix[r_index][c_index] = prob\n",
    "    \n",
    "    return link_probability_matrix\n",
    "\n",
    "link_prob_matrix = compute_link_probability_matrix(link_matrix)\n",
    "print_matrix(link_prob_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa22ed37134c7ecf0edf68a270614cfe",
     "grade": false,
     "grade_id": "cell-788712e8f0a440f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0  0.0 0.0  0.5  0.5 \n",
      "0.0 0.0 0.25 0.0 0.25 0.25 0.25\n",
      "0.0 0.5 0.0  0.5 0.0  0.0  0.0 \n",
      "0.0 0.5 0.0  0.0 0.5  0.0  0.0 \n",
      "0.0 0.0 0.0  0.0 0.0  0.0  0.0 \n",
      "0.0 0.0 0.0  0.0 0.0  0.0  0.0 \n",
      "0.0 0.0 0.0  0.0 0.0  0.0  0.0 \n"
     ]
    }
   ],
   "source": [
    "# This is for you to check if your function works properly\n",
    "test_link_matrix = np.array([\n",
    " [0.,0.,0.,0.,0.,1.,1.],\n",
    " [0.,0.,1.,0.,1.,1.,1.],\n",
    " [0.,1.,0.,1.,0.,0.,0.],\n",
    " [0.,1.,0.,0.,1.,0.,0.],\n",
    " [0.,0.,0.,0.,0.,0.,0.],\n",
    " [0.,0.,0.,0.,0.,0.,0.],\n",
    " [0.,0.,0.,0.,0.,0.,0.]])\n",
    "\n",
    "test_link_prob_matrix = compute_link_probability_matrix(test_link_matrix)\n",
    "print_matrix(test_link_prob_matrix)\n",
    "true_lpm = np.array([[0., 0., 0., 0., 0., 0.5, 0.5],\n",
    "                     [0., 0., 0.25, 0., 0.25, 0.25, 0.25],\n",
    "                     [0., 0.5, 0., 0.5, 0., 0., 0.],\n",
    "                     [0., 0.5, 0., 0., 0.5, 0., 0.],\n",
    "                     [0., 0., 0., 0., 0., 0., 0.],\n",
    "                     [0., 0., 0., 0., 0., 0., 0.],\n",
    "                     [0., 0., 0., 0., 0., 0., 0.]])\n",
    "    \n",
    "# a test for you\n",
    "assert (np.round(test_link_prob_matrix,2) == np.round(true_lpm,2)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "078e57adfe34635837883ecce76fd4ec",
     "grade": true,
     "grade_id": "1b",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hidden test cell, don’t modify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c97659e95b42bc254d48b589b6421aa2",
     "grade": false,
     "grade_id": "cell-6a2f36b6e0f31958",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "__c) Implement the function `compute_teleport_matrix(...)`, which computes the teleport matrix. Teleporting from one webpage to any webpage has the same probability. Execute the function and display the resulting teleport matrix using `print_matrix(...)`.__ (1P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0529fa0f465a5626f472166cb584048",
     "grade": true,
     "grade_id": "cell-368312ca66785bc4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n",
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n",
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n",
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n",
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n",
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n",
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n",
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n",
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n",
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n",
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n",
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n",
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n",
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n",
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n"
     ]
    }
   ],
   "source": [
    "def compute_teleport_matrix(num_pages: int = 15) -> npt.NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Compute the teleport matrix.\n",
    "    \n",
    "    :param num_pages: number of webpages\n",
    "    :return: teleport matrix\n",
    "    \"\"\"\n",
    "    teleport_matrix: npt.NDArray = np.array([])\n",
    "    \n",
    "    teleport_matrix = np.ones((num_pages, num_pages))\n",
    "    teleport_matrix = teleport_matrix / num_pages\n",
    "    \n",
    "    return teleport_matrix\n",
    "    \n",
    "teleport_matrix = compute_teleport_matrix(15)\n",
    "print_matrix(teleport_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa104009c94edffc19b5bae39595411f",
     "grade": false,
     "grade_id": "cell-7d3d1621af9e2542",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is for you to check if your function works properly\n",
    "test_teleport_matrix = compute_teleport_matrix(5)\n",
    "true_tm = np.array([\n",
    "       [0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "       [0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "       [0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "       [0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "       [0.2, 0.2, 0.2, 0.2, 0.2]])\n",
    "\n",
    "# a test for you\n",
    "assert (np.round(test_teleport_matrix,2) == np.round(true_tm,2)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ca2e5fa43507b83ae494a4107d06d94",
     "grade": true,
     "grade_id": "1c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hidden test cell, don’t modify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bde57d7f00289f5f44d77fd726b69a3",
     "grade": false,
     "grade_id": "cell-e9359f3b38d2c136",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "__d) Implement the function `compute_transition_matrix(...)`, which computes the transition matrix based on the link probability matrix, the teleport matrix, and the teleporting probability. The teleporting probability determines how likely a teleporting event is. Execute the function with the matrices from 1b) and 1c) and a teleporting probability of $0.1$. Display the resulting transition matrix using `print_matrix(...)`.__ (2P)\n",
    "\n",
    "__Hint:__ Make sure that each row of the transition matrix actually represents a probability distribution (i.e., it has to sum up to $1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56173ec8198c804977887b050bed555e",
     "grade": true,
     "grade_id": "cell-6a90af972cc64c42",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.01 0.01 0.23 0.01 0.01 0.23 0.23 0.01 0.01 0.01 0.01 0.23 0.01 0.01\n",
      "0.01 0.01 0.01 0.01 0.46 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.46 0.01\n",
      "0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.46 0.01 0.01 0.01 0.01 0.01 0.46 0.01\n",
      "0.01 0.01 0.01 0.01 0.01 0.23 0.23 0.01 0.23 0.23 0.01 0.01 0.01 0.01 0.01\n",
      "0.01 0.19 0.19 0.19 0.01 0.19 0.01 0.19 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      "0.01 0.01 0.01 0.19 0.19 0.01 0.19 0.01 0.19 0.01 0.19 0.01 0.01 0.01 0.01\n",
      "0.01 0.91 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      "0.01 0.14 0.14 0.14 0.01 0.14 0.14 0.01 0.01 0.01 0.01 0.14 0.01 0.14 0.01\n",
      "0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07 0.07\n",
      "0.01 0.01 0.31 0.31 0.01 0.01 0.31 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      "0.01 0.01 0.01 0.01 0.19 0.01 0.19 0.19 0.01 0.01 0.01 0.01 0.19 0.19 0.01\n",
      "0.01 0.01 0.16 0.01 0.01 0.01 0.16 0.16 0.16 0.16 0.01 0.01 0.01 0.16 0.01\n",
      "0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.91 0.01 0.01 0.01 0.01 0.01 0.01\n",
      "0.01 0.01 0.01 0.01 0.01 0.01 0.23 0.23 0.01 0.23 0.01 0.01 0.01 0.01 0.23\n",
      "0.01 0.01 0.01 0.01 0.01 0.23 0.01 0.01 0.23 0.23 0.01 0.01 0.23 0.01 0.01\n"
     ]
    }
   ],
   "source": [
    "def compute_transition_matrix(link_probability_matrix: np.ndarray, teleport_matrix: np.ndarray,\n",
    "                              teleporting_probability: float = 0.1) -> npt.NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Compute the transition matrix based on the teleport matrix and the link probability matrix.\n",
    "    \n",
    "    :param link_probability_matrix: link probability matrix\n",
    "    :param teleport_matrix: teleport matrix\n",
    "    :param teleporting_probability: probability of teleporting instead of following a link\n",
    "    :return: transition matrix\n",
    "    \"\"\"\n",
    "    # size of m x m where m is the size of link_probability_matrix\n",
    "    transition_matrix: npt.NDArray = np.array([])\n",
    "    transition_matrix = np.zeros_like(link_probability_matrix, dtype=np.float64)\n",
    "\n",
    "    # Calculate the sum of each row in link_probability_matrix. Reshape to a column vector\n",
    "    sum_rows = np.round(link_probability_matrix.sum(axis=1)).reshape(-1, 1)\n",
    "\n",
    "    # If the sum of a row is 0, set the row in transition_matrix to the corresponding row in teleport_matrix\n",
    "    # Otherwise, set the row in transition_matrix to the corresponding row in link_probability_matrix * (1 - teleporting_probability) + teleport_matrix * teleporting_probability\n",
    "    transition_matrix = np.where(sum_rows == 0, teleport_matrix, link_probability_matrix * (1 - teleporting_probability) + teleport_matrix * teleporting_probability)\n",
    " \n",
    "    return transition_matrix\n",
    "    \n",
    "transition_matrix = compute_transition_matrix(link_prob_matrix, teleport_matrix)\n",
    "print_matrix(transition_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d795d68145b2fd1ccca312ddf0ed9fcf",
     "grade": false,
     "grade_id": "cell-391d1a5e5d0f285c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is for you to check if your function works properly\n",
    "# link propability matrix and teleport matrix are from the other self-test above\n",
    "true_tm = 0.14285714 * np.ones((7,7))\n",
    "true_lpm = np.array([[0., 0., 0., 0., 0., 0.5, 0.5],\n",
    "                     [0., 0., 0.25, 0., 0.25, 0.25, 0.25],\n",
    "                     [0., 0.5, 0., 0.5, 0., 0., 0.],\n",
    "                     [0., 0.5, 0., 0., 0.5, 0., 0.],\n",
    "                     [0., 0., 0., 0., 1., 0., 0.],\n",
    "                     [0., 0., 0., 0., 0., 0., 0.],\n",
    "                     [0., 0., 0., 0., 0., 0., 0.]])\n",
    "\n",
    "test_transition_matrix = compute_transition_matrix(true_lpm, true_tm) \n",
    "\n",
    "true_transition_matrix = np.array([[0.01428572, 0.01428572, 0.01428572, 0.01428571, 0.01428571,\n",
    "        0.46428571, 0.46428571],\n",
    "       [0.01428572, 0.01428572, 0.23928572, 0.01428571, 0.23928571,\n",
    "        0.23928571, 0.23928571],\n",
    "       [0.01428572, 0.46428572, 0.01428572, 0.46428571, 0.01428571,\n",
    "        0.01428571, 0.01428571],\n",
    "       [0.01428572, 0.46428572, 0.01428572, 0.01428571, 0.46428571,\n",
    "        0.01428571, 0.01428571],\n",
    "       [0.01428572, 0.01428572, 0.01428572, 0.01428571, 0.91428571,\n",
    "        0.01428571, 0.01428571],\n",
    "       [0.14285715, 0.14285714, 0.14285714, 0.14285714, 0.14285714,\n",
    "        0.14285715, 0.14285714],\n",
    "       [0.14285715, 0.14285714, 0.14285714, 0.14285714, 0.14285714,\n",
    "        0.14285715, 0.14285714]])\n",
    "# a test for you\n",
    "assert (np.round(test_transition_matrix,2) == np.round(true_transition_matrix,2)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9eaf7a705b7894df4276fe2a01b55260",
     "grade": true,
     "grade_id": "1d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hidden test cell, don’t modify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2837ce06571bef268aad74c16cbdaa1d",
     "grade": false,
     "grade_id": "cell-2661012394c9eea6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Random Walk (6.5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1baabbc04ed5821482dd3b6564f9db09",
     "grade": false,
     "grade_id": "cell-13fc080778c49de9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "__e) Implement the function `get_next_page(...)`. Given the id of the current page, it samples the next webpage based on the probabilities in the transition matrix. Call the function 1000 times with `current_page=0` and the transition matrix from 1d) and count which page is selected how many times (this is already implemented for you).__ (1.5P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "212379cdb14171c731004786eb4ed48f",
     "grade": true,
     "grade_id": "cell-0ff859c1ef6452b6",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m next_page\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# This part is already implemented for you.,Just make sure it runs.\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page, count \u001b[38;5;129;01min\u001b[39;00m collections\u001b[38;5;241m.\u001b[39mCounter([get_next_page(\u001b[38;5;241m0\u001b[39m, transition_matrix) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m)])\u001b[38;5;241m.\u001b[39mmost_common():\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(page)\u001b[38;5;241m.\u001b[39mljust(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was selected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(count)\u001b[38;5;241m.\u001b[39mljust(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m times.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m next_page\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# This part is already implemented for you.,Just make sure it runs.\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page, count \u001b[38;5;129;01min\u001b[39;00m collections\u001b[38;5;241m.\u001b[39mCounter([\u001b[43mget_next_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransition_matrix\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m)])\u001b[38;5;241m.\u001b[39mmost_common():\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(page)\u001b[38;5;241m.\u001b[39mljust(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was selected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(count)\u001b[38;5;241m.\u001b[39mljust(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m times.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m, in \u001b[0;36mget_next_page\u001b[1;34m(current_page, transition_matrix, num_pages)\u001b[0m\n\u001b[0;32m     13\u001b[0m next_page: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m next_page\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "def get_next_page(current_page: int, transition_matrix: np.ndarray, num_pages: int = 15) -> int:\n",
    "    \"\"\"\n",
    "    Samples the next page based on the current page and the probabilities of the transition matrix.\n",
    "    \n",
    "    :param current_page: id of the current page (integer)\n",
    "    :param transition_matrix: transition matrix\n",
    "    :param num_pages: number of webpages\n",
    "    :return: index of the next webpage\n",
    "    \"\"\"\n",
    "    next_page: int = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return next_page\n",
    "    \n",
    "# This part is already implemented for you.,Just make sure it runs.\n",
    "for page, count in collections.Counter([get_next_page(0, transition_matrix) for i in range(1000)]).most_common():\n",
    "    print(f'Page {str(page).ljust(2)} was selected {str(count).ljust(3)} times.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2e6b91a5b948261a9f298f5423a46b8",
     "grade": false,
     "grade_id": "cell-e1e8f341aa3525ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is for you to check if your function works properly\n",
    "# The test_transition_matrix is from your self test of the task above\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "for page, count in collections.Counter([get_next_page(0, true_transition_matrix,7) for i in range(1000)]).most_common():\n",
    "    print(f'Page {str(page).ljust(2)} was selected {str(count).ljust(3)} times.')\n",
    "\n",
    "\n",
    "# The output should look like this:\n",
    "'''\n",
    "Page 6  was selected 469 times.\n",
    "Page 5  was selected 452 times.\n",
    "Page 1  was selected 25  times.\n",
    "Page 0  was selected 18  times.\n",
    "Page 4  was selected 16  times.\n",
    "Page 3  was selected 11  times.\n",
    "Page 2  was selected 9   times.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1a1021a2fb481cc9229b1af3a3afba2",
     "grade": true,
     "grade_id": "1e",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hidden test cell, don’t modify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "387813615d3b6b92e32940f71a1a3597",
     "grade": false,
     "grade_id": "cell-ea64300c56631792",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "__f) Implement the function `random_walk(...)`.__ (4P)\n",
    "\n",
    "The function should perform a random walk starting from a randomly selected webpage. For each step, it should select the next webpage using the function `get_next_page(...)` and the `transition_matrix`.\n",
    "\n",
    "Initialize all weights $w_i$ equally (i.e., $w_i=\\frac{1}{|D|}$ for all $i \\in D$ where $D$ represents the set of all documents). After every `weight_update_interval` walking steps during the process, the function should update the normalized weights $w_i$ for each webpage $i$ as\n",
    "\n",
    "$\\Large w_i = \\frac{c_i}{\\sum_{j=0}^{|D|}c_j}$,\n",
    "\n",
    "where $c_j$ is the count of how often the webpage $j$ has been visited.\n",
    "\n",
    "After each weight update, the function should check if the algorithm has sufficiently converged. To do so, we compute the euclidean distance between the current weights and the previous weights. The algorithm terminates once the euclidean distance is smaller than the threshold `epsilon`:\n",
    "\n",
    "$|w_{current} - w_{previous}| < \\epsilon$\n",
    "\n",
    "Furthermore, after the initialization as well as after each weight update, store the computed weights for all webpages in a dataframe with the three columns `step`, `page`, and `weight`. This dataframe should be the return value of the function.\n",
    "\n",
    "_Check out the example dataframe below, which assumes three webpages and `weight_update_interval=20`._\n",
    "\n",
    "__Execute the function with the transition matrix from 1d), `weight_update_interval=20`, and `epsilon=0.001`. Store the resulting dataframe in the variable `pagerank_results`, which will be used to plot the weights.__ \n",
    "\n",
    "\n",
    "__Hint:__ The distance function is already implemented for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d05d6972c3cfe486a582a8a7277562e6",
     "grade": false,
     "grade_id": "cell-9d476778560c7b12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'weight': [1/3, 1/3, 1/3, 12/20, 3/20, 5/20], # obviously much longer ...\n",
    "    'step': [0,0,0,20,20,20],\n",
    "    'page': [0,1,2,0,1,2],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d68775aebe4381381ef9f29014a524d",
     "grade": true,
     "grade_id": "cell-955f39991fb9cfc0",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "def distance(vec_1: np.ndarray, vec_2: np.ndarray) -> np.float64:\n",
    "    \"\"\"\n",
    "    Compute the eucledian distance between two vectors.\n",
    "    \n",
    "    :param vec_1: first vector\n",
    "    :param vec_2: second vector\n",
    "    :return: euclidean distance between the vectors\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(vec_1 - vec_2)\n",
    "\n",
    "def random_walk(transition_matrix: np.ndarray, weight_update_interval: int = 20,\n",
    "                epsilon: float = 0.001, num_pages: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Execute the random walk.\n",
    "    \n",
    "    :param transition_matrix: transition matrix\n",
    "    :param weight_update_interval: number of walking steps between weight updates\n",
    "    :param epsilon: convergence threshold\n",
    "    :param num_pages: number of webpages\n",
    "    :return: dataframe of weights for different pages at different steps\n",
    "    \"\"\"\n",
    "    walk: pd.DataFrame = pd.DataFrame({})\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "        \n",
    "    return walk\n",
    "    \n",
    "pagerank_results = random_walk(transition_matrix, 20, 0.001, 15)\n",
    "\n",
    "# This plots a graph showing the convergence of the page weights as the random walk progresses\n",
    "# make sure your data frame has the right format for the graph to make sense\n",
    "sns.lineplot(data=pagerank_results, x=\"step\", y=\"weight\", hue=\"page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "148a766786f60e8858747476e7b20b60",
     "grade": false,
     "grade_id": "cell-7a0b1b81477108a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is for you to check if your function works properly\n",
    "# The test_transition_matrix is from your self test of the task above\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "np.sum(true_transition_matrix,1)\n",
    "test_pagerank_results = random_walk(true_transition_matrix, 20, 0.001, 7)\n",
    "\n",
    "last_seven = pd.DataFrame({\n",
    "    \"weight\": [0.035714, 0.060714, 0.046429, 0.052976, 0.694048, 0.051786, 0.058333],\n",
    "    \"step\": [1680,1680,1680,1680,1680,1680,1680],\n",
    "    \"page\": [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"]\n",
    "}, index=[588,589,590,591,592,593,594])\n",
    "\n",
    "# Here is a test for you\n",
    "assert test_pagerank_results.iloc[-7:].round(6).equals(last_seven)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81716289455bf3386e273469bc2a8399",
     "grade": true,
     "grade_id": "1f",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hidden test cell, don’t modify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f1dfe99df4e07e9aa45fe5356a74925",
     "grade": false,
     "grade_id": "cell-eaab9a80072f3d89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "__g) Save all webpages and their final weights ranked by their final weights (highest-ranked webpage first) in the variable `ordered_webpages` as a pandas dataframe.__ (1P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "423013bf0db562c2aea4555df544c3ee",
     "grade": true,
     "grade_id": "cell-11a430d021e90a19",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordered_webpages = pd.DataFrame(columns=['weight', 'step', 'page'])\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df3e4a2fafe91150ada3b17da0c2174f",
     "grade": true,
     "grade_id": "1g_1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hidden test cell, don’t modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8cc30717ade18b2ae890da7562ff255",
     "grade": true,
     "grade_id": "1g_2",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hidden test cell, don’t modify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ed6c4987fc1eb229c747421b283abb6",
     "grade": false,
     "grade_id": "cell-95908b684d82c5a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 2: Clustering (8 Points)\n",
    "\n",
    "In this task, you will find clusters of similar arguments for a variety of topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5f40e1a9e2dbd9f3f5a1aa561acd2b1",
     "grade": false,
     "grade_id": "cell-b2690346d8da50c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__About the data__:\n",
    "\n",
    "The data for this task is stored in `topic_arguments.tsv`.,Each row contains a `topic` identifier, two arguments `argument_1` and `argument_2`, and a `label` that describes the similarity between the two arguments.,The dataset contains multiple arguments for each topic.\n",
    "\n",
    "The labels have the following meanings:\n",
    "\n",
    "* _NS_: no similarity\n",
    "* _DTORCD_: different topic or can't decide\n",
    "* _SS_: some similarity\n",
    "* _HS_: high similarity\n",
    "\n",
    "These labels will be used to evaluate how well the clustering works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f32626d012cda23090e737e91b15b26",
     "grade": false,
     "grade_id": "cell-a3418fa92b95f9ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Computing the Clusters (6 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f929f2c71b330678eb26c06c7494de2",
     "grade": false,
     "grade_id": "cell-e89064730834e7ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__a) Load the data and lowercase `argument_1` and `argument_2` in each row. Save the lowercased data in the variable `df`. Display the `.head()` of the loaded dataframe.__ (1P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b570c8ddc6513114cff822c654d9170e",
     "grade": true,
     "grade_id": "cell-5a98db2c9a4628f1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>argument_1</th>\n",
       "      <th>argument_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3d printing</td>\n",
       "      <td>3D Printed Products Can Improve Health Outcome...</td>\n",
       "      <td>Specifically, the Navy hopes to see 3D printin...</td>\n",
       "      <td>NS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3d printing</td>\n",
       "      <td>This could greatly increase the quality of lif...</td>\n",
       "      <td>The advent and spread of new technologies, lik...</td>\n",
       "      <td>DTORCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3d printing</td>\n",
       "      <td>Controlled Print Chamber: Controlled process e...</td>\n",
       "      <td>The new non-clog technology and moisture-lock ...</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3d printing</td>\n",
       "      <td>Spark will make visualization of prints much e...</td>\n",
       "      <td>The Cube Pro features a controlled environment...</td>\n",
       "      <td>NS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3d printing</td>\n",
       "      <td>Affordable 3D Printing for everyone With the U...</td>\n",
       "      <td>The Experience Centre, combined with our new S...</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic                                         argument_1  \\\n",
       "0  3d printing  3D Printed Products Can Improve Health Outcome...   \n",
       "1  3d printing  This could greatly increase the quality of lif...   \n",
       "2  3d printing  Controlled Print Chamber: Controlled process e...   \n",
       "3  3d printing  Spark will make visualization of prints much e...   \n",
       "4  3d printing  Affordable 3D Printing for everyone With the U...   \n",
       "\n",
       "                                          argument_2   label  \n",
       "0  Specifically, the Navy hopes to see 3D printin...      NS  \n",
       "1  The advent and spread of new technologies, lik...  DTORCD  \n",
       "2  The new non-clog technology and moisture-lock ...      SS  \n",
       "3  The Cube Pro features a controlled environment...      NS  \n",
       "4  The Experience Centre, combined with our new S...      SS  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "df = pd.read_csv('topic_arguments.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19f96f409857f7dc3ee3920f7663c0cc",
     "grade": true,
     "grade_id": "2a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hidden test cell, don’t modify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03beba430bcac72c492faf0c37e43603",
     "grade": false,
     "grade_id": "cell-a11c1e7902dd80d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "__b) Imlement the function `cluster_and_predict(...)`. It should:__\n",
    "\n",
    "* fit the given `vectorizer` on all _unique_ arguments in the `dataframe` (all topics)\n",
    "* vectorize all _unique_ arguments of the specified `topic` using this `vectorizer`\n",
    "* fit the given `clustering_model` on these computed vectors\n",
    "* output the cluster for each argument of the specified `topic`\n",
    "\n",
    "The output should map each argument to a cluster id as shown below:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"This is one argument\": 1,\n",
    "    \"This is a similar argument\": 1,\n",
    "    \"This is another very different argument.\": 2\n",
    "}\n",
    "```\n",
    "\n",
    "where `1` and `2` are the cluster ids (assigned by the clustering algorithm).\n",
    "\n",
    "\n",
    "__Apply the function using:__\n",
    "\n",
    "* a `TfidfVectorizer()` as the `vectorizer`\n",
    "* an `AgglomerativeClustering(n_clusters=None, distance_threshold=0.8, affinity='cosine', linkage='average')` as the `clustering_model`\n",
    "* `'Solar energy'` as the `topic`\n",
    "\n",
    "__and evaluate it using the provided evaluation method.__\n",
    "\n",
    "__Hint:__ Use the attribute `.labels_` of the clustering model. (3.5P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26121a94ddb14c840a7c32c45d67cf26",
     "grade": true,
     "grade_id": "cell-0a45f75609ff1cfe",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of predictions: 4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Make sure that all arguments from the topic also exist in the predictions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 75\u001b[0m\n\u001b[0;32m     73\u001b[0m clustering_model \u001b[38;5;241m=\u001b[39m AgglomerativeClustering(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, distance_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, affinity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m, linkage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     74\u001b[0m clusters \u001b[38;5;241m=\u001b[39m cluster_and_predict(df, TfidfVectorizer(), clustering_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolar energy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSolar energy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[49], line 61\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(df, predictions, topic)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ix, row \u001b[38;5;129;01min\u001b[39;00m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m topic]\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument_1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m predictions \u001b[38;5;129;01mor\u001b[39;00m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument_2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m predictions:\n\u001b[1;32m---> 61\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure that all arguments from the topic also exist in the predictions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m     y_true\u001b[38;5;241m.\u001b[39mappend(to_binary_label(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m     64\u001b[0m     y_pred\u001b[38;5;241m.\u001b[39mappend(predictions[row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument_1\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m==\u001b[39m predictions[row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument_2\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n",
      "\u001b[1;31mValueError\u001b[0m: Make sure that all arguments from the topic also exist in the predictions."
     ]
    }
   ],
   "source": [
    "def cluster_and_predict(df: pd.DataFrame, vectorizer: TfidfVectorizer,\n",
    "                        clustering_model: AgglomerativeClustering, topic: str ) -> dict:\n",
    "    \"\"\"\n",
    "    Cluster all unique arguments from all of (argument_1 | argument_2) and output the cluster mappings.\n",
    "    \n",
    "    :param df: dataframe (as loaded)\n",
    "    :param vectorizer: vectorizer from sklearn\n",
    "    :param clustering_model: clustering algorithm from sklearn\n",
    "    :param topic: only arguments from this topic will be clustered\n",
    "    :return: mappings from arguments to cluster ids\n",
    "    \"\"\"\n",
    "    clusters: dict = {}\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    #hier passiert irgendwas, das nicht stimmt...\n",
    "\n",
    "    vectorizer.fit(df) #fit the vectorizer to the raw arguments\n",
    "    #die Zeile tut überhaupt nix?!\n",
    "\n",
    "    topic_args = df[df[\"topic\"] == topic] #select only arguments on the specified topic\n",
    "\n",
    "# Hier fehlt mir inhaltliches Verständnis. Eigentlich sollte das Aufrufen von .fit() schon alles erledigen und dann ein Objekt von TfidfVectorizer ausgeben, mit dem ich aber mangels vernünftiger docu nciht veil anfangen kann.\n",
    "# Das doppelt zu machen, einmal über den ganzen df und einmal über die topics sorgt glaube ich für Unsinn.\n",
    "\n",
    "    matrix = vectorizer.fit_transform(topic_args)\n",
    "    #matrix = vectorizer.fit_transform(df)\n",
    "    matrix = matrix.toarray()\n",
    "\n",
    "    clustering_model.fit(matrix) #fit the clustering model to the computed vectors\n",
    "    \n",
    "    cluster_labels = clustering_model.labels_ #build the dict from the clustering results\n",
    "    for i, label in enumerate(cluster_labels):\n",
    "        argument = topic_args.iloc[i]\n",
    "        clusters[label] = [argument]\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def evaluate(df: pd.DataFrame, predictions: Mapping[str, int], topic: str = \"Solar energy\") -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the found clusters for a single topic using the similarity labels\n",
    "    \n",
    "    :param df: dataframe (as loaded)\n",
    "    :param predictions: mappings from arguments to cluster ids from cluster_and_predict(...)\n",
    "    :param topic: only argument pairs from this topic will be considered\n",
    "    :return: f_mean (mean of f1(sim) and f1(dissim))\n",
    "    \"\"\"\n",
    "    print(\"number of predictions:\", len(predictions))\n",
    "    \n",
    "    def to_binary_label(label):\n",
    "        if label in [\"HS\", \"SS\"]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for ix, row in df[df[\"topic\"] == topic].iterrows():\n",
    "        if row[\"argument_1\"] not in predictions or row[\"argument_2\"] not in predictions:\n",
    "            raise ValueError(\"Make sure that all arguments from the topic also exist in the predictions.\")\n",
    "        \n",
    "        y_true.append(to_binary_label(row[\"label\"]))\n",
    "        y_pred.append(predictions[row[\"argument_1\"]] == predictions[row[\"argument_2\"]])\n",
    "        \n",
    "    f_sim = f1_score(y_true, y_pred, pos_label=1)\n",
    "    f_dissim = f1_score(y_true, y_pred, pos_label=0)\n",
    "    f_mean = np.mean([f_sim, f_dissim])\n",
    "    \n",
    "    print(f\"F_sim: {f_sim}, F_dissim: {f_dissim}, F_mean: {f_mean}\")\n",
    "    return f_mean, f_sim, f_dissim\n",
    "\n",
    "clustering_model = AgglomerativeClustering(n_clusters=None, distance_threshold=0.8, affinity=\"cosine\", linkage=\"average\")\n",
    "clusters = cluster_and_predict(df, TfidfVectorizer(), clustering_model, \"Solar energy\")\n",
    "evaluate(df, clusters, \"Solar energy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "852ab8f503ff8d2f3f11addaec8184bd",
     "grade": false,
     "grade_id": "cell-6c33c0651cc4da86",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Tests\n",
    "clustertest = cluster_and_predict(df, TfidfVectorizer(), clustering_model, \"Social networks\")\n",
    "test1 = evaluate(df, clustertest, \"Social networks\")\n",
    "assert(test1 == (0.6587155963302752, 0.39999999999999997, 0.9174311926605504))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5e32b5db9796174c4b762b55a42d6d5",
     "grade": true,
     "grade_id": "2b",
     "locked": true,
     "points": 3.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hidden test cell, don’t modify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7b83d9b0d210a83e74f73c64d91d24e",
     "grade": false,
     "grade_id": "cell-d01fc802b5357415",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__c) Run a search over all `distance_thresholds` in `np.linspace(0.7, 1.0, 13)` (leave all other parameters as set in 2b) to find the best value for `distance_threshold` (based on f_mean) for the topic `'Solar energy'`.__\n",
    "\n",
    "__What is the best `distance_threshold` (save in variable `best_threshold`) and the `f_mean` (save in variable `best_f_mean`) it achieves and what is the corresponding cluster prediction from `cluster_and_predict` to those two best values?__ (1.5P)\n",
    "\n",
    "*HINT:* Use `affinity='cosine'` and `linkage='average'` parameters in `AgglomerativeClustering` for the clustering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5739ff98a918b667715400dbd03b8fa7",
     "grade": true,
     "grade_id": "cell-de0d14aaaddfe683",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of predictions: 4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Make sure that all arguments from the topic also exist in the predictions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     best_threshold \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_f_mean\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_f_mean, best_threshold, best_clusters\n\u001b[1;32m---> 19\u001b[0m best_f_mean, best_threshold, best_clusters \u001b[38;5;241m=\u001b[39m \u001b[43mdistance_threshold_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_f_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_clusters\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[45], line 13\u001b[0m, in \u001b[0;36mdistance_threshold_search\u001b[1;34m(best_f_mean, best_threshold, best_clusters)\u001b[0m\n\u001b[0;32m     11\u001b[0m     clustering_model \u001b[38;5;241m=\u001b[39m AgglomerativeClustering(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, distance_threshold\u001b[38;5;241m=\u001b[39mdist, affinity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m, linkage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m     clusters \u001b[38;5;241m=\u001b[39m cluster_and_predict(df, TfidfVectorizer(), clustering_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolar energy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m     results[dist] \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSolar energy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m best_f_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(results\u001b[38;5;241m.\u001b[39mvalues()[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     16\u001b[0m best_threshold \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_f_mean\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[44], line 53\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(df, predictions, topic)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ix, row \u001b[38;5;129;01min\u001b[39;00m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m topic]\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument_1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m predictions \u001b[38;5;129;01mor\u001b[39;00m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument_2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m predictions:\n\u001b[1;32m---> 53\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure that all arguments from the topic also exist in the predictions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m     y_true\u001b[38;5;241m.\u001b[39mappend(to_binary_label(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m     56\u001b[0m     y_pred\u001b[38;5;241m.\u001b[39mappend(predictions[row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument_1\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m==\u001b[39m predictions[row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument_2\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n",
      "\u001b[1;31mValueError\u001b[0m: Make sure that all arguments from the topic also exist in the predictions."
     ]
    }
   ],
   "source": [
    "best_f_mean: float = -1\n",
    "best_threshold: float = None\n",
    "best_clusters: dict = None\n",
    "\n",
    "def distance_threshold_search(best_f_mean: float, best_threshold: float, best_clusters: dict) -> Tuple[float, float, dict]:\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    distance_thresholds = np.linspace(0.7, 1.0, 13)\n",
    "    results = dict()\n",
    "    for dist in distance_thresholds:\n",
    "        clustering_model = AgglomerativeClustering(n_clusters=None, distance_threshold=dist, affinity=\"cosine\", linkage=\"average\")\n",
    "        clusters = cluster_and_predict(df, TfidfVectorizer(), clustering_model, \"Solar energy\")\n",
    "        results[dist] = evaluate(df, clusters, \"Solar energy\")\n",
    "\n",
    "    best_f_mean = max(results.values()[0]) #find the highest f_mean in the results with the different distances\n",
    "    best_threshold = results.loc['best_f_mean'] #the distance which produces the best f_mean should be the best distance\n",
    "    best_clusters #how do I calculate which cluster is best??\n",
    "    return best_f_mean, best_threshold, best_clusters\n",
    "\n",
    "best_f_mean, best_threshold, best_clusters = distance_threshold_search(best_f_mean, best_threshold, best_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68180ddcf04d19417b13c6d249f02c75",
     "grade": true,
     "grade_id": "2c_1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hidden test cell, don’t modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53c41758e2dad5195f703d0040ed3b6a",
     "grade": true,
     "grade_id": "2c_2",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hidden test cell, don’t modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ecf2f3130d361347a8ceaaa00f20508",
     "grade": true,
     "grade_id": "2c_3",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hidden test cell, don’t modify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d5fbf6cacb645151e72c329d756e8bb",
     "grade": false,
     "grade_id": "cell-3d7340e336cc958d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Displaying the Clusters (2 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82eab6d72a5812fe0381d7d2e3a99c67",
     "grade": false,
     "grade_id": "cell-3b3cdb6c22a75405",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For simplicity, we are only interested in the topic 'Solar energy'. Note that in reality, we would need to evaluate the derived hyperparameters on a different unseen dataset and different topics. To make things easier, we skip this and assume we have found a general clustering method.\n",
    "\n",
    "__d) Implement the function `to_ordered_clusters(...)`.,Based on the output of `cluster_and_predict(...)`, it should:__\n",
    "\n",
    "* create a list that contains a list of unique arguments for each cluster:\n",
    "```python\n",
    "[\n",
    "    [\"something about the sun.\", \"something else about the sun\"], # first cluster arguments\n",
    "    [\"something about energy consumption\", \"...\"], # second cluster arguments\n",
    "    # ...\n",
    "]\n",
    "```\n",
    "* remove all clusters that contain less than `min_arguments=3` unique arguments\n",
    "* sort all clusters based on the number of unique arguments they contain (with the cluster that contains the most arguments first)\n",
    "\n",
    "__Apply it on the clusters of the topic 'Solar energy' based on the best `distance_threshold` you found in 2c). If you did not solve 2c), you can choose use the same parameters as in 2b).__\n",
    "\n",
    "__Use the output of `to_ordered_clusters(...)` as the input for the already implemented function `print_keywords(...)` to display the top `k=10` keywords for each cluster of the topic 'Solar energy'.__ (2P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35c26d5e90506882c26ae7ef17ef7a2a",
     "grade": true,
     "grade_id": "cell-25442483efefc71a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_ordered_clusters(predictions: Mapping[str, int], min_arguments: int = 3) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Returns a sorted list of lists of arguments of all clusters that have more than min_arguments arguments.\n",
    "    \n",
    "    :param predictions: mappings from arguments to cluster ids\n",
    "    :param min_arguments: minimum number of arguments a cluster must have to not be filtered out\n",
    "    :return: list of lists of arguments\n",
    "    \"\"\"\n",
    "    ordered_clusters: List[List[str]] = []\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    clustering_model = AgglomerativeClustering(n_clusters=None, distance_threshold=0.8, affinity=\"cosine\", linkage=\"average\") #using the distance from 2b for safety\n",
    "    clusters = cluster_and_predict(df, TfidfVectorizer(), clustering_model, \"Solar energy\")\n",
    "    \n",
    "    for cluster in clusters:\n",
    "        if len(cluster.values()) > min_arguments:\n",
    "            list_of_arguments_in_cluster = []\n",
    "            for argument in cluster.values():\n",
    "                list_of_arguments_in_cluster.append(argument)\n",
    "            ordered_clusters.append(list_of_arguments_in_cluster)\n",
    "\n",
    "    #Achtung: Ich nutze die predictions nicht.... was tun die?!\n",
    "    return ordered_clusters\n",
    "    \n",
    "def print_keywords(clusters: list[list[str]], k: int = 10) -> None:\n",
    "    \"\"\"\n",
    "    Print the top k words (based on tf-idf weight) for each cluster.\n",
    "    \n",
    "    :param clusters: list of lists of arguments\n",
    "    :param k: number of keywords to print\n",
    "    \"\"\"\n",
    "    \n",
    "    clusters_merged = [\" \".join(arguments) for arguments in clusters]\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    features = vectorizer.fit_transform(clusters_merged).toarray()\n",
    "    \n",
    "    # sort by tf-idf value and extract token ids with the highest score\n",
    "    sorted_features = np.argsort(features)\n",
    "    top_sorted_features = sorted_features[:,-k:]\n",
    "    \n",
    "    for cluster_idx in range(top_sorted_features.shape[0]):\n",
    "        print(f\"Cluster #{cluster_idx} ({len(clusters[cluster_idx])} arguments)\")\n",
    "        for idx in top_sorted_features[cluster_idx,::-1]:\n",
    "            if features[cluster_idx,idx] > 0:\n",
    "                print(\"*\", vectorizer.get_feature_names_out()[idx])\n",
    "        print(\"---\\n\")\n",
    "\n",
    "print_keywords(to_ordered_clusters(best_clusters)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "094e08214354493a5cc33683e165d6b1",
     "grade": false,
     "grade_id": "cell-945ce0bc39c2cf60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "temp = to_ordered_clusters(best_clusters)\n",
    "assert(len(temp) == 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24fcdbace74f25edbf5660a9086a1ea4",
     "grade": true,
     "grade_id": "2d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hidden test cell, don’t modify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54564dd98f8c3278c9c33dc334aef01a",
     "grade": false,
     "grade_id": "cell-a9bfde81d5c2a782",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**Submission:**\n",
    "\n",
    "Please upload your submission to Moodle before the next exercise session <font color=\"red\">(Jan 10, 23:59pm)</font>!\n",
    "\n",
    "Submission format: `Group_XX_Exercise_XX.zip`\n",
    "\n",
    "Your submission should contain your filled out Jupyter notebook (naming schema: `NLP4Web_Home_Exercise4.ipynb`) and any auxiliar files that are necessary to run your code (e.g., the datasets provided by us).\n",
    "\n",
    "Each submission must be handed in only once per group. If the naming of the file and the zip is not correct, points will be deducted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
