{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da5064c9ed8cd1fec0f36b714c345b0b",
     "grade": false,
     "grade_id": "cell-4d87ae78fb4caf9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# NLP and the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1145e2ba69b3e56620106550f0984e0",
     "grade": false,
     "grade_id": "cell-8b531762670192f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 0 ~ 0P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d4cef5c9a404a5516183e6ce9bf2128",
     "grade": false,
     "grade_id": "cell-6eca7b6c6c224dde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### a) Please enter your group number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75470a4986487fdb40d73fa368335c95",
     "grade": true,
     "grade_id": "cell-cccfbf605a28a18a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a760dcd98f5ea360c504ee7fd50a4088",
     "grade": false,
     "grade_id": "cell-2ed8ca1b9e5204c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "_**Regarding types, documentation, and output:**_\n",
    "\n",
    "_We tried to make the description of the parameters as clear as possible. However, if you believe that something is missing, please reach out to us in Moodle. We provide type hints for the function parameters and return values of the functions that you have to implement._\n",
    "\n",
    "_Nevertheless, your code must use the provided method stubs and parameters. Furthermore, make sure that your code runs without errors and in a reasonable amount of time, for example by using \"Kernel/Restart & Run All\" before submitting._\n",
    "\n",
    "_Please use comments where appropriate to help the tutors understand your code. This is especially important for the more extensive exercises later on. Finally, please pay attention to how you output the results. We highly recommend using `display(df)` for displaying data frames._\n",
    "\n",
    "_**Please only modify the template in the specified markdown and code cells (e.g. YOUR CODE / ANSWER / IMPORTS HERE). If you add any extra cells, they wont be taken into account while grading!  Some cells are left blank on purpose. Please do not modify these cells, because they are used to autograde your submission. If these cells are modified, the automatic grading for your submission will fail and we might deduct points. Please do not modify the cells containing public and private tests. If you want to do your own tests, please use the code cell containing your code solution (YOUR CODE HERE).**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "NGK3p3euEpoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3db57ae64e28b10ec1c59ea20a580e26",
     "grade": false,
     "grade_id": "cell-c2c225bdbb8ec891",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# NLP and the Web: Home Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "vyEzoVz0ExZI",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b1ec96309f55c0524dd381732fa6d75",
     "grade": false,
     "grade_id": "cell-93dbc0a4ebbbf170",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "In this exercise, you will deepen the theoretical concept of QA from the lectures and learn how to analyze QA systems and how explainability in AI systems can be achieved. This will be based on the UKP-SQuARE platform which was presented during the lecture. Within this exercise, you will participate in the research community and increase the diversity of models on the UKP-SQuARE platform.\n",
    "\n",
    "For this task you should use [Google Colab](https://colab.research.google.com/) where you have free access to GPUs for fine-tuning your transformer model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "40yoiVXJE2bJ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef55ba641168b7883a1e7e48f0c1a310",
     "grade": false,
     "grade_id": "cell-9f6420be7d107600",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Task 1: Fine-tune Transformer - 5 Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xm7S2UuNE7T2",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8891d28c60baf881344c68731749d3b",
     "grade": false,
     "grade_id": "cell-ea8fcbc957a8de82",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "In this task, you will fine-tune a pre-trained transformer-based architecture on a QA dataset with PyTorch and the [Hugging Face](https://huggingface.co/) library. You will contribute to the community by deploying your model on Hugging Face’s Model Hub and the SQuARE platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "QOQ7BsquE-cy",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af36eeaf7e0f93d2add6d31226ad90c1",
     "grade": false,
     "grade_id": "cell-1d462b6ae572a7a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "**a) Finetune the assigned model with the respectively assigned dataset. Before you can do this you need to prepare your dataset. Therefore you have to download the data from Hugging Face and pass it through the training example script from Hugging Face: https://github.com/huggingface/transformers/blob/main/examples/pytorch/question-answering/run_qa.py** **(3p)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "deletable": false,
    "editable": false,
    "id": "OiGZMnY3dwco",
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "421a9d18fda28308353e290d0e1a8bcf",
     "grade": false,
     "grade_id": "cell-9df184190e4b678a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "20e7e400-f4fc-4957-ace2-7c687e091912",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'transformers'...\n",
      "remote: Enumerating objects: 181623, done.\u001b[K\n",
      "remote: Counting objects: 100% (415/415), done.\u001b[K\n",
      "remote: Compressing objects: 100% (228/228), done.\u001b[K\n",
      "remote: Total 181623 (delta 212), reused 309 (delta 149), pack-reused 181208\u001b[K\n",
      "Receiving objects: 100% (181623/181623), 201.87 MiB | 19.48 MiB/s, done.\n",
      "Resolving deltas: 100% (127198/127198), done.\n",
      "/home/jan/Projects/NLP4Web/Homework 6/transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jan/Projects/NLP4Web/Homework 6/transformers\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from transformers==4.38.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from transformers==4.38.0.dev0) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from transformers==4.38.0.dev0) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from transformers==4.38.0.dev0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from transformers==4.38.0.dev0) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.38.0.dev0)\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/8d/6b/2f6478814954c07c04ba60b78d688d3d7bab10d786e0b6c1db607e4f6673/regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m785.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:--:--\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from transformers==4.38.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from transformers==4.38.0.dev0) (0.15.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.38.0.dev0)\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/8e/cf/b32d236cc01429bf2827bd1d8d81fa5a34a6cc7fb3499506f5d1aa19dcb8/safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from transformers==4.38.0.dev0) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0.dev0) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0.dev0) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->transformers==4.38.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->transformers==4.38.0.dev0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->transformers==4.38.0.dev0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->transformers==4.38.0.dev0) (2023.11.17)\n",
      "Downloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.1/785.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.38.0.dev0-py3-none-any.whl size=8457124 sha256=bf6c815d6cdea053552ca3c3edd8c51c7f3de382e1f623475d1f83e79d0a3071\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6nc2n6d3/wheels/f9/f4/a9/841ea77673ec9d3647def9a20aeac68c738993fac93722d87d\n",
      "Successfully built transformers\n",
      "Installing collected packages: safetensors, regex, transformers\n",
      "Successfully installed regex-2023.12.25 safetensors-0.4.2 transformers-4.38.0.dev0\n",
      "Requirement already satisfied: huggingface_hub in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (0.20.3)\n",
      "Requirement already satisfied: filelock in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface_hub) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->huggingface_hub) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->huggingface_hub) (2023.11.17)\n",
      "/home/jan/Projects/NLP4Web/Homework 6/transformers/examples/pytorch/question-answering\n",
      "Collecting accelerate>=0.12.0 (from -r requirements.txt (line 1))\n",
      "  Obtaining dependency information for accelerate>=0.12.0 from https://files.pythonhosted.org/packages/a6/b9/44623bdb05595481107153182e7f4b9f2ef9d3b674938ad13842054dcbd8/accelerate-0.26.1-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: datasets>=1.8.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.16.1)\n",
      "Collecting torch>=1.3.0 (from -r requirements.txt (line 3))\n",
      "  Obtaining dependency information for torch>=1.3.0 from https://files.pythonhosted.org/packages/c8/02/d3adf4b4851d99a31c5a9cf7b668f171e84334945d05fb7b51c42bf41abf/torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata\n",
      "  Downloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting evaluate (from -r requirements.txt (line 4))\n",
      "  Obtaining dependency information for evaluate from https://files.pythonhosted.org/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl.metadata\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: psutil in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: filelock in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (3.9.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from torch>=1.3.0->-r requirements.txt (line 3)) (4.9.0)\n",
      "Collecting sympy (from torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/d5/f0/8fbc882ca80cf077f1b246c0e3c3465f7f415439bdea6b899f6b19f61f70/networkx-3.2.1-py3-none-any.whl.metadata\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from torch>=1.3.0->-r requirements.txt (line 3)) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for nvidia-cudnn-cu12==8.9.2.26 from https://files.pythonhosted.org/packages/ff/74/a2e2be7fb83aaedec84f391f082cf765dfb635e7caa9b49065f73e4835d8/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for nvidia-nccl-cu12==2.19.3 from https://files.pythonhosted.org/packages/38/00/d0d4e48aef772ad5aebcf70b73028f88db6e5640b36c38e90445b7a57c45/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.2.0 (from torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for triton==2.2.0 from https://files.pythonhosted.org/packages/bd/ac/3974caaa459bf2c3a244a84be8d17561f631f7d42af370fc311defeca2fb/triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for nvidia-nvjitlink-cu12 from https://files.pythonhosted.org/packages/1e/07/bf730d44c2fe1b676ad9cc2be5f5f861eb5d153fb6951987a2d6a96379a9/nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting responses<0.19 (from evaluate->-r requirements.txt (line 4))\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from jinja2->torch>=1.3.0->-r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (2023.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.3.0->-r requirements.txt (line 3))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (1.16.0)\n",
      "Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, responses, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, evaluate, accelerate\n",
      "Successfully installed accelerate-0.26.1 evaluate-0.4.1 mpmath-1.3.0 networkx-3.2.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 responses-0.18.0 sympy-1.12 torch-2.2.0 triton-2.2.0\n",
      "/home/jan/Projects/NLP4Web/Homework 6\n",
      "Requirement already satisfied: huggingface-hub in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (0.20.3)\n",
      "Requirement already satisfied: filelock in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface-hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface-hub) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface-hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface-hub) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface-hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface-hub) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface-hub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->huggingface-hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->huggingface-hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->huggingface-hub) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->huggingface-hub) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "# Download all necessary dependencies. You should not modify and only run this cell\n",
    "!git clone https://github.com/huggingface/transformers\n",
    "%cd ./transformers\n",
    "!pip install .\n",
    "!pip install huggingface_hub\n",
    "%cd ./examples/pytorch/question-answering\n",
    "!pip install -r requirements.txt\n",
    "%cd ../../../../\n",
    "!pip install huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "6Id_rdT_E6JP",
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74c4aed01d4b15f928e5902d083e52a6",
     "grade": false,
     "grade_id": "cell-ce285d6eb7e25499",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "fad3e0ef-4a42-4132-c398-59b044496037",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==2.16.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: filelock in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets==2.16.1) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets==2.16.1) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets==2.16.1) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets==2.16.1) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets==2.16.1) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets==2.16.1) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets==2.16.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets==2.16.1) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets==2.16.1) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets==2.16.1) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets==2.16.1) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets==2.16.1) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets==2.16.1) (0.20.3)\n",
      "Requirement already satisfied: packaging in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets==2.16.1) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from datasets==2.16.1) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.16.1) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.16.1) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.16.1) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.16.1) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.16.1) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets==2.16.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.16.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.16.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.16.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.16.1) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from pandas->datasets==2.16.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from pandas->datasets==2.16.1) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from pandas->datasets==2.16.1) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.1) (1.16.0)\n",
      "Requirement already satisfied: tokenizers==0.15.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (0.15.0)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from tokenizers==0.15.0) (0.20.3)\n",
      "Requirement already satisfied: filelock in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets==2.16.1\n",
    "!pip install tokenizers==0.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0N2mYeVhPfKL",
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3d3257892b17768131270e651c4acf5",
     "grade": false,
     "grade_id": "cell-f77b00213f3f9cfc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Please only run the cell to get all imports\n",
    "import json\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, AutoModel\n",
    "from typing import List, Dict,  Any\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import gzip\n",
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "rtV6xyQgPfKM",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5026fe3f9f01f9362b6c85dc7f475a65",
     "grade": false,
     "grade_id": "cell-24c64b9592f71592",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "The following code provides assigns your group a model and data set, that you should use to solve this homework. You have only to insert your group number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KvavunxFPfKM",
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e845f6857c25fdf9810cd6849a9995b",
     "grade": false,
     "grade_id": "cell-1bf388bdb2d92717",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_dataset_combination(group: int) -> tuple:\n",
    "    models = ['microsoft/xtremedistil-l6-h256-uncased', 'microsoft/xtremedistil-l12-h384-uncased', 'microsoft/xtremedistil-l6-h384-uncased', 'distilbert-base-uncased','microsoft/MiniLM-L12-H384-uncased', 'huawei-noah/TinyBERT_General_4L_312D', 'huawei-noah/TinyBERT_General_6L_768D']\n",
    "    datasets = ['squad_v2']\n",
    "    result = list(itertools.product(models, datasets))\n",
    "    result = 16*result\n",
    "    # for idx, r in enumerate(result):\n",
    "    #     print(f\"Index: {idx}, Content: {r}\")\n",
    "    return result[group]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "aQPh8y9bPfKM",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3a41536f03f065f5b2c294828887a36",
     "grade": false,
     "grade_id": "cell-67a2bf6dc03ecad5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "*In* the next subtask you should download the data set `squad_v2`.\n",
    "\n",
    "You can find more information on the Hugging Face [page](https://huggingface.co/datasets/squad_v2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "4_PsRXRDPfKN",
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4d90698152d16862ce95584d6f391c9",
     "grade": false,
     "grade_id": "cell-5023740bfcaf4f0a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "c265d55e-ec6b-4c9e-cd4a-4d9380b4bf59",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 1, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 2, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 3, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 4, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 5, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 6, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Index: 7, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 8, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 9, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 10, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 11, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 12, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 13, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Index: 14, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 15, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 16, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 17, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 18, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 19, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 20, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Index: 21, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 22, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 23, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 24, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 25, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 26, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 27, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Index: 28, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 29, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 30, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 31, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 32, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 33, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 34, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Index: 35, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 36, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 37, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 38, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 39, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 40, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 41, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Index: 42, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 43, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 44, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 45, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 46, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 47, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 48, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Index: 49, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 50, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 51, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 52, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 53, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 54, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 55, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Index: 56, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 57, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 58, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 59, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 60, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 61, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 62, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Index: 63, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 64, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 65, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 66, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 67, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 68, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 69, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Index: 70, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 71, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 72, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 73, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 74, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 75, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 76, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Index: 77, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 78, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 79, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 80, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 81, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 82, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 83, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Index: 84, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 85, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 86, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 87, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 88, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 89, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 90, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Index: 91, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 92, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 93, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 94, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 95, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 96, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 97, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Index: 98, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 99, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 100, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 101, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 102, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 103, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 104, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Index: 105, Content: ('microsoft/xtremedistil-l6-h256-uncased', 'squad_v2')\n",
      "Index: 106, Content: ('microsoft/xtremedistil-l12-h384-uncased', 'squad_v2')\n",
      "Index: 107, Content: ('microsoft/xtremedistil-l6-h384-uncased', 'squad_v2')\n",
      "Index: 108, Content: ('distilbert-base-uncased', 'squad_v2')\n",
      "Index: 109, Content: ('microsoft/MiniLM-L12-H384-uncased', 'squad_v2')\n",
      "Index: 110, Content: ('huawei-noah/TinyBERT_General_4L_312D', 'squad_v2')\n",
      "Index: 111, Content: ('huawei-noah/TinyBERT_General_6L_768D', 'squad_v2')\n",
      "Model: microsoft/xtremedistil-l6-h256-uncased, Dataset: squad_v2\n"
     ]
    }
   ],
   "source": [
    "# Insert your group number here and print your assigned model data set combination\n",
    "group_number = 14 # insert your group number\n",
    "model_name, dataset_name = get_model_dataset_combination(group_number)\n",
    "print(f\"Model: {model_name}, Dataset: {dataset_name}\")\n",
    "# Insert the link from the linked GitHub similar to the provided example to retrieve the data\n",
    "dataset = load_dataset('squad_v2')\n",
    "data_train = dataset['train']\n",
    "data_dev = dataset['validation']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "N8j90Dh7PfKN",
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27c90a7f16fe8b7971b9e94b19a4afc5",
     "grade": false,
     "grade_id": "cell-3a05d1c268ba2e10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is how your dataset should look like:\n",
    "expected = [{\n",
    "    \"answers\": {\n",
    "        \"answer_start\": [1],\n",
    "        \"text\": [\"This is a test text\"]\n",
    "    },\n",
    "    \"context\": \"This is a test context.\",\n",
    "    \"id\": \"1\",\n",
    "    \"question\": \"Is this a test?\",\n",
    "},...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "VQlydod_PfKO",
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "572cd3abd0c7b71740d54bb38e2ad5db",
     "grade": true,
     "grade_id": "cell-f1a5e59e0791f430",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tests - Don't modify\n",
    "assert data_train.split == \"train\"\n",
    "assert data_dev.split == \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "fJqzVZgQPfKO",
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ed2b73a6158590b91d6aae6d9de25a0",
     "grade": true,
     "grade_id": "cell-0dee56fbdf79a9db",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "64687bc8-8d20-4474-96c9-043c2328e174",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "{'id': '56bf6b0f3aeaaa14008c9604', 'title': 'Beyoncé', 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".', 'question': 'What album made her a worldwide known artist?', 'answers': {'text': ['Dangerously in Love'], 'answer_start': [505]}}\n",
      "{'id': '5ad39d53604f3c001a3fe8d2', 'title': 'Normans', 'context': 'The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.', 'question': 'What is France a region of?', 'answers': {'text': [], 'answer_start': []}}\n"
     ]
    }
   ],
   "source": [
    "# Tests - Don't modify\n",
    "import random\n",
    "idx = random.randint(0, 10)\n",
    "print(idx)\n",
    "print(data_train[idx])\n",
    "print(data_dev[idx])\n",
    "assert isinstance(data_train[idx]['context'], str)\n",
    "assert isinstance(data_train[idx]['id'], str)\n",
    "assert isinstance(data_train[idx]['question'], str)\n",
    "assert isinstance(data_dev[idx]['answers']['text'], list)\n",
    "assert isinstance(data_dev[idx]['answers']['answer_start'], list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbe058f85da5a885a39e9b32c3f8107d",
     "grade": false,
     "grade_id": "cell-d6be14507c418609",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Save the data into a JSON file and remove the questions where no answer is given.\n",
    "\n",
    "*Hint:* You might want to have a look at the `json.dumps` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "id": "D8ging4tPfKO",
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cab9fd4c1d60a13aa631f1cc2dde4b86",
     "grade": false,
     "grade_id": "cell-04d882e4794a58c7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_json(dataset: List[Dict[str, Any]], path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the right input format for the transformer model as json file.\n",
    "    \n",
    "    The data should be saved as a JSON. In the format of:\n",
    "        {\n",
    "        'data': [\n",
    "            {\n",
    "                \"answers\": {\n",
    "                    \"answer_start\": [1],\n",
    "                    \"text\": [\"This is a test text\"]\n",
    "                },\n",
    "                \"context\": \"This is a test context.\",\n",
    "                \"id\": \"1\",\n",
    "                \"question\": \"Is this a test?\",\n",
    "            },\n",
    "            {...},\n",
    "            ...\n",
    "        ]\n",
    "        }\n",
    "    :param dataset (List[Dict[str, Any]]): The list of input data to be saved to the file.\n",
    "    :param path (str): The path of the json file to save the data to.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dataset_list = [dataset[i] for i in range(len(dataset))]\n",
    "    with open(path, 'w', encoding='utf-8') as file:\n",
    "        # Use json.dump to write the data to a file, ensuring it's readable\n",
    "        json.dump({'data': dataset_list}, file, indent=2)\n",
    "\n",
    "save_json(data_train, 'train_file.json')\n",
    "save_json(data_dev, 'dev_file.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "oCSjzK_VPfKO",
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2de95451a3a96d243925b9e51266427d",
     "grade": true,
     "grade_id": "cell-c6de7086aa97cc05",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tests - Don't modify\n",
    "assert [f for f in os.listdir() if re.match('train_file.json', f)]\n",
    "assert [f for f in os.listdir() if re.match('dev_file.json', f)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ieSW0zsrPfKP",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "332b8f79e434a70e74ca968042c4054c",
     "grade": false,
     "grade_id": "cell-2c95945bb0eb5604",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "b) For training your model you need to adapt the following script and execute it. This should take less than 1 hour on Google Colab with a GPU.\n",
    "\n",
    "Hint: You are working directories of Google Colab, make sure you always use the right paths and a GPU for training. **(1p)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "id": "zo1xVy5uPfKP",
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8bbce0279a34a58952370dddd4003ba",
     "grade": false,
     "grade_id": "cell-d316e6b151a2f708",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define your script variables here\n",
    "MODEL_NAME = \"microsoft/xtremedistil-l6-h256-uncased\" # The one you where assigned from the function `get_model_dataset_combination`\n",
    "TRAIN_FILE_NAME = 'train_file.json' # The file name of the train file\n",
    "EVAL_FILE_NAME ='dev_file.json' # The file name of the eval file\n",
    "# # YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "nxZUcUHVPfKP",
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88bc4c05d478a3b77dc99129e0fd953a",
     "grade": true,
     "grade_id": "cell-24cb3799b1b7f3e6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tests - Don't modify\n",
    "assert re.search('train_file.json', TRAIN_FILE_NAME)\n",
    "assert re.search('dev_file.json', EVAL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "LT3ux_IYPfKP",
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c085a7146c304fded37cfc5d2309db2",
     "grade": false,
     "grade_id": "cell-30a36f6cbda7f076",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "c4119b3b-5156-4736-95dd-34b19becc00e",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/06/2024 23:07:00 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "02/06/2024 23:07:00 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=3e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./tmp/result/runs/Feb06_23-06-59_desktop1,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=2.0,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "output_dir=./tmp/result/,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=12,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./tmp/result/,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "02/06/2024 23:07:00 - INFO - __main__ - Checkpoint detected, resuming training at ./tmp/result/checkpoint-21500. To avoid this behavior, change the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\n",
      "Using custom data configuration default-071a1b4d7d319269\n",
      "02/06/2024 23:07:00 - INFO - datasets.builder - Using custom data configuration default-071a1b4d7d319269\n",
      "Loading Dataset Infos from /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages/datasets/packaged_modules/json\n",
      "02/06/2024 23:07:00 - INFO - datasets.info - Loading Dataset Infos from /home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "02/06/2024 23:07:00 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /home/jan/.cache/huggingface/datasets/json/default-071a1b4d7d319269/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "02/06/2024 23:07:00 - INFO - datasets.info - Loading Dataset info from /home/jan/.cache/huggingface/datasets/json/default-071a1b4d7d319269/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Found cached dataset json (/home/jan/.cache/huggingface/datasets/json/default-071a1b4d7d319269/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "02/06/2024 23:07:00 - INFO - datasets.builder - Found cached dataset json (/home/jan/.cache/huggingface/datasets/json/default-071a1b4d7d319269/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from /home/jan/.cache/huggingface/datasets/json/default-071a1b4d7d319269/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "02/06/2024 23:07:00 - INFO - datasets.info - Loading Dataset info from /home/jan/.cache/huggingface/datasets/json/default-071a1b4d7d319269/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "[INFO|configuration_utils.py:729] 2024-02-06 23:07:01,086 >> loading configuration file config.json from cache at /home/jan/.cache/huggingface/hub/models--microsoft--xtremedistil-l6-h256-uncased/snapshots/8d58f0e6e83c1ab87f88d8c556ec537a111e2ee0/config.json\n",
      "[INFO|configuration_utils.py:792] 2024-02-06 23:07:01,096 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"microsoft/xtremedistil-l6-h256-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.38.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:607] 2024-02-06 23:07:01,240 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:729] 2024-02-06 23:07:01,408 >> loading configuration file config.json from cache at /home/jan/.cache/huggingface/hub/models--microsoft--xtremedistil-l6-h256-uncased/snapshots/8d58f0e6e83c1ab87f88d8c556ec537a111e2ee0/config.json\n",
      "[INFO|configuration_utils.py:792] 2024-02-06 23:07:01,409 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"microsoft/xtremedistil-l6-h256-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.38.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2029] 2024-02-06 23:07:01,960 >> loading file vocab.txt from cache at /home/jan/.cache/huggingface/hub/models--microsoft--xtremedistil-l6-h256-uncased/snapshots/8d58f0e6e83c1ab87f88d8c556ec537a111e2ee0/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:2029] 2024-02-06 23:07:01,960 >> loading file tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2029] 2024-02-06 23:07:01,960 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2029] 2024-02-06 23:07:01,960 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2029] 2024-02-06 23:07:01,960 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:729] 2024-02-06 23:07:01,961 >> loading configuration file config.json from cache at /home/jan/.cache/huggingface/hub/models--microsoft--xtremedistil-l6-h256-uncased/snapshots/8d58f0e6e83c1ab87f88d8c556ec537a111e2ee0/config.json\n",
      "[INFO|configuration_utils.py:792] 2024-02-06 23:07:01,961 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"microsoft/xtremedistil-l6-h256-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.38.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:729] 2024-02-06 23:07:01,987 >> loading configuration file config.json from cache at /home/jan/.cache/huggingface/hub/models--microsoft--xtremedistil-l6-h256-uncased/snapshots/8d58f0e6e83c1ab87f88d8c556ec537a111e2ee0/config.json\n",
      "[INFO|configuration_utils.py:792] 2024-02-06 23:07:01,987 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"microsoft/xtremedistil-l6-h256-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.38.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3259] 2024-02-06 23:07:02,043 >> loading weights file pytorch_model.bin from cache at /home/jan/.cache/huggingface/hub/models--microsoft--xtremedistil-l6-h256-uncased/snapshots/8d58f0e6e83c1ab87f88d8c556ec537a111e2ee0/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:3982] 2024-02-06 23:07:02,062 >> Some weights of the model checkpoint at microsoft/xtremedistil-l6-h256-uncased were not used when initializing BertForQuestionAnswering: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:3994] 2024-02-06 23:07:02,063 >> Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at microsoft/xtremedistil-l6-h256-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading cached processed dataset at /home/jan/.cache/huggingface/datasets/json/default-071a1b4d7d319269/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-977618506737a466.arrow\n",
      "02/06/2024 23:07:02 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/jan/.cache/huggingface/datasets/json/default-071a1b4d7d319269/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-977618506737a466.arrow\n",
      "Loading cached processed dataset at /home/jan/.cache/huggingface/datasets/json/default-071a1b4d7d319269/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-73eb858302c43589.arrow\n",
      "02/06/2024 23:07:02 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/jan/.cache/huggingface/datasets/json/default-071a1b4d7d319269/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-73eb858302c43589.arrow\n",
      "[INFO|trainer.py:2104] 2024-02-06 23:07:04,513 >> Loading model from ./tmp/result/checkpoint-21500.\n",
      "[INFO|trainer.py:1747] 2024-02-06 23:07:04,661 >> ***** Running training *****\n",
      "[INFO|trainer.py:1748] 2024-02-06 23:07:04,661 >>   Num examples = 131,754\n",
      "[INFO|trainer.py:1749] 2024-02-06 23:07:04,661 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:1750] 2024-02-06 23:07:04,661 >>   Instantaneous batch size per device = 12\n",
      "[INFO|trainer.py:1753] 2024-02-06 23:07:04,661 >>   Total train batch size (w. parallel, distributed & accumulation) = 12\n",
      "[INFO|trainer.py:1754] 2024-02-06 23:07:04,661 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1755] 2024-02-06 23:07:04,661 >>   Total optimization steps = 21,960\n",
      "[INFO|trainer.py:1756] 2024-02-06 23:07:04,662 >>   Number of trainable parameters = 12,684,802\n",
      "[INFO|trainer.py:1776] 2024-02-06 23:07:04,662 >>   Continuing training from checkpoint, will skip to saved global_step\n",
      "[INFO|trainer.py:1777] 2024-02-06 23:07:04,662 >>   Continuing training from epoch 1\n",
      "[INFO|trainer.py:1778] 2024-02-06 23:07:04,662 >>   Continuing training from global step 21500\n",
      "[INFO|trainer.py:1780] 2024-02-06 23:07:04,662 >>   Will skip the first 1 epochs then the first 10520 batches in the first epoch.\n",
      "100%|███████████████████████████████████▉| 21906/21960 [00:30<00:00, 349.80it/s][INFO|trainer.py:1988] 2024-02-06 23:07:38,774 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 34.1144, 'train_samples_per_second': 7724.242, 'train_steps_per_second': 643.716, 'train_loss': 0.033168413339416836, 'epoch': 2.0}\n",
      "100%|████████████████████████████████████| 21960/21960 [00:34<00:00, 643.73it/s]\n",
      "[INFO|trainer.py:2981] 2024-02-06 23:07:38,777 >> Saving model checkpoint to ./tmp/result/\n",
      "[INFO|configuration_utils.py:473] 2024-02-06 23:07:38,778 >> Configuration saved in ./tmp/result/config.json\n",
      "[INFO|modeling_utils.py:2454] 2024-02-06 23:07:38,907 >> Model weights saved in ./tmp/result/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2435] 2024-02-06 23:07:38,907 >> tokenizer config file saved in ./tmp/result/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2444] 2024-02-06 23:07:38,907 >> Special tokens file saved in ./tmp/result/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        2.0\n",
      "  train_loss               =     0.0332\n",
      "  train_runtime            = 0:00:34.11\n",
      "  train_samples            =     131754\n",
      "  train_samples_per_second =   7724.242\n",
      "  train_steps_per_second   =    643.716\n",
      "02/06/2024 23:07:38 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:737] 2024-02-06 23:07:38,916 >> The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:3287] 2024-02-06 23:07:38,916 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3289] 2024-02-06 23:07:38,917 >>   Num examples = 12134\n",
      "[INFO|trainer.py:3292] 2024-02-06 23:07:38,917 >>   Batch size = 8\n",
      "100%|██████████████████████████████████████▉| 1513/1517 [00:30<00:00, 50.21it/s]02/06/2024 23:08:16 - INFO - utils_qa - Post-processing 11873 example predictions split into 12134 features.\n",
      "\n",
      "  0%|                                                 | 0/11873 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏                                      | 68/11873 [00:00<00:17, 672.37it/s]\u001b[A\n",
      "  1%|▍                                     | 142/11873 [00:00<00:16, 706.70it/s]\u001b[A\n",
      "  2%|▋                                     | 220/11873 [00:00<00:15, 736.01it/s]\u001b[A\n",
      "  3%|▉                                     | 297/11873 [00:00<00:15, 749.05it/s]\u001b[A\n",
      "  3%|█▏                                    | 373/11873 [00:00<00:15, 751.50it/s]\u001b[A\n",
      "  4%|█▍                                    | 451/11873 [00:00<00:15, 759.35it/s]\u001b[A\n",
      "  4%|█▋                                    | 528/11873 [00:00<00:14, 761.35it/s]\u001b[A\n",
      "  5%|█▉                                    | 605/11873 [00:00<00:14, 759.77it/s]\u001b[A\n",
      "  6%|██▏                                   | 683/11873 [00:00<00:14, 764.80it/s]\u001b[A\n",
      "  6%|██▍                                   | 760/11873 [00:01<00:14, 755.76it/s]\u001b[A\n",
      "  7%|██▋                                   | 838/11873 [00:01<00:14, 762.20it/s]\u001b[A\n",
      "  8%|██▉                                   | 918/11873 [00:01<00:14, 772.24it/s]\u001b[A\n",
      "  8%|███▏                                  | 996/11873 [00:01<00:14, 772.06it/s]\u001b[A\n",
      "  9%|███▎                                 | 1074/11873 [00:01<00:14, 763.15it/s]\u001b[A\n",
      " 10%|███▌                                 | 1151/11873 [00:01<00:14, 752.92it/s]\u001b[A\n",
      " 10%|███▊                                 | 1227/11873 [00:01<00:14, 751.36it/s]\u001b[A\n",
      " 11%|████                                 | 1303/11873 [00:01<00:14, 748.08it/s]\u001b[A\n",
      " 12%|████▎                                | 1379/11873 [00:01<00:13, 749.98it/s]\u001b[A\n",
      " 12%|████▌                                | 1455/11873 [00:01<00:13, 749.72it/s]\u001b[A\n",
      " 13%|████▊                                | 1530/11873 [00:02<00:13, 748.09it/s]\u001b[A\n",
      " 14%|█████                                | 1605/11873 [00:02<00:13, 746.13it/s]\u001b[A\n",
      " 14%|█████▏                               | 1680/11873 [00:02<00:13, 738.41it/s]\u001b[A\n",
      " 15%|█████▍                               | 1754/11873 [00:02<00:13, 736.32it/s]\u001b[A\n",
      " 15%|█████▋                               | 1828/11873 [00:02<00:13, 730.74it/s]\u001b[A\n",
      " 16%|█████▉                               | 1903/11873 [00:02<00:13, 734.25it/s]\u001b[A\n",
      " 17%|██████▏                              | 1978/11873 [00:02<00:13, 738.70it/s]\u001b[A\n",
      " 17%|██████▍                              | 2053/11873 [00:02<00:13, 741.47it/s]\u001b[A\n",
      " 18%|██████▋                              | 2128/11873 [00:02<00:13, 735.28it/s]\u001b[A\n",
      " 19%|██████▊                              | 2202/11873 [00:02<00:13, 735.27it/s]\u001b[A\n",
      " 19%|███████                              | 2276/11873 [00:03<00:13, 736.45it/s]\u001b[A\n",
      " 20%|███████▎                             | 2350/11873 [00:03<00:12, 735.41it/s]\u001b[A\n",
      " 20%|███████▌                             | 2424/11873 [00:03<00:12, 734.32it/s]\u001b[A\n",
      " 21%|███████▊                             | 2498/11873 [00:03<00:12, 730.62it/s]\u001b[A\n",
      " 22%|████████                             | 2573/11873 [00:03<00:12, 735.36it/s]\u001b[A\n",
      " 22%|████████▏                            | 2647/11873 [00:03<00:12, 735.85it/s]\u001b[A\n",
      " 23%|████████▍                            | 2721/11873 [00:03<00:12, 735.89it/s]\u001b[A\n",
      " 24%|████████▋                            | 2795/11873 [00:03<00:12, 730.49it/s]\u001b[A\n",
      " 24%|████████▉                            | 2871/11873 [00:03<00:12, 737.90it/s]\u001b[A\n",
      " 25%|█████████▏                           | 2945/11873 [00:03<00:12, 732.59it/s]\u001b[A\n",
      " 25%|█████████▍                           | 3019/11873 [00:04<00:12, 719.18it/s]\u001b[A\n",
      " 26%|█████████▋                           | 3091/11873 [00:04<00:12, 697.08it/s]\u001b[A\n",
      " 27%|█████████▊                           | 3161/11873 [00:04<00:14, 585.64it/s]\u001b[A\n",
      " 27%|██████████                           | 3233/11873 [00:04<00:13, 618.83it/s]\u001b[A\n",
      "100%|███████████████████████████████████████| 1517/1517 [00:41<00:00, 50.21it/s]\u001b[A\n",
      " 28%|██████████▍                          | 3355/11873 [00:04<00:18, 449.83it/s]\u001b[A\n",
      " 29%|██████████▋                          | 3412/11873 [00:04<00:17, 476.11it/s]\u001b[A\n",
      " 29%|██████████▊                          | 3486/11873 [00:05<00:15, 538.50it/s]\u001b[A\n",
      " 30%|███████████                          | 3561/11873 [00:05<00:14, 591.63it/s]\u001b[A\n",
      " 31%|███████████▎                         | 3629/11873 [00:05<00:13, 614.67it/s]\u001b[A\n",
      " 31%|███████████▌                         | 3700/11873 [00:05<00:12, 639.28it/s]\u001b[A\n",
      " 32%|███████████▊                         | 3777/11873 [00:05<00:12, 674.02it/s]\u001b[A\n",
      " 32%|███████████▉                         | 3847/11873 [00:05<00:11, 670.20it/s]\u001b[A\n",
      " 33%|████████████▏                        | 3917/11873 [00:05<00:11, 676.81it/s]\u001b[A\n",
      " 34%|████████████▍                        | 3988/11873 [00:05<00:11, 685.46it/s]\u001b[A\n",
      " 34%|████████████▋                        | 4070/11873 [00:05<00:10, 724.14it/s]\u001b[A\n",
      " 35%|████████████▉                        | 4145/11873 [00:05<00:10, 728.12it/s]\u001b[A\n",
      " 36%|█████████████▏                       | 4219/11873 [00:06<00:10, 712.24it/s]\u001b[A\n",
      " 36%|█████████████▍                       | 4301/11873 [00:06<00:10, 742.24it/s]\u001b[A\n",
      " 37%|█████████████▋                       | 4382/11873 [00:06<00:09, 761.12it/s]\u001b[A\n",
      " 38%|█████████████▉                       | 4459/11873 [00:06<00:10, 682.13it/s]\u001b[A\n",
      " 38%|██████████████▏                      | 4537/11873 [00:06<00:10, 707.15it/s]\u001b[A\n",
      " 39%|██████████████▍                      | 4618/11873 [00:06<00:09, 733.27it/s]\u001b[A\n",
      " 40%|██████████████▋                      | 4697/11873 [00:06<00:09, 746.73it/s]\u001b[A\n",
      " 40%|██████████████▉                      | 4775/11873 [00:06<00:09, 753.77it/s]\u001b[A\n",
      " 41%|███████████████                      | 4851/11873 [00:06<00:09, 748.41it/s]\u001b[A\n",
      " 42%|███████████████▎                     | 4929/11873 [00:06<00:09, 757.45it/s]\u001b[A\n",
      " 42%|███████████████▌                     | 5007/11873 [00:07<00:09, 762.12it/s]\u001b[A\n",
      " 43%|███████████████▊                     | 5085/11873 [00:07<00:08, 765.54it/s]\u001b[A\n",
      " 44%|████████████████                     | 5165/11873 [00:07<00:08, 775.46it/s]\u001b[A\n",
      " 44%|████████████████▎                    | 5245/11873 [00:07<00:08, 781.92it/s]\u001b[A\n",
      " 45%|████████████████▌                    | 5324/11873 [00:07<00:08, 750.28it/s]\u001b[A\n",
      " 46%|████████████████▊                    | 5404/11873 [00:07<00:08, 763.37it/s]\u001b[A\n",
      " 46%|█████████████████                    | 5482/11873 [00:07<00:08, 767.96it/s]\u001b[A\n",
      " 47%|█████████████████▎                   | 5562/11873 [00:07<00:08, 775.87it/s]\u001b[A\n",
      " 48%|█████████████████▌                   | 5640/11873 [00:07<00:08, 764.20it/s]\u001b[A\n",
      " 48%|█████████████████▊                   | 5717/11873 [00:07<00:08, 764.08it/s]\u001b[A\n",
      " 49%|██████████████████                   | 5795/11873 [00:08<00:07, 768.19it/s]\u001b[A\n",
      " 49%|██████████████████▎                  | 5876/11873 [00:08<00:07, 780.47it/s]\u001b[A\n",
      " 50%|██████████████████▌                  | 5956/11873 [00:08<00:07, 785.67it/s]\u001b[A\n",
      " 51%|██████████████████▊                  | 6037/11873 [00:08<00:07, 791.64it/s]\u001b[A\n",
      " 52%|███████████████████                  | 6117/11873 [00:08<00:07, 787.62it/s]\u001b[A\n",
      " 52%|███████████████████▎                 | 6197/11873 [00:08<00:07, 789.20it/s]\u001b[A\n",
      " 53%|███████████████████▌                 | 6278/11873 [00:08<00:07, 792.94it/s]\u001b[A\n",
      " 54%|███████████████████▊                 | 6358/11873 [00:08<00:06, 792.80it/s]\u001b[A\n",
      " 54%|████████████████████                 | 6438/11873 [00:08<00:06, 782.10it/s]\u001b[A\n",
      " 55%|████████████████████▎                | 6517/11873 [00:09<00:06, 776.73it/s]\u001b[A\n",
      " 56%|████████████████████▌                | 6595/11873 [00:09<00:06, 774.44it/s]\u001b[A\n",
      " 56%|████████████████████▊                | 6676/11873 [00:09<00:06, 782.03it/s]\u001b[A\n",
      " 57%|█████████████████████                | 6755/11873 [00:09<00:07, 731.09it/s]\u001b[A\n",
      " 58%|█████████████████████▎               | 6832/11873 [00:09<00:06, 740.58it/s]\u001b[A\n",
      " 58%|█████████████████████▌               | 6909/11873 [00:09<00:06, 748.37it/s]\u001b[A\n",
      " 59%|█████████████████████▊               | 6988/11873 [00:09<00:06, 758.01it/s]\u001b[A\n",
      " 60%|██████████████████████               | 7066/11873 [00:09<00:06, 764.07it/s]\u001b[A\n",
      " 60%|██████████████████████▎              | 7146/11873 [00:09<00:06, 773.35it/s]\u001b[A\n",
      " 61%|██████████████████████▌              | 7225/11873 [00:09<00:05, 775.75it/s]\u001b[A\n",
      " 62%|██████████████████████▊              | 7303/11873 [00:10<00:05, 773.09it/s]\u001b[A\n",
      " 62%|███████████████████████              | 7381/11873 [00:10<00:05, 774.64it/s]\u001b[A\n",
      " 63%|███████████████████████▏             | 7459/11873 [00:10<00:05, 767.94it/s]\u001b[A\n",
      " 64%|███████████████████████▌             | 7541/11873 [00:10<00:05, 781.94it/s]\u001b[A\n",
      " 64%|███████████████████████▋             | 7620/11873 [00:10<00:05, 776.96it/s]\u001b[A\n",
      " 65%|███████████████████████▉             | 7698/11873 [00:10<00:05, 768.86it/s]\u001b[A\n",
      " 65%|████████████████████████▏            | 7775/11873 [00:10<00:05, 758.12it/s]\u001b[A\n",
      " 66%|████████████████████████▍            | 7851/11873 [00:10<00:05, 747.70it/s]\u001b[A\n",
      " 67%|████████████████████████▋            | 7926/11873 [00:10<00:05, 723.86it/s]\u001b[A\n",
      " 67%|████████████████████████▉            | 8004/11873 [00:10<00:05, 737.97it/s]\u001b[A\n",
      " 68%|█████████████████████████▏           | 8084/11873 [00:11<00:05, 753.80it/s]\u001b[A\n",
      " 69%|█████████████████████████▍           | 8162/11873 [00:11<00:04, 759.78it/s]\u001b[A\n",
      " 69%|█████████████████████████▋           | 8239/11873 [00:11<00:04, 757.62it/s]\u001b[A\n",
      " 70%|█████████████████████████▉           | 8320/11873 [00:11<00:04, 772.30it/s]\u001b[A\n",
      " 71%|██████████████████████████▏          | 8399/11873 [00:11<00:04, 775.33it/s]\u001b[A\n",
      " 71%|██████████████████████████▍          | 8477/11873 [00:11<00:04, 758.62it/s]\u001b[A\n",
      " 72%|██████████████████████████▋          | 8556/11873 [00:11<00:04, 766.32it/s]\u001b[A\n",
      " 73%|██████████████████████████▉          | 8633/11873 [00:11<00:04, 767.16it/s]\u001b[A\n",
      " 73%|███████████████████████████▏         | 8713/11873 [00:11<00:04, 774.79it/s]\u001b[A\n",
      " 74%|███████████████████████████▍         | 8792/11873 [00:11<00:03, 778.24it/s]\u001b[A\n",
      " 75%|███████████████████████████▋         | 8870/11873 [00:12<00:03, 777.03it/s]\u001b[A\n",
      " 75%|███████████████████████████▉         | 8948/11873 [00:12<00:03, 774.19it/s]\u001b[A\n",
      " 76%|████████████████████████████▏        | 9027/11873 [00:12<00:03, 777.90it/s]\u001b[A\n",
      " 77%|████████████████████████████▍        | 9106/11873 [00:12<00:03, 781.05it/s]\u001b[A\n",
      " 77%|████████████████████████████▌        | 9185/11873 [00:12<00:03, 782.02it/s]\u001b[A\n",
      " 78%|████████████████████████████▊        | 9264/11873 [00:12<00:03, 781.63it/s]\u001b[A\n",
      " 79%|█████████████████████████████        | 9343/11873 [00:12<00:03, 778.96it/s]\u001b[A\n",
      " 79%|█████████████████████████████▎       | 9422/11873 [00:12<00:03, 779.61it/s]\u001b[A\n",
      " 80%|█████████████████████████████▌       | 9500/11873 [00:12<00:03, 767.50it/s]\u001b[A\n",
      " 81%|█████████████████████████████▊       | 9577/11873 [00:13<00:03, 764.73it/s]\u001b[A\n",
      " 81%|██████████████████████████████       | 9655/11873 [00:13<00:02, 766.79it/s]\u001b[A\n",
      " 82%|██████████████████████████████▎      | 9736/11873 [00:13<00:02, 778.37it/s]\u001b[A\n",
      " 83%|██████████████████████████████▌      | 9814/11873 [00:13<00:02, 778.14it/s]\u001b[A\n",
      " 83%|██████████████████████████████▊      | 9894/11873 [00:13<00:02, 783.97it/s]\u001b[A\n",
      " 84%|███████████████████████████████      | 9974/11873 [00:13<00:02, 787.14it/s]\u001b[A\n",
      " 85%|██████████████████████████████▍     | 10055/11873 [00:13<00:02, 793.02it/s]\u001b[A\n",
      " 85%|██████████████████████████████▋     | 10135/11873 [00:13<00:02, 792.58it/s]\u001b[A\n",
      " 86%|██████████████████████████████▉     | 10215/11873 [00:13<00:02, 788.83it/s]\u001b[A\n",
      " 87%|███████████████████████████████▏    | 10294/11873 [00:13<00:02, 781.81it/s]\u001b[A\n",
      " 87%|███████████████████████████████▍    | 10373/11873 [00:14<00:01, 783.19it/s]\u001b[A\n",
      " 88%|███████████████████████████████▋    | 10452/11873 [00:14<00:01, 774.68it/s]\u001b[A\n",
      " 89%|███████████████████████████████▉    | 10532/11873 [00:14<00:01, 782.15it/s]\u001b[A\n",
      " 89%|████████████████████████████████▏   | 10611/11873 [00:14<00:01, 775.06it/s]\u001b[A\n",
      " 90%|████████████████████████████████▍   | 10689/11873 [00:14<00:01, 764.56it/s]\u001b[A\n",
      " 91%|████████████████████████████████▋   | 10766/11873 [00:14<00:01, 765.41it/s]\u001b[A\n",
      " 91%|████████████████████████████████▉   | 10843/11873 [00:14<00:01, 760.47it/s]\u001b[A\n",
      " 92%|█████████████████████████████████   | 10920/11873 [00:14<00:01, 761.31it/s]\u001b[A\n",
      " 93%|█████████████████████████████████▎  | 10998/11873 [00:14<00:01, 766.28it/s]\u001b[A\n",
      " 93%|█████████████████████████████████▌  | 11079/11873 [00:14<00:01, 778.53it/s]\u001b[A\n",
      " 94%|█████████████████████████████████▊  | 11159/11873 [00:15<00:00, 784.26it/s]\u001b[A\n",
      " 95%|██████████████████████████████████  | 11239/11873 [00:15<00:00, 786.13it/s]\u001b[A\n",
      " 95%|██████████████████████████████████▎ | 11318/11873 [00:15<00:00, 784.62it/s]\u001b[A\n",
      " 96%|██████████████████████████████████▌ | 11397/11873 [00:15<00:00, 784.71it/s]\u001b[A\n",
      " 97%|██████████████████████████████████▊ | 11476/11873 [00:15<00:00, 783.26it/s]\u001b[A\n",
      " 97%|███████████████████████████████████ | 11555/11873 [00:15<00:00, 769.39it/s]\u001b[A\n",
      " 98%|███████████████████████████████████▎| 11632/11873 [00:15<00:00, 769.12it/s]\u001b[A\n",
      " 99%|███████████████████████████████████▌| 11709/11873 [00:15<00:00, 753.09it/s]\u001b[A\n",
      " 99%|███████████████████████████████████▋| 11789/11873 [00:15<00:00, 766.52it/s]\u001b[A\n",
      "100%|████████████████████████████████████| 11873/11873 [00:15<00:00, 743.76it/s]\u001b[A\n",
      "02/06/2024 23:08:32 - INFO - utils_qa - Saving predictions to ./tmp/result/eval_predictions.json.\n",
      "02/06/2024 23:08:32 - INFO - utils_qa - Saving nbest_preds to ./tmp/result/eval_nbest_predictions.json.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jan/Projects/NLP4Web/Homework 6/transformers/examples/pytorch/question-answering/run_qa.py\", line 716, in <module>\n",
      "    main()\n",
      "  File \"/home/jan/Projects/NLP4Web/Homework 6/transformers/examples/pytorch/question-answering/run_qa.py\", line 673, in main\n",
      "    metrics = trainer.evaluate()\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jan/Projects/NLP4Web/Homework 6/transformers/examples/pytorch/question-answering/trainer_qa.py\", line 72, in evaluate\n",
      "    metrics = self.compute_metrics(eval_preds)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jan/Projects/NLP4Web/Homework 6/transformers/examples/pytorch/question-answering/run_qa.py\", line 635, in compute_metrics\n",
      "    return metric.compute(predictions=p.predictions, references=p.label_ids)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jan/Projects/NLP4Web/venv/lib/python3.11/site-packages/evaluate/module.py\", line 462, in compute\n",
      "    output = self._compute(**inputs, **compute_kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jan/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--squad/b4e2dbca455821c7367faa26712f378254b69040ebaab90b64bdeb465e4a304d/squad.py\", line 110, in _compute\n",
      "    score = compute_score(dataset=dataset, predictions=pred_dict)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jan/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--squad/b4e2dbca455821c7367faa26712f378254b69040ebaab90b64bdeb465e4a304d/compute_score.py\", line 67, in compute_score\n",
      "    exact_match += metric_max_over_ground_truths(exact_match_score, prediction, ground_truths)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jan/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--squad/b4e2dbca455821c7367faa26712f378254b69040ebaab90b64bdeb465e4a304d/compute_score.py\", line 52, in metric_max_over_ground_truths\n",
      "    return max(scores_for_ground_truths)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: max() arg is an empty sequence\n",
      "100%|███████████████████████████████████████| 1517/1517 [00:55<00:00, 27.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# Task: run the script\n",
    "!python transformers/examples/pytorch/question-answering/run_qa.py \\\n",
    "  --model_name_or_path $MODEL_NAME \\\n",
    "  --train_file $TRAIN_FILE_NAME \\\n",
    "  --validation_file $EVAL_FILE_NAME \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --per_device_train_batch_size 12 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --output_dir ./tmp/result/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "qktc-Lr0PfKP",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71ef8820bc48bf968b510ebd2e180630",
     "grade": false,
     "grade_id": "cell-b013aff665a537c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "**c) To make the model available for other researchers you need to deploy it to the [Hugging Face Model Hub](https://huggingface.co/models). Don't forget to upload your tokenizer alongside the model. Insert the link of your deployed model as an answer for this task.**  **(1p)**\n",
    "\n",
    "Hint: You will need to create an account on Hugging Face and create a [repository](https://huggingface.co/new). \n",
    "\n",
    "**IMPORTANT:** Make the repository **public**!!! Save your model name in the variable `your_model_name`. You'll find the model name on top of your model repository on Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "tAc_nJFPPfKP",
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8caffe908043947491d28409ce62e9ba",
     "grade": false,
     "grade_id": "cell-be478dceac7a7c92",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# insert the name of your shared model\n",
    "your_model_name = '' # The name from Hugging Face: `UserName/RepoName`\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "QDJv9Rx8PfKP",
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9ab3b44cf99e204f7e32d5846022391",
     "grade": true,
     "grade_id": "cell-bf02b5cbe1d35c61",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tests - Don't modify\n",
    "assert re.search(\"huggingface.co\", link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "kOPpJV3PPfKQ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ad48e0fda565e5992022789a66a20cd",
     "grade": false,
     "grade_id": "cell-56ba9e9b66a212de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Task 2: Analyze the model - 5 Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6IBqmrfDPfKQ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73a758b8cc9523b18e98ea22044e7143",
     "grade": false,
     "grade_id": "cell-55fc7071e7839462",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "In this task, you will analyze models with regard to different questions. You should state your findings clearly and traceable including examples. You are allowed to include screenshots in your answers to make your answers understandable. This task is independent of task 1. Please select one of the follwing models: `DROP BERT Adapter`, `Xtremedistil-L6-H256-Uncased-NaturalQuestionsShort`, `SQuAD 2.0 BERT Adapter`. They should be available on the SQuARE website in the [*QA Hub*](https://square.ukp-lab.de/qa_hub).\n",
    "\n",
    "Hint: In general it's not expected that you write full essays to answer the questions. Short and clear answers are preferred and sufficient to achieve full points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "le_tUTTIPfKQ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ebbd4e86377c655a85ab72ebbe151211",
     "grade": false,
     "grade_id": "cell-d8f0d9a5f13272cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "**a) Which type of questions is your selected model able to answer? How is this type different from at least one other type of questions you know from the lecture?\n",
    "Please state which model you choose.** **(1p)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "Ifqv3pguPfKQ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d30cbe728b44426a51f07dc6495bf30",
     "grade": true,
     "grade_id": "cell-5a7a2f5389710f38",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UkqniupVPfKQ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "042a0b8ec0fdc70fe33f170df61130b9",
     "grade": false,
     "grade_id": "cell-a59ea71a460055c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "**b) Analyze the general behavior of the model. Therefore run the model with different questions. Which type of questions is the model able to answer, and which are not? Interpret your results and provide examples for both.** **(2p)**\n",
    "\n",
    "Hint: It may help to compare the selected model to other models on the UKP-SQuARE platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "lCD29o6APfKR",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "785fe5e3c6c20935925c646043a8fe28",
     "grade": true,
     "grade_id": "cell-75563ba3314fecee",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5fdYJGrrPfKR",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb4b9581035de016defbfad47cebbb87",
     "grade": false,
     "grade_id": "cell-489ce64c65970eb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "**c) Now we want to formalize the results from above. Explain the concept behind in-domain and out-of-domain data. Analyze your results and categorize the found examples from b) respectively. Which performance would you expect if you run your selected model on a full in-domain and out-of-domain dataset based on the knowledge you gained so far?** **(2p)**\n",
    "\n",
    "Hint: This concept will be taught in the lecture QA II. It might also help to think about on what dataset the model was trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "I_EEIW3YPfKR",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21de815bdcfdccc9a59a4c8575f360fa",
     "grade": true,
     "grade_id": "cell-8fc722fbaac3a37b",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "n1DK61eZPfKR",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "571d0e63de9df5fa63475270e57919d6",
     "grade": false,
     "grade_id": "cell-cb2f72c02ad62572",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Task 3: Explainability - 6 Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UDvYC1X8PfKV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1ec178e495964d6c462a62ecfe44f48",
     "grade": false,
     "grade_id": "cell-346db9e086d97246",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "In this task, you will learn about the explainability of transformer-based models. For this purpose, saliency maps are a common method to visualize predictions in Deep Learning inspired by research in computer vision. In the NLP domain,  saliency maps attribute weights to every input token to assess the importance of the model prediction. The UKP-SQuARE platform provides two different family methods: gradient-based and attention-based.\n",
    "For learning more about it, you can read the following paper: https://aclanthology.org/2022.aacl-demo.4.pdf. or the respective Medium article https://medium.com/@ukp-square/interpreting-saliency-maps-for-question-a-with-ukp-square-a6b2831d8431.\n",
    "Both are not required to achieve full points on the tasks but help to understand the topics.\n",
    "\n",
    "Hint: You are highly encouraged to include screenshots to make your results understandable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4b3L9Gr0PfKW",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f1ae8c7ca46e42757994d88b6df3545",
     "grade": false,
     "grade_id": "cell-c578cac764f304e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "**a) Give a short introduction about why explainability is important in Deep Learning research? Because this is an NLP class, provide one example from the domain of NLP.** **(2p)**\n",
    "\n",
    "Hint: For the example, it's sufficient to think logically, it's not needed to cite papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "17JdkBsEPfKW",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f77d53ab8c22306151eef4bd69431157",
     "grade": true,
     "grade_id": "cell-da7422f87eb7a398",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4y16FpznPfKW",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "210c54ae2c52cfa3ea9f526ec08baabe",
     "grade": false,
     "grade_id": "cell-d6f06aa0800a2cf1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "**b) In this subtask we start to analyze the predictions from your selected model with the respective saliency maps. Find at least one method that explains the prediction from your selected model and describe and interpret your results.** **(2p)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "QkdpvAbkPfKW",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc65797886bacac481bd42f1df6ea7ec",
     "grade": true,
     "grade_id": "cell-714a5945fcec1a2d",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "GprqaKSnPfKW",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73fc32f734a2bee79f2773433c78ce78",
     "grade": false,
     "grade_id": "cell-4f12a95473ce9045",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "**c) Explain one method that doesn't explain the prediction from your model and interpret your results. Prove your result with at least one question.** **(2p)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "oOjCV91fPfKW",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93a99295d7d15d71de1b3bb2d4fe662b",
     "grade": true,
     "grade_id": "cell-96d50e6502d716a5",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "t_SVw7kdPfKW",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e380db55e3e42307eb7319ed88a312a3",
     "grade": false,
     "grade_id": "cell-6b9b4a8b15d99d07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Task 4: Attacking your model - 4 Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "lZ4mwUktPfKX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9291b2ea123a4f4755038817f96133c4",
     "grade": false,
     "grade_id": "cell-7f27c7bc20160152",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "In this task, you will learn about attacking your selected model.\n",
    "Therefore the UKP-SQuARE interface makes it easy to apply different input modifications to find vulnerabilities in the model. You will explore different attacking methods.\n",
    "For learning more about the attacking methods, you can read the following paper: https://aclanthology.org/2022.aacl-demo.4.pdf. or the respective Medium article https://medium.com/@ukp-square/interpreting-adversarial-attacks-in-question-answering-with-ukp-square-5f1866ade13c.\n",
    "Both are not required to achieve full points on the tasks but help to understand the topics.\n",
    "\n",
    "Hint: You are highly encouraged to include screenshots to make your results understandable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "kB9NauDKPfKX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1cba19a66efd887b736de32eab374b01",
     "grade": false,
     "grade_id": "cell-fa4a6aecbbf24153",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "**a) Identify whether and how your selected model can be fooled/hacked with the Input Reduction method. Interpret your findings in your own words.** **(1p)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "9O8aBmGxPfKX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "322ff214a0a6c79e65e612ebb9a8145a",
     "grade": true,
     "grade_id": "cell-3a63f63edf85abc7",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9fnx2Z9QPfKX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4a6d02ccefc580dafbbed4bc5d67f02",
     "grade": false,
     "grade_id": "cell-ee290e3f7770c31b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "**b) Identify whether and how your selected model can be fooled/hacked with the Sub-Span method. Interpret your findings in your own words.** **(1p)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "s_xrbthzPfKX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06bca055cc5c17ecdbcb1c43e33c6b60",
     "grade": true,
     "grade_id": "cell-8beb429ded55e08e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "JQpbljdhPfKX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcbd67eb5dd2bcadc01bef5251fde9d3",
     "grade": false,
     "grade_id": "cell-dca171c140217290",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "**c) Identify whether and how your selected model can be fooled/hacked with the Top K method. Interpret your findings in your own words.** **(1p)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "8ZzBLVuSPfKX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b070641065b4e8a9067ada71cf299caa",
     "grade": true,
     "grade_id": "cell-e2cf22c30823a3d1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "kTOQ8a79PfKc",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0cd98e0d37613a498b11eaebf0e2fb04",
     "grade": false,
     "grade_id": "cell-287dc38868273c81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "**d) Explain why it's interesting for you as a researcher to know how your selected model is attackable?** **(1p)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "TDbAIgUPN7zv",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e250e2880d33145b6933f0d8f128f37",
     "grade": true,
     "grade_id": "cell-c9990cd201d54481",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6dvalMM2jTUg",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4284833abcf1d3d2f84989bce4fd41e",
     "grade": false,
     "grade_id": "cell-f7e5db7b97dbedb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "**Submission:**\n",
    "\n",
    "Please upload your submission to Moodle before the next exercise session <font color=\"red\">(Feb 09th, 23:59)</font>!\n",
    "\n",
    "Submission format: `homework 6.zip`\n",
    "\n",
    "Your submission should contain your filled out Jupyter notebook (naming schema: `homework 6.ipynb`) and any auxiliar files that are necessary to run your code (e.g., the datasets provided by us).\n",
    "\n",
    "Each submission must be handed in only once per group."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
