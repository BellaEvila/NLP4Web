{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da5064c9ed8cd1fec0f36b714c345b0b",
     "grade": false,
     "grade_id": "cell-4d87ae78fb4caf9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# NLP and the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1145e2ba69b3e56620106550f0984e0",
     "grade": false,
     "grade_id": "cell-8b531762670192f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 0 ~ 0P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d4cef5c9a404a5516183e6ce9bf2128",
     "grade": false,
     "grade_id": "cell-6eca7b6c6c224dde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### a) Please enter your group number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75470a4986487fdb40d73fa368335c95",
     "grade": true,
     "grade_id": "cell-cccfbf605a28a18a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a760dcd98f5ea360c504ee7fd50a4088",
     "grade": false,
     "grade_id": "cell-2ed8ca1b9e5204c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "_**Regarding types, documentation, and output:**_\n",
    "\n",
    "_We tried to make the description of the parameters as clear as possible. However, if you believe that something is missing, please reach out to us in Moodle. We provide type hints for the function parameters and return values of the functions that you have to implement._\n",
    "\n",
    "_Nevertheless, your code must use the provided method stubs and parameters. Furthermore, make sure that your code runs without errors and in a reasonable amount of time, for example by using \"Kernel/Restart & Run All\" before submitting._\n",
    "\n",
    "_Please use comments where appropriate to help the tutors understand your code. This is especially important for the more extensive exercises later on. Finally, please pay attention to how you output the results. We highly recommend using `display(df)` for displaying data frames._\n",
    "\n",
    "_**Please only modify the template in the specified markdown and code cells (e.g. YOUR CODE / ANSWER / IMPORTS HERE). If you add any extra cells, they wont be taken into account while grading!  Some cells are left blank on purpose. Please do not modify these cells, because they are used to autograde your submission. If these cells are modified, the automatic grading for your submission will fail and we might deduct points. Please do not modify the cells containing public and private tests. If you want to do your own tests, please use the code cell containing your code solution (YOUR CODE HERE).**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47bc61ebae9bdcf73f7d3b5239e7fdac",
     "grade": false,
     "grade_id": "cell-4d87ae78fb4caf9d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#  Home Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a75a8dd97ac24bd1fe7356bb5051830",
     "grade": false,
     "grade_id": "cell-e69442a7dc08d8ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85d7e0333b7cdc759edb8e78f4af0670",
     "grade": false,
     "grade_id": "cell-5e9358cbfb48b314",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, List\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7fe728803cac836793366bab74e658eb",
     "grade": false,
     "grade_id": "cell-4fb173363b87fa48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 1: Neural Network from scratch ~ 10P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0bb11abd30a4e157195033d2758c0b71",
     "grade": false,
     "grade_id": "cell-8b9e11b86587a53c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**a) What is a Perceptron and what are the tasks of the 5 different components? (1P)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3440fd200a121129e056a6e0f3385c66",
     "grade": true,
     "grade_id": "cell-b61af27cdc9fc324",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b24e4dfc6728c0e22e2a9d46d91cd83e",
     "grade": false,
     "grade_id": "cell-00fea53a9accf127",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**b) Which activation functions do you know besides the ReLU (name at least 3) and explain the inputs / outputs of one of those? (1.5P)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a33ae8b3cbc47ee171fe96f101f5b74d",
     "grade": true,
     "grade_id": "cell-0afb53fc3ad6f345",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5fe826f3a01d867bf08cc4e8a85d29dd",
     "grade": false,
     "grade_id": "cell-474539096c395ac8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**c) Implement the ReLU activation function and its derivative. (2P)**\n",
    "\n",
    "*Note:* The ReLU (Rectified Linear Unit) function is a piecewise linear function which is very similar to the linear activation function that you know from lecture 2 page 30. The difference between these two is that ReLU cuts of the negative value and sets them to zero. $$\\text{ReLU}(x) = \\begin{cases} x, & \\text{if } x > 0 \\\\ 0, & \\text{if } x \\le 0 \\end{cases} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40931a5e1582103d01be3057c6309f04",
     "grade": true,
     "grade_id": "cell-59f29cac5e1ab452",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def relu(z: npt.NDArray[np.float64]) -> npt.NDArray[np.float64]:\n",
    "    '''\n",
    "    Input: \n",
    "        z: floating point vector to which you want to apply the ReLU activation function\n",
    "\n",
    "    Output:\n",
    "        Output a floating point vector that has the same shape as z but with the activated values\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2e2fc955e90733b12b23afd25a39447",
     "grade": false,
     "grade_id": "cell-b5dc2659cbb5bdc6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "relu(np.array([1,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4e9ffea2f91033d0b1f2fdac3dd56de",
     "grade": true,
     "grade_id": "cell-7cc5e0bafd23eda9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These are some test cases for you to check your implementation\n",
    "assert((relu(np.array([1,-1])) == np.array([1,0])).all())\n",
    "assert((relu(np.array([-112,234])) == np.array([0,234])).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "853f0edba213b23697ed28e4d0a1355d",
     "grade": true,
     "grade_id": "cell-25722a6942cadbc3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grad_relu(z: npt.NDArray[np.float64]) -> npt.NDArray[np.float64]:\n",
    "    '''\n",
    "    Input: \n",
    "        z: Vector to which you want to apply the gradient of the ReLU activation function\n",
    "\n",
    "    Output:\n",
    "        Output a vector that has the same shape as z and is the derivative of z\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return d_az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4078ba101a72af211392857e6ccae8ca",
     "grade": true,
     "grade_id": "cell-a7a9a25aa59363f7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These are some test cases for you to check your implementation\n",
    "assert((grad_relu(np.array([1,-1])) == np.array([1,0])).all())\n",
    "assert((grad_relu(np.array([-112,234])) == np.array([0,1])).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcae33a9f2b41237e7d668c912fccaa9",
     "grade": false,
     "grade_id": "cell-3d371c1a9510adba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**d) Implement the forward function and the cost function and its gradient (2.5P).**\n",
    "\n",
    "Implement the forward function for a neural network with one hidden layer.\n",
    "\n",
    "*Hint:* You only need to use the activation function in the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d8f1baba7bedcdee73d38fc1a0db94e",
     "grade": true,
     "grade_id": "cell-ddd55abc575278ce",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward(X: npt.NDArray[np.float64], \n",
    "            Wh: npt.NDArray[np.float64], \n",
    "            Bh: npt.NDArray[np.float64], \n",
    "            Wo: npt.NDArray[np.float64], \n",
    "            Bo: npt.NDArray[np.float64]) -> Tuple[npt.NDArray[np.float64], \n",
    "                                                  npt.NDArray[np.float64], \n",
    "                                                  npt.NDArray[np.float64]]:\n",
    "    ''' \n",
    "    This is the forward function for making predictions. \n",
    "    In order to train the network later you also need to return the activation and pre-activation of the hidden layer.\n",
    "    \n",
    "    Input:\n",
    "        X: This is equivalent to the x in f(x). So to this value we want a prediction, Dimension: Scalar\n",
    "        Wh: weight matrix or vector for the hidden layer, Dimension: inputLayerSize x hiddenLayerSize\n",
    "        Bh: bias for the hidden layer, Dimension: 1 x hiddenLayerSize\n",
    "        Wo: weight matrix for the output layer, Dimension: hiddenLayerSize x ouputLayerSize\n",
    "        Bo: bias for the output layer, Dimension: 1 x ouputLayerSize\n",
    "\n",
    "    Output:\n",
    "        1. Prediction, Dimension: Scalar\n",
    "        2. Activation of the hidden layer, Dimension: 1 x hiddenLayerSize\n",
    "        3. Pre-activation of the hidden layer, Dimension: 1 x hiddenLayerSize\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return Zo, Ah, Zh\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "970c76a1d73b1bba0ba4ab8db4c42f9c",
     "grade": true,
     "grade_id": "cell-61597567b468dbbf",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test - Don't modify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d54d6a82a17075365fac15097ea258a2",
     "grade": false,
     "grade_id": "cell-a798b1592661fd2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "The cost function (also known as *loss*) is given as follows: $$\\begin{align*} X &:= \\text{Input for forward function}\\\\ y &:= \\text{Correct label for } X \\\\ \\text{forward}(X) &:= \\text{Forward function that predicts a label for input } X\\\\ \\text{The cost function:}\\\\ \\text{cost}(X,y) &= \\frac{\\sum (\\text{forward}(X)-y)^2}{2} \\end{align*} $$\n",
    "\n",
    "This is a slight variation of the one you already learned in the lecture but will do just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66f4ace36f2c9f61a15cc3840148385f",
     "grade": true,
     "grade_id": "cell-9cd1af9bdd6992c7",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cost(X: npt.NDArray[np.float64], y: np.float64,\n",
    "            Wh: npt.NDArray[np.float64], \n",
    "            Bh: npt.NDArray[np.float64], \n",
    "            Wo: npt.NDArray[np.float64], \n",
    "            Bo: npt.NDArray[np.float64]) -> np.float64:\n",
    "    ''' \n",
    "    Quadratic loss function.\n",
    "    \n",
    "    Dimensions are similar to forward function.\n",
    "\n",
    "    Input:\n",
    "        X: Input for the value to predict\n",
    "        y: real value for the prediction, Dimension: Scalar\n",
    "        Wh: weight matrix or vector for the hidden layer\n",
    "        Bh: bias for the hidden layer\n",
    "        Wo: weight matrix for the output layer\n",
    "        Bo: bias for the output layer\n",
    "\n",
    "    Output:\n",
    "        cost, Dimension: Scalar\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b17eb0531767d6059ba8700e073e7256",
     "grade": true,
     "grade_id": "cell-4253b8f8ec4d529a",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test - Don't modify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1975e6ec1e19abad35f632759f164965",
     "grade": true,
     "grade_id": "cell-634c90ea8da4ecc0",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cost_grad(output: np.float64, y: np.float64) -> np.float64:\n",
    "    ''' \n",
    "    Gradient of Quadratic loss function\n",
    "\n",
    "    Input:\n",
    "        output: predicted value\n",
    "        y: real value for the output\n",
    "\n",
    "    Output:\n",
    "        gradient of cost\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bffbea3f28ea5777c8f785ff1e9fb834",
     "grade": true,
     "grade_id": "cell-6fa874405335c61d",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test - Don't modify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e11403fc820b7ef12ca4ccda4104760",
     "grade": false,
     "grade_id": "cell-f3509e30c92090a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Make yourself a clear image of what gradients are required and how they are calculated. We implemented the `backprop` function already for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3dbba0ead107e3b50ba043c1cecfba54",
     "grade": false,
     "grade_id": "cell-467471a6e368a58a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def backprop(X: npt.NDArray[np.float64],\n",
    "             output: npt.NDArray[np.float64],\n",
    "             y: npt.NDArray[np.float64],\n",
    "             Ah: npt.NDArray[np.float64],\n",
    "             Zh: npt.NDArray[np.float64],\n",
    "             Wo: npt.NDArray[np.float64]) -> Tuple[npt.NDArray[np.float64], \n",
    "                                                   npt.NDArray[np.float64], \n",
    "                                                   npt.NDArray[np.float64], \n",
    "                                                   npt.NDArray[np.float64]]:\n",
    "\n",
    "    '''\n",
    "    The backprop function should output the gradients to all the necessary vectors. \n",
    "     \n",
    "    Input:\n",
    "        X: This is equivalent to the x in f(x). So to this value we want a prediction\n",
    "        output: Predicted value\n",
    "        y: true value to X\n",
    "        Ah: activation of hidden layer\n",
    "        Zh: pre-activation of hidden layer\n",
    "        Wo: weights of output layer\n",
    "\n",
    "    Output:\n",
    "        1. Gradients of weights of hidden layer\n",
    "        2. Gradients of weights of output layer \n",
    "        3. Gradients of bias of hidden layer\n",
    "        4. Gradients of bias of output layer\n",
    "    '''\n",
    "    err_output: np.float64 = cost_grad(output, y) #last layer is linear, no gradient needed\n",
    "    err_hidden: npt.NDArray[np.float64] = np.dot(err_output, Wo.T) * grad_relu(Zh)\n",
    "\n",
    "    # Weight Gradients\n",
    "    dCdWh: npt.NDArray[np.float64] = np.dot(X, err_hidden)\n",
    "    dCdWo: npt.NDArray[np.float64] = np.dot(Ah.T, err_output)\n",
    "    \n",
    "    # Bias Gradients\n",
    "    dCdBh: npt.NDArray[np.float64] = np.sum(err_hidden, axis=0, keepdims=True)\n",
    "    dCdBo: npt.NDArray[np.float64] = np.sum(err_output, axis=0, keepdims=True)\n",
    "\n",
    "    return dCdWh, dCdWo, dCdBh, dCdBo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7d1afb2ffc9fec254a83ca2a684679b",
     "grade": false,
     "grade_id": "cell-e3afde8da9485e0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**e) Implement the training loop and train a simple function in the from of $f(x) = axÂ² + bx + c$ for example $f(x) = (x-5)^2$. But feel free to experiment and maybe try higher order functions too.**\n",
    "\n",
    "For that you have to implement *gradient descent* to update the weights and performs one epoch of the training cycle and after that the training loop. (3P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2cfcc753fa6fb4bba8cf8403dd23733",
     "grade": true,
     "grade_id": "cell-edb04359f5df9ef7",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x: List[float], \n",
    "                     y: List[float],\n",
    "                     lr: float, \n",
    "                     Wh: npt.NDArray[np.float64], \n",
    "                     Wo: npt.NDArray[np.float64], \n",
    "                     Bh: npt.NDArray[np.float64], \n",
    "                     Bo: npt.NDArray[np.float64]) -> Tuple[float, \n",
    "                                                           npt.NDArray[np.float64], \n",
    "                                                           npt.NDArray[np.float64], \n",
    "                                                           npt.NDArray[np.float64], \n",
    "                                                           npt.NDArray[np.float64]]:\n",
    "    ''' \n",
    "    Gradient descent gets a list of inputs and true outputs and iterates trough \n",
    "    them and performs a weight and bias update each step. \n",
    "    \n",
    "    Dimensions of the varables are similar to task 1 d)\n",
    "\n",
    "    Input:\n",
    "        x: list of inputs in the same ordering as y\n",
    "        y: list of true outputs with the same ordering as x\n",
    "        lr: learning rate of gradient descent\n",
    "        Wh: weight matrix or vector for the hidden layer\n",
    "        Bh: bias for the hidden layer\n",
    "        Wo: weight matrix for the output layer\n",
    "        Bo: bias for the output layer\n",
    "    \n",
    "    Output:\n",
    "        1. average of cost function of input data (TODO: check formulation)\n",
    "        2. updated weights of hidden layer\n",
    "        3. updated weights of output layer\n",
    "        4. updated bias of hidden layer\n",
    "        5. updated bias of output layer\n",
    "    '''\n",
    "    costs: float = 0.0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return costs, Wh, Wo, Bh, Bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "989a6ff256a20f76e98bf332eb164238",
     "grade": false,
     "grade_id": "cell-4bb6dc49743ff2b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Tests to check your implementation\n",
    "inputLayerSize_t = 1\n",
    "hiddenLayerSize_t = 5 # This is the value you can play around with\n",
    "outputLayerSize_t = 1 \n",
    "\n",
    "# Initialize Weights\n",
    "Wh_t = np.ones((inputLayerSize_t, hiddenLayerSize_t)) \n",
    "Wo_t = np.ones((hiddenLayerSize_t, outputLayerSize_t))\n",
    "\n",
    "# Initialize Biases\n",
    "# Small positive value to avoid Relu units dying too quickly\n",
    "Bh_t = np.full((1, hiddenLayerSize_t), 0.2)\n",
    "Bo_t = np.full((1, outputLayerSize_t), 0.2)\n",
    "\n",
    "# gradient_descent([1,2],[3,4], 0.001, Wh_t, Wo_t, Bh_t, Bo_t)\n",
    "\n",
    "# Forward inputs and outputs\n",
    "## Test 1\n",
    "x_1 = [1,2,3]\n",
    "y_1 = [3,2,1]\n",
    "Wh_1 = Wh_t\n",
    "Wo_1 = Wo_t\n",
    "Bh_1 = Bh_t\n",
    "Bo_1 = Bo_t\n",
    "\n",
    "tmp_1 = gradient_descent(x_1,y_1, 0.001, Wh_1, Wo_1, Bh_1, Bo_1)\n",
    "\n",
    "# for i in range(5):\n",
    "#     print(np.round(tmp_1[i], 2))\n",
    "\n",
    "assert(np.round(tmp_1[0], 2) == np.round(42.57, 2))\n",
    "assert((np.round(tmp_1[1], 2) == np.round(np.array([[0.94, 0.94, 0.94, 0.94, 0.94]]), 2)).all())\n",
    "assert((np.round(tmp_1[2], 2) == np.round(np.array([[0.93], [0.93], [0.93], [0.93], [0.93]]), 2)).all())\n",
    "assert((np.round(tmp_1[3], 2) == np.round(np.array([[0.17, 0.17, 0.17, 0.17, 0.17]]), 2)).all())\n",
    "assert((np.round(tmp_1[4], 2) == np.round(np.array([[0.17]]), 2)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6eb7ac46f68a20b6151c971ddf805473",
     "grade": true,
     "grade_id": "cell-4a7162dbc77a1cd2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test - Don't modify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3dce9f0ca72a2dc39e6fa9b1cb01e55",
     "grade": false,
     "grade_id": "cell-928872b54329966e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "The following is the initialization of the weights and biases. So you get consistent results. Feel free to experiment with the number of neurons in the hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67a6ce10a6c5b5b1a732ec01644faa37",
     "grade": false,
     "grade_id": "cell-44bf0ddbf23c622b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_network() -> Tuple[npt.NDArray[np.float64], npt.NDArray[np.float64], npt.NDArray[np.float64], npt.NDArray[np.float64]]:\n",
    "    inputLayerSize: int = 1\n",
    "    hiddenLayerSize: int = 10 # This is the value you can play around with\n",
    "    outputLayerSize: int = 1 \n",
    "\n",
    "    # Initialize Weights\n",
    "    np.random.seed(0)\n",
    "    Wh: npt.NDArray = np.random.randn(inputLayerSize, hiddenLayerSize) /np.sqrt(inputLayerSize)\n",
    "    Wo: npt.NDArray = np.random.randn(hiddenLayerSize, outputLayerSize) /np.sqrt(hiddenLayerSize)\n",
    "\n",
    "    # Initialize Biases\n",
    "    # Small positive value to avoid Relu units dying too quickly\n",
    "    Bh: npt.NDArray = np.full((1, hiddenLayerSize), 0.2)\n",
    "    Bo: npt.NDArray = np.full((1, outputLayerSize), 0.2)\n",
    "\n",
    "    return Wh, Wo, Bh, Bo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1eed77a6378f4dbdbae0c5afc4c10be",
     "grade": false,
     "grade_id": "cell-095bdf88390389d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Next is the generation of the training data. Here you can also change up the function which the network should learn or the interval in which the numbers are generated. \n",
    "\n",
    "*Hint:* Start with an easy function an later aim for something more difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b53a5aef0f4e558cea17db18c93de8b0",
     "grade": false,
     "grade_id": "cell-ad6e0fed392b835d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f_x(x: float) -> float:\n",
    "    '''\n",
    "    Feel free to play around!\n",
    "    '''\n",
    "    # return 0.1 * ((x-5)**3 - 10 * x + 120) # Example of a more complex function\n",
    "    return (x-5)**2\n",
    "\n",
    "x = np.linspace(0, 10, 1001)\n",
    "y = np.array([ f_x(i)  for i in x])\n",
    "\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d529fd0311ccce1158c065fcc9edd12",
     "grade": false,
     "grade_id": "cell-e8c14444f4319468",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Now implement the training loop and train your network for 1000 epochs with a learning rate of 0.001. Shuffle the training data before each epoch.\n",
    "\n",
    "*Note:* The cost should go down if that is not the case check your code above. Are the derivatives correct?\n",
    "\n",
    "**At the end the cost for $f(x) = (x-5)^2$ has to be below 0.05!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9aef08cfea05a0e9893bbcbc957dee17",
     "grade": true,
     "grade_id": "cell-5dc46853dbb96276",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Wh, Wo, Bh, Bo = init_network()\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9673bc653e1581f89d52261ab2c5f0e",
     "grade": true,
     "grade_id": "cell-e277af25361b7e06",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test - Don't modify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "81d3022d6b21648446e7c32773a056f3",
     "grade": false,
     "grade_id": "cell-b469b612703dd4a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Normally you also need test data in order to validate the accuracy of you network. But for now we only plot the predictions and the real values in the same plot so we can compare it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a52ca2e0a416a2773ba2b358f5432ecf",
     "grade": false,
     "grade_id": "cell-4eb1b00d00a54ce6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_ax = np.linspace(0, 10, 1001)\n",
    "y = np.array([ f_x(i)  for i in x_ax])\n",
    "preds = np.array([forward(i, Wh, Bh, Wo, Bo)[0][0,0] for i in x_ax])\n",
    "plt.plot(x_ax, preds)\n",
    "plt.plot(x_ax,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2734ef04e60afa2655a6984ca94b4227",
     "grade": false,
     "grade_id": "cell-5d5f9281c4b703a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 2 - Byte Pair Encoding ~ 10P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1dfcbaa6c44fc286ce9f48d54aebd6d",
     "grade": false,
     "grade_id": "cell-fd3236059c81ce63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "The goal is to calculate byte pair encodings for a given dataset. For a recap of the concept we refer to lecture 9, slides 66.ff.\n",
    "\n",
    "But first we need to install some additional libraries in order to get it working properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d23a8475d46f1d7ecaf787c7b10e57c",
     "grade": false,
     "grade_id": "cell-729ec0d1cfeed7ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install datasets==2.16.1\n",
    "!pip install tokenizers==0.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a74270652236e10e7ee7a5414c0e8b30",
     "grade": false,
     "grade_id": "cell-58d15d5fee462ae7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "55d5099d7b679a5cae90a4303f5946e8",
     "grade": false,
     "grade_id": "cell-81ea36f9a35cc6ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**a)** First we want to make sure we create a suffieciently large corpus. As dataset you import the dataset \"wikitext-2-raw-v1\" from huggingface. Make sure to use the 500 first entries of the training dataset and subsequently filter out empty lines. \n",
    "\n",
    "Save the dataset in the variable `dataset` and the corpus in the variable `corpus`. ***(1P)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a333e096c04d96422eefc5e888e334f5",
     "grade": true,
     "grade_id": "cell-244778a82446be41",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load WikiText-2 dataset \"wikitext-2-raw-v1\"\n",
    "\n",
    "dataset : Dataset = None\n",
    "corpus: list = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d9a7e7af6846cfd268fbfbc2b6ecd43",
     "grade": true,
     "grade_id": "cell-e0ff412ce441cbd7",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test - Don't modify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbf99055e4c5b4439744ab040436fb46",
     "grade": true,
     "grade_id": "cell-0e9998b74bc12e96",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test - Don't modify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8cd6025cb614eb2a9678bb81bee395b",
     "grade": true,
     "grade_id": "cell-5fefde03129fd7c1",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test - Don't modify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8d88fb9328c51f79c6b338ce2b34e45",
     "grade": true,
     "grade_id": "cell-e08087f00de78bdd",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test - Don't modify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "715edb8610e28f71570bc1e88075faca",
     "grade": false,
     "grade_id": "cell-437a975b42eb356c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Note that the corpus should have a format like:\n",
    "\n",
    "```python\n",
    "corpus = [\n",
    "    \"This is the first line\",\n",
    "    \"This is the second line\",\n",
    "    ..\n",
    "]\n",
    "``` \n",
    "\n",
    "For debugging during coding you can also consider working with a smaller corpus, e.g. only 5 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f3bbc50e289bc1b3c0dbf443e57312a",
     "grade": false,
     "grade_id": "cell-622fb67db5051cf2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**b)** Here, you loop through the corpus and count the word frequencies and save the output in the variable `word_freqs`. \n",
    "\n",
    "The `Whitespace` pre_tokenizer can be used for preprocessing a string to strip away empty spaces as well as to separate out special characters such as punctuations. \n",
    "\n",
    "*Hint:* You may want to have a look at the function: `pre_tokenize_str` of the `Whitespace` pre_tokenizer. This might help you. ***(2P)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c64efb57584be5ffbf5dbe65912dffbb",
     "grade": true,
     "grade_id": "cell-8ce3e5e867205cc4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a Whitespace pre_tokenizer from the tokenizers library\n",
    "# Helps in separating text about white space and punctuations\n",
    "tokenizer = Whitespace()\n",
    "\n",
    "# Initialize a defaultdict to store word frequencies\n",
    "word_freqs = defaultdict(int)\n",
    "# this dictionary gets entries for word_freqs[word]\n",
    "\n",
    "# This will be needed later\n",
    "vocab_size:int = 200\n",
    "\n",
    "def count_word_freqs(corpus:list) -> dict:\n",
    "    # We loop through to corups to calculate word frequencies\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return word_freqs\n",
    "\n",
    "word_freqs = count_word_freqs(corpus)\n",
    "print(word_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6d6ca12c49105b740d5823290df8c6f",
     "grade": true,
     "grade_id": "cell-a261f5385cdff84d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test - Don't modify\n",
    "assert len(word_freqs.keys()) == 6911\n",
    "assert sum(word_freqs.values()) == 40051\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f9aa9338de3e9772f9f7af7797b05c5",
     "grade": false,
     "grade_id": "cell-9e92e0927f2f1080",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "The following block creates the alphabet and initial vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3004a1e909e2bb2190196872569f9988",
     "grade": false,
     "grade_id": "cell-27444c649f61b834",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize(word_freqs:dict) -> Tuple[list, list, dict, dict]:\n",
    "    alphabet:list = []\n",
    "    vocab:list = [\"\"]\n",
    "    splits:dict = {}\n",
    "    merges:dict = {}\n",
    "    \n",
    "    for word in word_freqs.keys():\n",
    "        for letter in word:\n",
    "            if letter not in alphabet:\n",
    "                alphabet.append(letter)\n",
    "    alphabet.sort()\n",
    "\n",
    "    vocab = alphabet.copy()\n",
    "    splits = {word: [c for c in word] for word in word_freqs.keys()}\n",
    "\n",
    "    return alphabet, vocab, splits, {}\n",
    "\n",
    "alphabet, vocab, splits, merges = initialize(word_freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9cb7452c1f1819d7d6d17fcac5665c2",
     "grade": false,
     "grade_id": "cell-bfeeaae21bb6d318",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**c)** Define a function to compute the frequency of each pair of characters ***(2P)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d43757610f78b7f54bc9876d1d87bf6",
     "grade": true,
     "grade_id": "cell-5e59098a15cbf372",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_pair_freqs(splits:dict) -> dict:\n",
    "    pair_freqs = defaultdict(int)\n",
    "    # to compute the frequency of each pair of characters\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return pair_freqs\n",
    "\n",
    "# Initialize pair_freqs by calling the calc_pair_freqs function\n",
    "pair_freqs = calc_pair_freqs(splits)\n",
    "print(pair_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "faf8ca2d7c2a5e8097237afceb82aa88",
     "grade": true,
     "grade_id": "cell-a7b55d57116b9963",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test - Don't modify\n",
    "assert len(pair_freqs.keys()) == 969\n",
    "assert sum(pair_freqs.values()) == 130300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e60f0f1a8ff5a945b23c6ebf8668c1b7",
     "grade": false,
     "grade_id": "cell-c4088328174c2fe1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Here we find the pair of characters that appears most frequently together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ed4815cb33aa84cdb9bab59dadb876b",
     "grade": false,
     "grade_id": "cell-adf2fed7d428b17a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, key in enumerate(pair_freqs.keys()):\n",
    "    print(f\"{key}: {pair_freqs[key]}\")\n",
    "    if i >= 5:\n",
    "        break\n",
    "\n",
    "best_pair = \"\"\n",
    "max_freq = None\n",
    "\n",
    "for pair, freq in pair_freqs.items():\n",
    "    if max_freq is None or max_freq < freq:\n",
    "        best_pair = pair\n",
    "        max_freq = freq\n",
    "\n",
    "print(best_pair, max_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "383d16a9825071bf516829a47502e3c6",
     "grade": false,
     "grade_id": "cell-ade896d5c4f80d74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**d)** Define a function to merge the most frequent pair of characters ***(2P)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da449f7057fd36305252f26c806ee585",
     "grade": true,
     "grade_id": "cell-f31bb69bdadebf4f",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_pair(a:str, b:str, splits:dict, word_freqs:dict) -> dict:\n",
    "    for word in word_freqs:\n",
    "        split = splits[word]\n",
    "        if len(split) == 1:\n",
    "            continue\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9137d6fa61b1ddaedf869c533962837f",
     "grade": true,
     "grade_id": "cell-6d34502f30668a98",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test - Don't modify\n",
    "# Example and sanity check\n",
    "splits_example = combine_pair(\"y\", \"r\", splits, word_freqs)\n",
    "assert splits_example[\"Valkyria\"] == ['V', 'a', 'l', 'k', 'yr', 'i', 'a']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4cf864ff059854760b664be66f803ad",
     "grade": false,
     "grade_id": "cell-e2b2e4fa505d0504",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**e)** Create the vocabulary by computing the pair frequencies and merging them accordingly, until you have a vocabulary size of 200 like it is done in the lecture notes of lecture 9. ***(2P)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "262707cc90c79be05da711719ac11d0e",
     "grade": true,
     "grade_id": "cell-c0d21a5824af85c6",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91dc268b8038c992bb7fde446cbbdb01",
     "grade": true,
     "grade_id": "cell-3c432d2dedb4097a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test - Don't modify\n",
    "assert len(vocab) == 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72d20fb34831b78881053f10a4a76c97",
     "grade": false,
     "grade_id": "cell-9a5f825524ad467b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "We provide the tokenize function to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e098b0b6d65e9a2db38a22bb7f9f495",
     "grade": false,
     "grade_id": "cell-ed28577a19c4f92f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_splitting(text:str, merges:dict, splits:dict) -> list:\n",
    "    tokens = tokenizer.pre_tokenize_str(text)\n",
    "    tokens_text = [word for word, _ in tokens]\n",
    "    splits = [[l for l in word] for word in tokens_text]\n",
    "    for pair, merge in merges.items():\n",
    "        for ind, split in enumerate(splits):\n",
    "            i = 0\n",
    "            while i < len(split) - 1:\n",
    "                if split[i] == pair[0] and split[i + 1] == pair[1]:\n",
    "                    split = split[:i] + [merge] + split[i + 2 :]\n",
    "                else:\n",
    "                    i += 1\n",
    "            splits[ind] = split\n",
    "\n",
    "    return sum(splits, [])\n",
    "\n",
    "alphabet, vocab, splits, merges = create_vocab(word_freqs, vocab_size)\n",
    "text_splitting(\"Darmstadt holds the official title City of Science (German: Wissenschaftsstadt) as it is a major centre of scientific institutions, universities, and high-technology companies.\", merges, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67ac905574c0929f2f908c55024b439f",
     "grade": false,
     "grade_id": "cell-d59f82a1fcd68494",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**f)** Now, repeat the byte pair encoding for vocab sizes of 1000 and 5000. What do you notice? ***(1P)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4ed5fc2d426f91565357dc0e2423e00",
     "grade": false,
     "grade_id": "cell-8df4b75a33ad2def",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "alphabet, vocab, splits, merges = create_vocab(word_freqs, 1000)\n",
    "text_splitting(\"Darmstadt holds the official title City of Science (German: Wissenschaftsstadt) as it is a major centre of scientific institutions, universities, and high-technology companies.\", merges, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae22f0fa328fe959e2d4f343bea26ad8",
     "grade": false,
     "grade_id": "cell-f600b70e7d84d027",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "alphabet, vocab, splits, merges = create_vocab(word_freqs, 5000)\n",
    "text_splitting(\"Darmstadt holds the official title City of Science (German: Wissenschaftsstadt) as it is a major centre of scientific institutions, universities, and high-technology companies.\", merges, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a576cf2a0c3d39def819c7fe974a8fac",
     "grade": true,
     "grade_id": "cell-659e803b4ca7bd4d",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49168ea45d6367fbdb9453d8367e01ec",
     "grade": false,
     "grade_id": "cell-684915d3de4d1aab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**Submission:**\n",
    "\n",
    "Please upload your submission to Moodle before the next exercise session <font color=\"red\">(Jan 24, 23:59pm)</font>!\n",
    "\n",
    "Submission format: `homework 5.zip`\n",
    "\n",
    "Your submission should contain your filled out Jupyter notebook (naming schema: `homework 5.ipynb`) and any auxiliar files that are necessary to run your code (e.g., the datasets provided by us).\n",
    "\n",
    "Each submission must be handed in only once per group."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "9dd41b0cab5a130a043f9245acb1f850e1d2ee1859e50283dacddd6f5f9d8999"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
