{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da132e44",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da5064c9ed8cd1fec0f36b714c345b0b",
     "grade": false,
     "grade_id": "cell-4d87ae78fb4caf9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# NLP and the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332ad0ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1145e2ba69b3e56620106550f0984e0",
     "grade": false,
     "grade_id": "cell-8b531762670192f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 0 ~ 0P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e71b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "__Task 0 is only relevant for the homework.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84b8d39",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d4cef5c9a404a5516183e6ce9bf2128",
     "grade": false,
     "grade_id": "cell-6eca7b6c6c224dde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### a) Please enter your group number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a9a8b8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75470a4986487fdb40d73fa368335c95",
     "grade": true,
     "grade_id": "cell-cccfbf605a28a18a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5ed890",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6fdb993af1b0b63ec0df26dca558cdd0",
     "grade": false,
     "grade_id": "cell-2ed8ca1b9e5204c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "_**Regarding types, documentation, and output:**_\n",
    "\n",
    "_We tried to make the description of the parameters as clear as possible. However, if you believe that something is missing, please reach out to us in Moodle. We provide type hints for the function parameters and return values of the functions that you have to implement._\n",
    "\n",
    "_Nevertheless, your code must use the provided method stubs and parameters. Furthermore, make sure that your code runs without errors and in a reasonable amount of time, for example by using \"Kernel/Restart & Run All\" before submitting._\n",
    "\n",
    "_Please use comments where appropriate to help the tutors understand your code. This is especially important for the more extensive exercises later on. Finally, please pay attention to how you output the results. We highly recommend using `display(df)` for displaying data frames._\n",
    "\n",
    "_**Please only modify the template in the specified markdown and code cells (e.g. YOUR CODE / ANSWER / IMPORTS HERE). Some cells are left blank on purpose. Please do not modify these cells, because they are used to autograde your submission. If these cells are modified, the automatic grading for your submission will fail and we might deduct points. Please do not modify the cells containing public and private tests. If you want to do your own tests, please use the code cell containing your code solution (YOUR CODE HERE).**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e8bbfd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e444f879",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6460611ce8e2f24cc032189daea7eb5b",
     "grade": false,
     "grade_id": "cell-a89388d235bd82a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Home Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ebc6a7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec0400f1f66119460a1c7834498fef79",
     "grade": false,
     "grade_id": "cell-7116ccdef607538c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h2> Part 1: Hidden Markov Models (10 Points) </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54258a06",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51f98b3a124063757ab4385c2e584aa6",
     "grade": false,
     "grade_id": "cell-3d71abc30a9f7bb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this exercise, you will be able to perform part-of-speech tagging by yourself using Hidden Markov Models.\n",
    "Part-of-speech tagging (POS tagging) is the process assigning a syntactic label to each token in a document. This\n",
    "kind of tagging gives us more information about surrounding words, e.g. adjectives occur more often before a noun and\n",
    "after a determiner and verbs appear usually after a noun. As an example, here we have two sentences:<br><br>\n",
    "\"Time flies like an arrow.\"<br>\n",
    "\"Fruit flies ate a banana\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a93624",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67f7902c6a0f2f03b412d998ac0893eb",
     "grade": false,
     "grade_id": "cell-f63702a8ab12419c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A tokenizer would split them into the following tokens:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25516825",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f62780e2ac2bc8fd395c3bb58761a1e",
     "grade": false,
     "grade_id": "cell-aaecafbf9e460bf0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"data:image/png;base64,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\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1578e95d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2211ba4bc42e255cf50e9d855d61e93c",
     "grade": false,
     "grade_id": "cell-db0a9d5b2629347c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A part-of-speech tagger (spaCy tagger) could then assign labels, or <b>tags</b>, to the tokens according to their respective parts\n",
    "of speech:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feafd20",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f895d2a3aa4611da245fc11602d39172",
     "grade": false,
     "grade_id": "cell-cca5c0a60b6abb78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAATMAAABNCAYAAADKB4NbAAAABHNCSVQICAgIfAhkiAAAABl0RVh0U29mdHdhcmUAZ25vbWUtc2NyZWVuc2hvdO8Dvz4AABRaSURBVHic7d17TJPXGwfwLxVFKF4wonFEZQPZzNxMsw1BiWUYA4HNmaqTwVyGlMmcErxtA7dBXHReUTPAu4PMqIg4FBQLghsRRYwoc2OgXLxArXIXkQotz++Phf6KtvTeQnc+CdGevuec53nf9zxtX17AhogIDMMwgxzH0gEwDMMYAytmDMNYBVbMGIaxCqyYMQxjFVgxYxjGKpi0mMXHx8PGxmbAffn6+lpFbvHx8QbnoczX13dQHQ9zHANDzxVL7dPBuCYMPZ9tTH1rho2NDQba3R/GismSuZlibkvlY8i8po7Z0PEH4vmviqXXhDHmZx8zGYaxCqyYMQxjFVgxYxjGKrBixjCMVWDFjGEYq8CKGcMwVmHAFjOxWIyuri5Lh2GQjIwMLF++HCKRCAcPHgQwePMqLy/Hxo0bIZFIAPw/j+vXryM+Ph4dHR0WjpD5r7NYMQsODsa6deuwdu1a8Hg8xMTEYPXq1QgLC1M8f/LkSUuFZ7ATJ06gvr4eQUFBuHbtGvLz8wEM3rxsbW1x5MgRNDU1Afh/HsOHD8f+/fshlUotHCHzX2drqYk7Ojqwbds2tLW1YceOHbhx4wYA4IMPPgAA5OfnY+jQoZYKz2C//PILtm7dirfeegsymQx///03gMGbl4eHBxwdHRWPlfOws7OzVFgMo2Cxd2ZZWVkq27Ozs3Hjxg2sXbsW9+7dQ3FxMVasWIHCwkLExsZi1apVePz4Mfbu3YuQkBBUVFQo+lZWVmLdunUQCoW4evWquVJ5SWlpKcrKynD06FEcP35c0a6cV68XYyYibN++Hd988w2+/vprS4Svkao8AKCoqAhfffUVTp06BcDyx+Ps2bNISEjAp59+isuXLwOA4nzKyclBZGQkhEIhmpubzR6buhh746usrMTSpUtx5coVlW3//PMPYmJiEBsbi7NnzwIAiAjx8fGIiopCcXExAGDnzp14+PAhpFIpfvjhB2zYsMFiuZocmZimKVpbW1/apqmpiXg8Ht28eZMaGhrIw8OD9uzZQ9XV1TRr1iwKDQ2l27dvU1xcHAmFQiIiEovFxOPxqLm5mcRiMY0bN446Ojr0isnQ3J48eULu7u507do1ampqoszMTAoODu6Tl7qYf/31V/r888+JiCgmJkbnuU2RT693332X/vrrr5fycHV1pcbGRkpPT6e9e/cSkfmOh7q+VVVV5OLiQkRE+fn55OnpSUTU53yqra0lgUBAiYmJOo9vaHzqYuyNLzo6mnJzc6m8vPyltry8PHJ3d6fHjx+TTCajgIAAysjIICKi6upqcnV1JSKitrY2GjduHCUlJRERUXx8PFVVVZkkT0PHMcb8FvuY2Z8xY8YoPrqMHTsWw4YNw9y5c/Haa6/Bz88Po0aNwpQpUyAQCLBs2TIAwPHjx2Fvb4/k5GQAAJfLRU1NDaZNm6Z2noyMDIhEIuzduxccDgebN2+Gi4sLHBwcVLYvWbJEq/hHjBgBW1tbODs7Y8yYMSrzUhczh8OBSCTCqVOnsGnTpn7naWlpQVxcHGbMmIHQ0FDU19dj165d+OKLL1BRUQGRSAQPDw8MGzYMQqEQIpEI5eXlGDlyJKqrqzFz5kzMnz9fq5yUvZgHAPzxxx+4fPkyEhIS1Oam6Xjk5uYiPT0da9aswd9//23QMXBzc0NdXR0kEglu3bqlePelfD65uroqrmlqkpWVBZFIhOnTp6OrqwuLFy/G2LFjERcXh0mTJqG4uBheXl6oqanBxo0b9Y6xN74VK1bAzc1Nsa1yW0JCAvh8PpydnQEAYWFh2L9/PwQCAV577TVwuVzcvn0bV65cwU8//YS0tDQsX74c9+7d6zOmKqZaE+YwYL+bqc6QIUNU/r+5uRn+/v5Yv3491q9fr3HhAICPjw/Kysqwe/duAMDUqVMxc+ZMte3GpirmkJAQnD9/HomJiZgzZw66u7vV9ndycgKPx0NjYyMAYPz48eByuZgyZQo8PT3x6NEjREVFobS0FDk5ObC1tcWyZcvw6aeforCwELNnzzZaLvfu3cNvv/2GhoYGtblpOh5z5sxBVVUV3njjDYOPwcOHD7Fw4UKcO3cOc+fOVbud8jnUn979GRERgZCQEISGhqK1tRU8Hg/h4eGoqKhAeHg43nvvPaPH+KK2tjZwuVzFY0dHR7S2tioez5s3D+fPn0dpaSmWLl2KBw8eoKysDFOmTNE4tqXXhCEGXTFTx9vbG6dPn4ZMJgMAyOVydHZ2auwXGRmJvLw83LlzR6t2Y1IVc2pqKiZPnoyCggLcv39fcSuEOosWLUJ6ejoAIC8vDwEBAYrnOjs7UVJSgp6eHnh7e8Pf3x8jR45ETEwMvv766z7vGg312WefISoqCkKhUG1u2hwPZYYcg7S0NDg7O2Pp0qV9vnFhDE5OTvDz88OZM2deemeryztdfWPk8/l9rkFevXoV77//vuLxvHnzcOTIEUyYMAHAv99Ui4yMxIIFC7Qa31Rr4uLFi3j+/LlefbVh0WLW3d2t+B1GMTExivYLFy7g7t27OHDgAE6fPg2xWIzU1FQ8ePAABQUFEIlEkEgkSElJwd27d5Gbm4vAwEDw+Xx4eXkhIiICkZGRfV6t1OFwOEhKSkJUVBTkcrnGdm1kZ2dDIpHg0KFDaG9vR1paGsrKyrBhwwZFXnK5XGXMN27cwJo1axAfHw8+n4+JEyf2O5ejoyPc3NxQVlaGq1evwsvLS/Fcc3MzHj58CC6Xq7ggXFRUhIaGBggEAp1yysrKwv3797Fv3z7k5OQo8khPT0djYyNSUlIQHR0NsViMZcuWYdasWXodD2WGHAN/f38UFRXhyy+/RGpqKhoaGpCZmYns7GzF+dTW1obMzEyUlJTg1q1bOo3P5XLx7NkznfpoE6NQKIRYLEZSUhJaWloAQBFzb5ufnx8CAwOxbNkybNiwAbdv38b69esV43p6euL+/fv4+OOPAQACgQDPnj2Dh4eHVnGZYk10dnYiMDAQ169f16mfTgy+6qaBGaboQyqVqr3Q3Ks3JolEQikpKURElJycTO+//z5VVVWpbVc3jrFjfvbsGT19+lSrHIiILl68SEKhkHbs2KFok0gktHDhQiIiunLlCn3yyScklUrJx8eHHj9+TEREubm5asc0Fl2Oh0wmI19fXyJSf2zU9VVFLpeTTCbTN/Q+4yvvTyKi4OBgKi8vVzz28fHpt78pYuzu7ta4b7VljjUhlUo1zm8Iq/mY2cvOzg4ODg5abZuXl4eCggL09PQgMjISHA6n33ZTeTFme3v7PtdENOHz+SgoKOjzbquwsBDV1dVISEhAcnIyVq5ciW3btmH06NE4ceIEdu3ahXPnzhk1D1V0OR4XLlxAfX09KioqjHIMOByO1tfENCksLERtbS327duH2NhYLFiwAFOnTgUAlJSUoK6uDkVFRWaN0dbWVut9qy1Trglt70e8dOkSoqOjdR6f/abZATCOMeZ+/vy5wTevst80a/zxB+L5r4ql18SL/eRyuc5F3uremf1XsbvwGWuiz7tVVswYhrEKrJgxDGMVWDFjGMYqsGLGMIxVYMWMYRirYPK/aA7A4n+t+cUvPp8/6HNTjsFY+Hz+oDoe5jgGhp4rltqng21NKPfXl8nvM2MYhjEH9jGTYRirwIoZwzBWgRUzhmGsAitmDMNYBVbMGIaxCqyYMQxjFVgxYxjGKrBixjCMVWDFjGEYq8CKGcMwVoEVM4ZhrIJJipmvr6/Ff3BW+cvX19fgnOLj4y2eh7F/sLyXOY+XMY6FKXMwdB8PtHN/MK4Xfec3yQ+a29gMrD/iYKx4LJmXKec2Z16mmssY4w6UMSzN0utF337sYybDMFaBFTOGYawCK2YMw1gFVswYhrEKrJgxDGMVBmUxE4vF6OrqsnQYL8nIyMDy5cshEolw8OBBRftAjZcxnz/++MNkt9Yw/zJrMTt27Bhmz56N8PBwxMTE4JtvvsGHH36o8zjBwcE4efKkCSLU34kTJ1BfX4+goCBcu3YN+fn5iucGYryMeY0YMQJbtmyxdBjWjUygv2F9fX0pOztb8djf31/n8bu6uvo83rdvn97x6KK/cQICAujPP/8kIqLMzEwKDg5WPPdivMae2xJja9rnxpzLXOOaeozhw4cbPL45mGO9mKKfrWVK6L/u3buHnJwcFBcX48iRI1i5ciW2bNmCiIgItLe3IzU1FYmJiZDL5di5cydeffVVvPPOO0hJScHq1asxefJknDt3DjExMWhvb4eLiwuCg4PNnkdpaSnKyspw9OhRTJ8+Hfb29ornbty40SfeyspKHDx4EC0tLYiIiMCMGTNARNixYwcaGhpARNi6davZc1Dn7NmzqKysRGlpKZYvX46ZM2eq3Oeq8hooVOVgCXK5HElJSbh69SrefvttrFq1CkOGDFEZI4fDwZEjRxAUFITTp09DJpNh69atGDNmjNqceteRLn2sil4lUIP+hvX19aXt27dTcXExBQUFkVQqpYaGBvLw8KDo6GjKzc2l8vJyamtro4kTJ5JEIqHu7m7avHkzrV27lpqamojH49HNmzeJiKilpYUcHBxIIpFQU1OTzvEYI68nT56Qu7s7Xbt2jZqamvq8M1OOVywWE4/Ho+bmZhKLxTRu3Djq6OigjIwM+vzzz4mIKCYmxqQ56DJ2VVUVubi4EBFRfn4+eXp6EtHL+1xdXrrMZe4cTBVbf2PY2dlRV1cXdXR0kL+/P/34449qY+xdE3v27KHa2loSCASUmJjYb0769NE1B13oO46+/SzyzqyxsRF1dXVob28HAIwdOxbDhg3DihUr4Obmptiu91XL1tYWjo6OaGxsxJgxY2BnZ6fYZvTo0eBwOBg/frx5k1AyYsQI2NrawtnZWfEq2Es53uPHj8Pe3h7JyckAAC6Xi5qaGri7u0MkEuHUqVPYtGmT2eNXx83NDXV1dZBIJLh16xaam5sBvLzPd+7cqTKvadOmWSz2XupysAQbGxsMHToUQ4cOxapVq/D999/ju+++Uxlj75qYO3cuXF1dFddi+8tJnz7WxCLFzMfHB0FBQXB3d8fQoUPNNm9GRgZEIhH27t0LDoeDzZs3w8XFBQ4ODirblyxZYtT5m5ub4e/vj/Xr1wOA4l8AOH/+PKKjo5GUlITz58/3u190zSM0NBRbtmyBjY0NWltbsXnzZq3iffjwIVauXInAwEDMnTsXiYmJOuelSktLC+Li4jBjxgyEhoaivr4eu3btwoQJE1BTUwMPDw8MGzYMQqEQOTk5EIlEmD59Orq6urB48WKMHTtWq/h1yUFZVlaWyjnj4uIwadIkFBcXw8vLCzU1Ndi4caPWsSjjcrmKFzltYux9YdclJ336KLP0etGVRW/NmD59Ojgc9SE4OTmhrq5O4zhyuRxPnz7VuJ2Pjw/Kysqwe/duAMDUqVMxc+ZMte3G5u3trbiW0Rt3Z2cnTpw4gcmTJ6OgoAD379+HRCIxah6nT5+GVCrFt99+i9dff13reNPS0uDs7IylS5fC0dGxz3PK+1xdXuo4OTmBx+OhsbERADB+/HhwuVyEhobi0aNHiIqKQmlpKXJycuDp6YlHjx4hIiICISEhCA0NRWtrq1FyUEfdnDweD+Hh4aioqEB4eDjee+89reN40YULF/DBBx/oFaM+OenTx5Tr5eLFi3j+/LlOfTQxazE7c+YMKisrcfjwYVRWViras7OzIRaLkZSUhJaWFkV7SEgIBAIBhEIhCgsLcenSJRw4cAB3797FgQMHIJfLAQB+fn5YuHAhjh07pjGGyMhI5OXl4c6dO1q1ayM7OxsSiQSHDh1Ce3s70tLSUFZWhsuXL+PChQuKeP39/cHn8+Hl5YWIiAhERkaitbUVtbW1WLNmDeLj48Hn8zFx4kSj5vHmm28iMzMTv//+O8LCwrTOy9/fH0VFRfjyyy+RmpqKhoYGZGZmAui7zwMDA1Xm1Z9FixYhPT0dAJCXl4eAgAAAQGdnJ0pKStDT0wNvb+8+fZycnODn54czZ84YJQdtKM85f/78Ps+9+FiT7u5uxMbGYvXq1bCxscGaNWvUxigUCiEWi5Gamoq2tjZkZmaipKQEt27dUptT7zrSpY8mplgvnZ2dCAwMxPXr13Xu2y+9rrRpYMxhW1tbqaenR+N2/W3TG49EIqGUlBSqqamhgIAAysjIoKqqKrXt6sYxlFQqfekC+bNnz+jp06cac9A3j7t371JYWBgJBAKd8pLL5SSTyVQ+9+I+V5VXf3N99tlndPPmTYqLi1Pk5e3tTZmZmRQVFUVZWVkkkUho4cKFij4///wz7dmzx2g5qBpD05w+Pj5a5acLbWPUd3td+phjvUilUo3z62rA/wTAqFGjYGNjo3E7bbbp9eqrr2LevHkvXTdQ125sdnZ2cHBw6NNmb28PLper0zja5pGRkYFXXnkFhw8fhkwm0+nVlMPh9Ln2ouzFfa4qr/6EhYUhMTERI0eOVLS5uLjgo48+wieffIKjR4++1KeoqAh8Pl/rOYD+c9CGPnPqStcY9clJ3/1givWi/E08YxnwxcyY8vLyUFBQgJ6eHkRGRiqu16lrH6h0zaOurg4//vgjEhIS4Orq2uc7xpbE5/NRUFAAgUAAACgsLER1dTUSEhKQnJyMlStXorCwELW1tdi3bx9iY2OxYMECTJ061aRx9TdnSUkJ6urqUFRUZNIYBgJLr5dLly4hOjpa6+3Zb5q1wDiWmLu7uxsymazPDb3GGlsXL871/Plzo7xKD5TfEjvQzn19WHq9KPeTy+Vav5u06E8AMObTe3/TQGOKjxuM9dDpo7cJ42AYhjEbVswYhrEKrJgxDGMVWDFjGMYqsGLGMIxVMEkx4/P5Fv+rzMpfxrjhsfdXHlsqB+UYjM2cx8tUN58aIwfA8H080M79wbhe9J3fJPeZMQzDmBv7mMkwjFVgxYxhGKvAihnDMFaBFTOGYazC/wBhU95gksSUrAAAAABJRU5ErkJggg==\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7952d897",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9265e38be051b130a7dcdaacf3c94b4",
     "grade": false,
     "grade_id": "cell-5725b8f1071c5bc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Hidden Markov Models (HMMs): are graphical probabilistic models that enable us to talk about observed and hidden\n",
    "events. The latter being considered as causal factors in the model (Jurafky & Martin, 2019). For instance, in our real\n",
    "world we can see words but we cannot see pos-tags. Given the explanation of HMMs in the lecture and in our lab session,\n",
    "we will find the best pos sequence for a given word sequence using the Bayes’ Rule and the Viterbi Algorithm, please\n",
    "refer to slides from both Lecture and Lab session for further details.<br><br>\n",
    "<b>Note:</b> For this exercise, you may only use spaCy, scikit-learn, NumPy, Pandas and internal packages from Python. Please\n",
    "follow the instructions as given below and in case of questions use our Discussion forum in Moodle, we don’t answer\n",
    "questions via email.\n",
    "<br>\n",
    "<br>\n",
    "Using the files <i>transisition_probabilities.csv</i> and <i>observation_likelihoods.csv</i>, compute the likelihood of POS tags for the\n",
    "following word sequence:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2469de",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d567accece2185c820e4b86329fcb20e",
     "grade": false,
     "grade_id": "cell-95e3327c0ee257c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAJMAAAAoCAYAAAD66MijAAAABHNCSVQICAgIfAhkiAAAABl0RVh0U29mdHdhcmUAZ25vbWUtc2NyZWVuc2hvdO8Dvz4AAAT7SURBVHic7dtNSFRvFAbw544m5AjW4AfiRvxoYwUqWOpikBwUroRoxKWdpiGioEuRtHGh1CJdVIq4iiFwERGDEoFrHQShDwpFi2iYRPE6oiHFXJ//ohrKv6NOvlYj5wezGK/vuWcOj77X64xGkhBCAdvfbkAcHxImoYyESSgjYRLKSJiEMhImoYyESajDKDmdTgL47UdPT4/ymkfxcDqdR/L6Y20ukeawG42M7qalpmmIcsm+aw9T86j8yV7/5blE04Nsc0IZCZNQRsIklJEwCWUkTEIZCZNQRsIklFEapvHxcbhcLhiGgdevX6ssLWKA0jDpuo6UlBSUl5fj7NmzKksrNzIyEhM1Y0n8325gLyThdrthmiauXbuGixcvYmBgAIZh4PTp0+jr60N8fDy6u7sxPj6Oubk5zM7OoqWlBTabDR6PB7qu4+nTpwiFQrhz5w4cDgcmJibQ2dmJjY0NZGZmwjCMQ/e6W823b9/i4cOH0DQNZWVl0HVdwVS+mZ6ehsfjQVtbG27fvo2mpiaYpvnLDEpLSwEA8/Pz8Hg8OHHiBEpLS3Hp0iXMzc1hdHQUa2traGpqwoULFw7f1IH/8fLdfksMw+Dw8HBUa/equbi4yKysLJLk+vo609LSeP/+fZLkrVu3uLCwwIWFBWZmZpIkJycnWVxczJWVFZ45c4ZDQ0N8//49a2tree/ePZLk2toaExMTubS0xNXVVSW97qzp9/uZm5vL5eVlhkIhVlVV8fHjx0rORTL8+trb2/n8+XN6vd7/zYAk/X4/8/Pzubq6Sp/Px6KiIgYCARYUFNA0TQYCAaalpfHz589R97DTP/2bCQCys7Nht9sxPz+Pqakp9Pf3Y2xsDC0tLfjw4QNycnIAAH6/H0tLS3j16hVM00RKSgoSEhLgcrmQlZUFXdcxMzMDADh16hRsNhvS09OV9bmz5t27d+F0OpGamgoAqK+vx8jICGpra5Wc78fra21tjTgDABgbG0NFRQUcDgeKi4sxMzODwcFBnDx5Eg8ePAAA2O12vHv37tCXJjHx19zly5fx7NkzzM7OoqGhAR8/fsSLFy+Ql5cHAPj06ROuXLmCiYkJuFyuXWvExcX9yZaxvr4Ou90efp6UlIRgMHhk54s0g2AwiISEhPBzTdNgmiYqKyvR1dWFrq4uJUECYihMHo8HGRkZAIDq6mo0Nzejrq4OwLefvtTUVDQ0NCApKelANS3LwubmptI+f67pdDrh8/nCx3w+H8rLy5We72eRZlBWVgav14utra1wjyUlJeHryB9f+3H8UA68IR5gD/V6vczLy2NFRQVfvnx54LX7tWFZFtPT07m4uEiSnJqa4vnz58PH37x5w3PnzrG5uZm9vb1MTk7m9evX6XA4ePPmTQaDQdbU1LCwsDDcl67rrKys5KNHj6Lqaa9ed9Z0u928ceMG3W43DcPgxsaGsnN5vV46HA52dHTQNM1dZ/DkyROSZGdnJ/Pz83n16lXW19eTJDs6OlhUVMTGxkY2NjYyEAhE3cNOx+b9TNvb2yAZ1XZGEpqm7Xrsd3vdWTMUCuHr169ITEyMuEbVXPaagWVZsCzrly3vy5cvsCzrt3rb9XuPS5hUkzfHRd9DTFwzidggYRLKSJiEMhImoYyESSgjYRLKSJiEOge+vfmdfKJXPtEbSdQ3LYWIRLY5oYyESSgjYRLKSJiEMv8B85NY3z0YmFEAAAAASUVORK5CYII=\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5826b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14561ffd0c63409ce6a92e30d5262f4f",
     "grade": false,
     "grade_id": "cell-331862dc16995399",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<i>Please use comments where appropriate to help tutors understand your code.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fc689",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cff928d150797d7f1a2c816a9a7d5e83",
     "grade": false,
     "grade_id": "cell-9ecfdee985d13818",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3>Task 1 - 4 points</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0637eb41",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "896bcb0d45998010d487465a8900022e",
     "grade": false,
     "grade_id": "cell-b6d6c17398732c61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Load the given files and:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a01e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>VB</th>\n",
       "      <th>TO</th>\n",
       "      <th>NN</th>\n",
       "      <th>PPSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.00430</td>\n",
       "      <td>0.04100</td>\n",
       "      <td>0.06700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VB</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.03500</td>\n",
       "      <td>0.04700</td>\n",
       "      <td>0.00700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TO</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.01600</td>\n",
       "      <td>0.08700</td>\n",
       "      <td>0.00450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPSS</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>0.00014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tags      VB       TO       NN     PPSS\n",
       "0   <s>  0.0190  0.00430  0.04100  0.06700\n",
       "1    VB  0.0038  0.03500  0.04700  0.00700\n",
       "2    TO  0.8300  0.00000  0.00047  0.00000\n",
       "3    NN  0.0040  0.01600  0.08700  0.00450\n",
       "4  PPSS  0.2300  0.00079  0.00120  0.00014"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV files\n",
    "observation_likelihood = pd.read_csv('observation_likelihoods.csv')\n",
    "transition_probability = pd.read_csv('transisition_probabilities.csv')\n",
    "\n",
    "# Assign labels for better readability\n",
    "observation_likelihood.columns = ['Tags', ' I', ' want', ' to ', ' race']\n",
    "transition_probability.columns = ['Tags', 'VB', 'TO', 'NN', 'PPSS']\n",
    "\n",
    "transition_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e6efa7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b989ae10a2f596db502e86d0574ca1bd",
     "grade": false,
     "grade_id": "cell-a776818a8c2a1f53",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "a) Write a function to obtain a list of all possible tag sequences for the word sequence given above and store them in a list. Print the first 5 tag sequences as well as the total number of sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b4722cc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a758f57255b28e0ef302d7c191078969",
     "grade": false,
     "grade_id": "cell-d6eb1200d25ca492",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('VB', 'VB', 'VB', 'VB'), ('VB', 'VB', 'VB', 'TO'), ('VB', 'VB', 'VB', 'NN'), ('VB', 'VB', 'VB', 'PPSS'), ('VB', 'VB', 'TO', 'TO'), ('VB', 'VB', 'TO', 'NN'), ('VB', 'VB', 'TO', 'PPSS'), ('VB', 'VB', 'NN', 'NN'), ('VB', 'VB', 'NN', 'PPSS'), ('VB', 'VB', 'PPSS', 'PPSS'), ('VB', 'TO', 'TO', 'TO'), ('VB', 'TO', 'TO', 'NN'), ('VB', 'TO', 'TO', 'PPSS'), ('VB', 'TO', 'NN', 'NN'), ('VB', 'TO', 'NN', 'PPSS'), ('VB', 'TO', 'PPSS', 'PPSS'), ('VB', 'NN', 'NN', 'NN'), ('VB', 'NN', 'NN', 'PPSS'), ('VB', 'NN', 'PPSS', 'PPSS'), ('VB', 'PPSS', 'PPSS', 'PPSS'), ('TO', 'TO', 'TO', 'TO'), ('TO', 'TO', 'TO', 'NN'), ('TO', 'TO', 'TO', 'PPSS'), ('TO', 'TO', 'NN', 'NN'), ('TO', 'TO', 'NN', 'PPSS'), ('TO', 'TO', 'PPSS', 'PPSS'), ('TO', 'NN', 'NN', 'NN'), ('TO', 'NN', 'NN', 'PPSS'), ('TO', 'NN', 'PPSS', 'PPSS'), ('TO', 'PPSS', 'PPSS', 'PPSS'), ('NN', 'NN', 'NN', 'NN'), ('NN', 'NN', 'NN', 'PPSS'), ('NN', 'NN', 'PPSS', 'PPSS'), ('NN', 'PPSS', 'PPSS', 'PPSS'), ('PPSS', 'PPSS', 'PPSS', 'PPSS')]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "import itertools\n",
    "\n",
    "def calculate_tag_permutations(observations: pd.DataFrame) -> List[Tuple[str, ...]]:\n",
    "    \"\"\"\n",
    "    Calculates an array-like object of all possible tag permutations for the token sequence\n",
    "    \n",
    "    Input:\n",
    "      observations: pandas DataFrame object of tokens and tag probabilities\n",
    "   \n",
    "    Output:    \n",
    "      A list of all tag permutations, each permutation is contained in a tuple\n",
    "    \"\"\"\n",
    "    perm = []\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "  \n",
    "    perm = list(itertools.combinations_with_replacement(observations[\"Tags\"], len(observations[\"Tags\"])))\n",
    "\n",
    "\n",
    "    return perm\n",
    "\n",
    "sequences = calculate_tag_permutations(observation_likelihood)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fe8f295",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6775fa80670fa14b6bde6fea41c6667",
     "grade": true,
     "grade_id": "cell-f7f8d5fb46a84e2f",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "assert sequences[0] == ('VB', 'VB', 'VB', 'VB')\n",
    "assert sequences[3] == ('VB', 'VB', 'VB', 'PPSS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c76344c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4184d6f40eb88f0f02ba787a9c12ffda",
     "grade": true,
     "grade_id": "cell-7f6377e3d559e1e3",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "import random\n",
    "idx = random.randint(0, len(sequences)-1)\n",
    "while True:\n",
    "  idx2 = random.randint(0, len(sequences)-1)\n",
    "  if idx2 != idx:\n",
    "    break\n",
    "assert sequences[idx] != sequences[idx2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57ff906d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd0881e41babf283c40df09e1cbd3d02",
     "grade": true,
     "grade_id": "cell-6bcddcb4dcf71a1c",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "idx = random.randint(0, len(sequences)-1)\n",
    "assert len(sequences[idx]) == 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc2a4b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f339875db445a92be07efed0643bb351",
     "grade": true,
     "grade_id": "cell-1830c7ae39d7fc29",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "allowed_tags = ['VB', 'TO', 'NN', 'PPSS']\n",
    "idx = random.randint(0, len(sequences)-1)\n",
    "for tag in list(sequences[idx]):\n",
    "  assert tag in allowed_tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bd7537",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "147202a03f54e339e01a41d9037c2904",
     "grade": false,
     "grade_id": "cell-ef23e7dffc2c1391",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "b) Implement the Hidden Markov Model (HMM) discussed in the lecture and use it to assign a probability to each possible sequence. Print the most likely tag sequence and its probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad90fc69",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdcd767c0f97ebe387db0e9f2522889d",
     "grade": false,
     "grade_id": "cell-8e8f92fdb03e74ce",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def calculate_sequence_probability(sequence: List[str], \n",
    "                                   observations: pd.DataFrame, transitions: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Calculates a probability for a token sequence using the Hidden Markov Model\n",
    "    \n",
    "    Input:\n",
    "      sequences: List of POS tag sequences\n",
    "      observations: pandas DataFrame object of observation probabilities\n",
    "      transitions: pandas DataFrame object of transition probabilities\n",
    "    \n",
    "    Output:\n",
    "      Probability of the POS sequence\n",
    "    \"\"\"\n",
    "    sequence_probability = 1\n",
    "\n",
    "    #YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return sequence_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523f96f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5cc9562618b856119aeab6de18d1b88",
     "grade": true,
     "grade_id": "cell-e7d2fc18c75788fc",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7947ff",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa64c2ad0c5bda048c84461107d62f53",
     "grade": false,
     "grade_id": "cell-f05bfb6d26ee3839",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def score_tag_sequences(sequences: List[List[str]], \n",
    "                        observations: pd.DataFrame, \n",
    "                        transitions: pd.DataFrame) -> List[Tuple[Tuple[str, ...], float]]:\n",
    "    \"\"\"\n",
    "    Calculate the sequences probability for every entry in an array-like object of POS sequences\n",
    "    \n",
    "    Input:\n",
    "      sequences: List of POS tag sequences\n",
    "      observations: pandas DataFrame object of observation probabilities\n",
    "      transitions: pandas DataFrame object of transition probabilities\n",
    "    \n",
    "    Output:\n",
    "      A list that contains a POS sequence and a probability for every entry\n",
    "    \"\"\"\n",
    "    tag_scores = []\n",
    "    for sequence in sequences:\n",
    "        tag_scores.append(calculate_sequence_probability(sequence, observations, transitions))\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad6da7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d73f1134b8c253067c7bb8e9d6247e43",
     "grade": true,
     "grade_id": "cell-aef4eed19c7e8d0f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f184a4c6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88ab159e5f4df18fc14974d628f1d104",
     "grade": false,
     "grade_id": "cell-c2101a1a33f14375",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score_tag_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Bella\\Documents\\NLP4Web\\Homework 2\\homework_2.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bella/Documents/NLP4Web/Homework%202/homework_2.ipynb#X43sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bella/Documents/NLP4Web/Homework%202/homework_2.ipynb#X43sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m best_comb\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Bella/Documents/NLP4Web/Homework%202/homework_2.ipynb#X43sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m scored_sequences \u001b[39m=\u001b[39m score_tag_sequences(sequences, observation_likelihood, transition_probability)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bella/Documents/NLP4Web/Homework%202/homework_2.ipynb#X43sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m best_combination \u001b[39m=\u001b[39m find_sequence_with_highest_probability(scored_sequences)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'score_tag_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "def find_sequence_with_highest_probability(\n",
    "    scored_sequences: List[Tuple[Tuple[str, ...], float]]) -> Tuple[Tuple[str, ...], float]:\n",
    "    \"\"\"\n",
    "    Returns the POS tag sequence and probability with the highest probability from an array-like object that contains a POS sequence and a probability for every entry\n",
    "    \n",
    "    Input:\n",
    "      scored_sequences: A list that contains a POS sequence and a probability for every entry\n",
    "    \n",
    "    Output:\n",
    "      Tuple of sequence and probability \n",
    "    \"\"\"\n",
    "    best_comb = ()\n",
    "    best_score = 0\n",
    "    # YOUR CODE HERE\n",
    "    for sequence in scored_sequences:\n",
    "        new_score = sequence[1]\n",
    "        if new_score > best_score:\n",
    "            best_score = new_score\n",
    "            best_comb = sequence\n",
    "            \n",
    "\n",
    "    #raise NotImplementedError()\n",
    "    return best_comb\n",
    "\n",
    "scored_sequences = score_tag_sequences(sequences, observation_likelihood, transition_probability)\n",
    "best_combination = find_sequence_with_highest_probability(scored_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2c0832",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b54f3303701171c06c7ac50a85ce5121",
     "grade": true,
     "grade_id": "cell-93d34dccfabcface",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "assert best_combination[0] == ('PPSS', 'VB', 'TO', 'VB')\n",
    "assert np.isclose([best_combination[1]], [1.829995e-10])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35f874b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24fd3c69012f56586835a2eb4b515426",
     "grade": false,
     "grade_id": "cell-55b5f766f265a195",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "c) Why would the naive solution of scoring each tag sequence not scale up to real world problems ? How does the Viterbi algorithm relate to that ? Discuss in up to 3 sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b3d3df",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1b8f234f11dca7f6f56e9ce32b4753a",
     "grade": true,
     "grade_id": "cell-f09d4f7efaaad4e8",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f801d9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c8a64a0320baf0da3b52d4d757d750db",
     "grade": false,
     "grade_id": "cell-715f2775d40c42dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3>Task 2 - 6 points</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf92ab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c3eea44dda583b9f09b276c6d3d3635",
     "grade": false,
     "grade_id": "cell-311477de7f90560d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement the Viterbi algorithm as shown in slide 92ff. of our lecture slides `Text Classification 2` and apply it to the data from Task 1.1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b502f055",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a16682c781cc47f9b5cb7401ac448697",
     "grade": false,
     "grade_id": "cell-76fa9c25ec71e2fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "a) Compute the initialization step of Viterbi given transition and observation probability and print the probability matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ec919",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62389d19f9e468b815b7e9074b278d40",
     "grade": false,
     "grade_id": "cell-b7355655cb27cbb6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def viterbi_init(observation_likelihood:pd.DataFrame, transition_probability:pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Initialize the viterbi matrix\n",
    "    \n",
    "    Input:\n",
    "      observation_likelihood: pandas DataFrame object - observation probabilities\n",
    "      transition_probability: pandas DataFrame object - transition probabilities\n",
    "    \n",
    "    Output:\n",
    "      numpy ndarray object - the initialized viterbi matrix\n",
    "    \"\"\"\n",
    "    viterbi = np.zeros((1, 1)) # not the right shape\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return viterbi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c6a80a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1ff9a8e5470304711985991ca0fc74d",
     "grade": true,
     "grade_id": "cell-c072ed9591479aa1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "expected_init = np.array( [[0.     , 0.     , 0.     , 0.     ],\n",
    "                           [0.     , 0.     , 0.     , 0.     ],\n",
    "                           [0.     , 0.     , 0.     , 0.     ],\n",
    "                           [0.02479, 0.     , 0.     , 0.     ]])\n",
    "viterbi = viterbi_init(observation_likelihood, transition_probability)\n",
    "assert viterbi.shape == (4,4)\n",
    "assert (viterbi == expected_init).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6319b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb90e60c5968d10b70f2a487a3a662b3",
     "grade": false,
     "grade_id": "cell-0de4084ffd213a9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "b) Compute the recursion step of Viterbi given transition and observation probability and print the probability matrix again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9025823",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4558fc982a7083d3f229c3e2d8ffa930",
     "grade": false,
     "grade_id": "cell-c16647b9922f2ee0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def viterbi_recursion(observation_likelihood:pd.DataFrame, \n",
    "                      transition_probability:pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, int]:\n",
    "    \"\"\"\n",
    "    Compute the recursion steps of viterbi algorithm\n",
    "    \n",
    "    Input:\n",
    "      observation_likelihood: pandas DataFrame object of observation probabilities\n",
    "      transition_probability: pandas DataFrame object of transition probabilities\n",
    "    \n",
    "    Output:\n",
    "      1: numpy ndarray object - the viterbi matrix\n",
    "      2: numpy ndarray object - the backpointer matrix which contains the previous state\n",
    "      3: integer - the index of the most likely starting state\n",
    "    \"\"\"\n",
    "    viterbi = np.zeros((1, 1)) # not the right shape\n",
    "    backpointer = np.zeros((1, 1)) # not the right shape\n",
    "    max_idx = 0\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return viterbi, backpointer, max_idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a3256f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f13099c3513622acde997b13225af005",
     "grade": true,
     "grade_id": "cell-41d18ec9966b23ef",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "expected_v = np.array([[0.00000000e+00, 5.30258100e-05, 0.00000000e+00, 1.82999494e-10],\n",
    "                       [0.00000000e+00, 0.00000000e+00, 1.83734432e-06, 0.00000000e+00],\n",
    "                       [0.00000000e+00, 1.60639200e-09, 0.00000000e+00, 4.92224542e-13],\n",
    "                       [2.47900000e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])\n",
    "\n",
    "expected_b = np.array([[0., 3., 0., 1.],\n",
    "                       [0., 0., 0., 0.],\n",
    "                       [0., 3., 0., 1.],\n",
    "                       [0., 0., 0., 0.]])\n",
    "\n",
    "v,b,m = viterbi_recursion(observation_likelihood, transition_probability)\n",
    "\n",
    "assert np.isclose(v, expected_v).all()\n",
    "assert (b==expected_b).all()\n",
    "assert m==0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e4f10f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c78f789790605613e432bb2acb12598",
     "grade": false,
     "grade_id": "cell-db5daa324d2031bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "c) Compute the termination step of Viterbi given transition and observation probability and print the most likely tag sequence and its probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af6a17f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de4cd63b234533bfa77fb984efe2382d",
     "grade": false,
     "grade_id": "cell-47003870bf6c4b55",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def viterbi_final(observation_likelihood:pd.DataFrame, transition_probability:pd.DataFrame) -> Tuple[List[str], float]:\n",
    "    \"\"\"\n",
    "    Find the most likely POS combination with the help of viterbi algorithm\n",
    "    \n",
    "    Input:\n",
    "      observation_likelihood: pandas DataFrame object of observation probabilities\n",
    "      transition_probability: pandas DataFrame object of transition probabilities\n",
    "    \n",
    "    Input:\n",
    "      1: list of string - the most probable POS combination\n",
    "      2: float - the probability of that combination\n",
    "    \"\"\"\n",
    "    tag_sequence = []\n",
    "    p_best_path = 0\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return tag_sequence, p_best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eb1b75",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6107edfd5e457c5ec626fba872e4979a",
     "grade": true,
     "grade_id": "cell-4a3271d2dc21b460",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "tag_sequence, p = viterbi_final(observation_likelihood, transition_probability)\n",
    "assert tag_sequence == ['PPSS', 'VB', 'TO', 'VB']\n",
    "assert np.isclose([p], [1.8299949392340004e-10])[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac0a639",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ed0274cb14df45b91e1d3df47b1e1f6",
     "grade": false,
     "grade_id": "cell-2d73606258e34e05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h2>Part 2: Vectorizing and ML with scikit-learn (10 Points) </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302ee448",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ac88f10bdc4933b8ad23e3b26d671af",
     "grade": false,
     "grade_id": "cell-f07bb0b745f28ede",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Text classification is the task of categorizing text data into a set of predefined labels. The most important part of text classification is feature engineering: the process of extracting features from raw text data for machine learning models. We discussed previously what is a bag of words (bow) and why it is important to use it. In today’s class, we have seen how to transform a raw text into a set of features that can be represented as a matrix or a vector. In this exercise, we will practice feature engineering for text classification with <a href=\"https://scikit-learn.org/stable/\">scikit-learn</a>. The goal of this exercise is to explore different features and their representations, to train and to evaluate different classifiers to automatically identify the sentiment polarity of the movie reviews.<br><br>\n",
    "<b>Data:</b> The dataset provided for this exercise contains 5k movie reviews with positive and negative labels, which were taken from the IMDB Dataset. It's saved in the file *IMDB_reviews.csv*, which has two columns separated by `,`. The first column contains reviews and the second column contains their sentiment labels (0=negative, 1=positive). <br><br>\n",
    "<b>Note:</b> For this exercise, you may **only use** spaCy, scikit-learn, NumPy, Pandas and internal packages from Python. Please follow the instructions as given below and in case of questions use our Discussion forum in Moodle.<br><br>\n",
    "Please use comments where appropriate to help tutors understand your code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa989f7f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1ae4e8ba8a80e6ff0527fcffd84d62a",
     "grade": false,
     "grade_id": "cell-3d42d2e0d8461588",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3> Task 3 - 5 Points </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b04ca0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91d204353c5b98c29d4c8cc3734f2e75",
     "grade": false,
     "grade_id": "cell-f7a3d7a7766b3d9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**a)** Read the data from *IMDB_reviews.csv*. Shuffle and split it into training (60%), development (20%) and test (20%) sets. Print the size of the training, development and test set. **(1.5p)**\n",
    "\n",
    "*Hint: Like in the class exercise, you can use train_test_split from scikit-learn for this.*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f81945c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c37fe5c8bc885ec7094787f154c29410",
     "grade": false,
     "grade_id": "cell-c3b5f57b7fe79e71",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(data:pd.DataFrame, seed:int=42) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split the data into train/dev/set with the said percentage. You can use the default seed but can \n",
    "    also try other seed if you want. Try to get the model's accuracy to the recommended accuracy that \n",
    "    is used in the tests.\n",
    "    \n",
    "    Input:\n",
    "      data: pandas DataFrame object - the loaded data\n",
    "      seed: int - the pseudo-random seed \n",
    "    \n",
    "    Output:\n",
    "      1: pandas DataFrame object - train data\n",
    "      2: pandas DataFrame object - development data\n",
    "      3: pandas DataFrame object - test data\n",
    "    \"\"\"\n",
    "    df_train, df_test, df_dev = None, None, None\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    \n",
    "    split_train = int(len(data) * 0.6)\n",
    "    split_test = int(len(data) * 0.8)\n",
    "\n",
    "    data.sample()\n",
    "    df_train = data.iloc[:split_train]\n",
    "    df_test = data.iloc[split_train:split_test]\n",
    "    df_dev = data.iloc[split_test:]\n",
    "    \n",
    "    return df_train, df_dev, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58bd7cd9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32dec9bf837937ab6c806c3ade528803",
     "grade": true,
     "grade_id": "cell-c02e040cc9120819",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "data = pd.read_csv(\"IMDB_reviews.csv\")\n",
    "df_train, df_dev, df_test = split_data(data)\n",
    "assert len(df_train) == 3000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d377d46",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e021432de8181aed6b766e5adf40ccd1",
     "grade": false,
     "grade_id": "cell-fa0e5d47292c496d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**b)** Implement the function `train_valid_cls()`. The function should take the training and development set as well as a vectorizer and a classifier as input parameters (as shown below). The function should then train and validate the given classifier using the data and the vectorizer and print the accuracy on the development dataset. Also return the classifier and the accuracy.\n",
    "<br>\n",
    "Use `train_valid_cls()` together with the `CountVectorizer()` and the `MultinomialNB()` provided by scikit-learn, to train and to evaluate two multinomial Naive Bayes classifiers with the training and development datasets. One classifier uses the count matrix (absolute occurrence of each word) and the other one uses the binary count matrix (binary, whether a word occurs in a text) as features. Print the accuracy of each classifier. Also return the classifier and the accuracy. **(2.5p)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397f1c48",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a1c08be1b552d8126ac3d3f1739d7cf",
     "grade": false,
     "grade_id": "cell-fb8e1f5206077b6d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "  \n",
    "\n",
    "def train_valid_cls(train_texts: pd.Series, train_labels: pd.Series, dev_texts: pd.Series, dev_labels: pd.Series, \n",
    "                    vectorizer: CountVectorizer, classifier: MultinomialNB) -> Tuple[MultinomialNB, float]:\n",
    "    \"\"\"\n",
    "    Train and validate the classifier with the given data and vectorizer, PRINT the accuracy of \n",
    "    the trained classifier on the development set.\n",
    "    \n",
    "    Input:\n",
    "      train_texts: array-like object containing review texts from the training set\n",
    "      train_labels: array-like object with corresponding sentiment labels for train_texts\n",
    "      dev_texts: array-like object containing review texts from the development set\n",
    "      dev_labels: array-like object with corresponding sentiment labels for dev_texts\n",
    "      vectorizer: a customized scikit-learn Vectorizer \n",
    "      classifier: a scikit-learn Classifier\n",
    "    \n",
    "    Output:\n",
    "      A classifier and the accuracy on dev set \n",
    "    \"\"\"\n",
    "    dev_acc = 0\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return classifier, dev_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000240d8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6a767a7a28179ea9a2595393d4e8181",
     "grade": false,
     "grade_id": "cell-8af36e2dac608cc1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# naive bayes classifier with count matrix\n",
    "\n",
    "def count_matrix_NBC() -> Tuple[MultinomialNB, float]:\n",
    "    \"\"\"\n",
    "    Initialize and train the naive bayes classifier with count matrix\n",
    "    \n",
    "    Output:\n",
    "      A classifier and the accuracy on dev set \n",
    "    \"\"\"\n",
    "    cls = None\n",
    "    acc = 0\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return cls, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857af13c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1246cbb5f96c2cffa374a38320f2c58",
     "grade": true,
     "grade_id": "cell-eaca4430af2eea7d",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "cls, acc = count_matrix_NBC()\n",
    "assert acc > 0\n",
    "assert cls is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9283d5f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87e224d5e6c00a05f93d4a15a7baf188",
     "grade": true,
     "grade_id": "cell-06a61e382975b6fc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "cls, acc = count_matrix_NBC()\n",
    "assert acc >= 0.7\n",
    "assert isinstance(cls, MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f05f418",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "568147c27783c10bb8d0ac8479dcce7a",
     "grade": false,
     "grade_id": "cell-e067bb76e5b86eae",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# naive bayes classifier with binary count matrix\n",
    "\n",
    "def binary_count_matrix_NBC() -> Tuple[MultinomialNB, float]:\n",
    "    \"\"\"\n",
    "    Initialize and train the naive bayes classifier with binary count matrix\n",
    "    \n",
    "    Output:\n",
    "      A classifier and the accuracy on dev set \n",
    "    \"\"\"\n",
    "    cls = None\n",
    "    acc = 0\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return cls, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fbbb44",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a98753fafc8c43cac90e57fb6090df2a",
     "grade": true,
     "grade_id": "cell-4309ca552732cdda",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "cls, acc = binary_count_matrix_NBC()\n",
    "assert acc > 0\n",
    "assert cls is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941140fc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a729f55ab74d5500b3031b0aa8c694db",
     "grade": true,
     "grade_id": "cell-eb93fa4311ebcc8b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "cls, acc = binary_count_matrix_NBC()\n",
    "assert acc >= 0.7\n",
    "assert isinstance(cls, MultinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae000f1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "298ea90029437515f3e36878a1621225",
     "grade": false,
     "grade_id": "cell-fd17cdf895d537ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**c)** Using the function `train_valid_cls()` from b), explore at least 3 different ranges of n-grams (introduce bigram, trigram ... features) and try to find the best one for training the multinomial Naive Bayes classifier with count matrix or binary count matrix. Report the accuracy on the development set for every range you tried and also return the classifier and the accuracy. **(1p)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b4a06",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36c46554b263498c055627652ad2f86a",
     "grade": false,
     "grade_id": "cell-9ec469dfada5871e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ngram_classifier(n: int, df_train: pd.DataFrame, df_dev: pd.DataFrame) -> Tuple[MultinomialNB, float]:\n",
    "    \"\"\"\n",
    "    Initialize and train the naive bayes classifier with n-grams\n",
    "    \n",
    "    Output:\n",
    "      A classifier and the accuracy on dev set \n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"ngram_range=(1, {n})\")\n",
    "    cls = None\n",
    "    acc = 0\n",
    "    train_data = df_train['text']\n",
    "    train_label = df_train['label']\n",
    "    dev_data = df_dev['text']\n",
    "    dev_label = df_dev['label']\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return cls, acc\n",
    "\n",
    "n_grams_list = [] # Put your 3 n-grams in here\n",
    "models_list = [ngram_classifier(n, df_train, df_dev) for n in n_grams_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a4b608",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9efa3fc36bee71ed78a4057a72fd4eac",
     "grade": true,
     "grade_id": "cell-44d4e33bc8fd7b10",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "cls, acc = ngram_classifier(3, df_train, df_dev)\n",
    "assert acc >= 0.7\n",
    "assert isinstance(cls, MultinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f00f3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4d9bcd7865172bb6e9398185342360e",
     "grade": false,
     "grade_id": "cell-5b9f23b5716a529a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3> Task 4 - 5 Points </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d09c71",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7932d18b1030d83b967943c200a896b2",
     "grade": false,
     "grade_id": "cell-7feb5d179fa7aa54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**a)** Use spaCy's medium language model to tokenize every review text in the training and development sets (It may take a few minutes). You should store the tokens as spaCy token objects (instead of strings) for the subsequent tasks **(0.5p)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ab87b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99c02d3f85215bc8e06563c715fafebb",
     "grade": false,
     "grade_id": "cell-dacc4fef70c52ee9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "# In case you have not downloaded it yet you can use the following line\n",
    "# spacy.cli.download(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea0842",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c95cdb3d88c2b297216d704dfb69c2e",
     "grade": false,
     "grade_id": "cell-c47d6d2e06ef03ca",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from spacy.tokens.token import Token\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "def tokenize(text:str) -> List[Token]:\n",
    "    \"\"\"\n",
    "    tokenize the sentence with spacy\n",
    "    \n",
    "    Input:\n",
    "      text: str - the sentence\n",
    "    \n",
    "    Output:\n",
    "      A list of tokens from the tokenized sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = []\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return tokens\n",
    "\n",
    "df_train['tokenized'] = df_train['text'].apply(tokenize)\n",
    "df_dev['tokenized'] = df_dev['text'].apply(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d91234",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0430a0ef5e24c353a537ee3cf1ddb220",
     "grade": true,
     "grade_id": "cell-e889173616e71b12",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "assert isinstance(df_train['tokenized'].iloc[0][0], Token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754903ad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53ee01d7a3790123f703092d67cca706",
     "grade": false,
     "grade_id": "cell-68ab214a0453b7aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**b)** For each review text, calculate the average of all word vectors as its vector representation. Then train a gaussian Naive Bayes classifier (`sklearn.naive_bayes.GaussianNB`) with the obtained vector representations, evaluate and print its accuracy on the development set. Also return the classifier and the accuracy. **(1.5p)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9b382",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4422faf975ac1ff01c52bf08d89e5e4",
     "grade": false,
     "grade_id": "cell-f59b7231ec2434eb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Feature extraction\n",
    "\n",
    "def feature_extract(tokenized_text: list[Token, ...]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the average vector of all token. Hint: you can use token.vector to get the vector\n",
    "    of the given token.\n",
    "    \n",
    "    Output:\n",
    "      numpy ndarray object - the computed mean vector\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce156b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ce98e4b5af309a34d315bda8d241848",
     "grade": true,
     "grade_id": "cell-119b4a41c2e6c785",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "assert len(feature_extract(df_train['tokenized'].iloc[0]))==300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2d59a4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f90a4fe5c825e923a6b67ced07dd56b8",
     "grade": false,
     "grade_id": "cell-d4f5d24b0bf7c5a1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_data(df_train: pd.DataFrame, df_dev: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute the features of the train/dev dataset using feature_extract function\n",
    "    \n",
    "    Input:\n",
    "      df_train: pandas DataFrame object - train data\n",
    "      df_dev: pandas DataFrame object - development data\n",
    "    \n",
    "    Output:\n",
    "      numpy ndarray - features of train dataset and dev dataset \n",
    "    \"\"\"\n",
    "    train_X = []\n",
    "    dev_X = []\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return np.array(train_X), np.array(dev_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf45ae5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c81ce81e2dbebc18a4640b3e9a0290b5",
     "grade": true,
     "grade_id": "cell-1530829ab3bfb7a0",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "train, dev = get_data(df_train, df_dev)\n",
    "assert train.shape == (3000, 300)\n",
    "assert dev.shape == (1000, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9161b9c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "490e2488a02a997a06ce03c4434604a9",
     "grade": false,
     "grade_id": "cell-33272373ca291cf3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def GNB_classifier(train_X: np.ndarray, dev_X: np.ndarray) -> Tuple[GaussianNB, float]:\n",
    "    \"\"\"\n",
    "    Initialize and train the gaussian naive bayes classifier with the calculated features\n",
    "    \n",
    "    Input:\n",
    "      train_X: numpy ndarray object - train data\n",
    "      dev_X: numpy ndarray object - development data\n",
    "    \n",
    "    Output:\n",
    "      A classifier and the accuracy on dev set \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18d0eda",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4cc4e073b612a49d5eea374c653164d",
     "grade": true,
     "grade_id": "cell-d4fb1cdc2e2e2316",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "cls, acc = GNB_classifier(train, dev)\n",
    "assert isinstance(cls, GaussianNB)\n",
    "assert acc > 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd6ec63",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96318c1fee2469811372285e230b6d27",
     "grade": false,
     "grade_id": "cell-4bd3ac5a47ca032d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**c)** Now, filter out all tokens except verbs, adjectives and adverbs from the tokenized review texts from a). You should store the remaining tokens as spaCy token objects (instead of strings). These remaining tokens should be verbs, adjectives and adverbs. \n",
    "Extract the spaCy word vectors of the remaining tokens and create a vector representation of each review text like you did in b). Then you should again train and evaluate a GaussianNB classifier and print its accuracy on the development set. Also return the classifier and the accuracy. **(2p)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a51d26",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "975da53369c02d02d46681c5b8fbc89e",
     "grade": false,
     "grade_id": "cell-19e168a578ae653f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Filter tokens\n",
    "\n",
    "def filter_tokens(tokenized_text: List[Token]) -> List[Token]:\n",
    "    \"\"\"\n",
    "    Filter tokens that are not verbs, adjectives ore adverbs\n",
    "    \n",
    "    Input:\n",
    "      tokenized_text: list of token object\n",
    "    \n",
    "    Output:\n",
    "      List of filtered token object \n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56be797",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d77666846bf8448dc09c899d257caf8",
     "grade": true,
     "grade_id": "cell-cff307de4c6d3593",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "for t in filter_tokens(df_train['tokenized'].iloc[0]):\n",
    "    assert t.pos_ in ['ADJ', 'ADV', 'VERB']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d281717",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0fb577fbf24601a0df3c9871ac69b0b4",
     "grade": false,
     "grade_id": "cell-2c17f8956cdf6a9d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create new word vectors\n",
    "def get_filtered_data(df_train: pd.DataFrame, df_dev: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute the features of the filtered train/dev dataset using feature_extract function\n",
    "    \n",
    "    Input:\n",
    "      df_train: pandas DataFrame object - filtered train data\n",
    "      df_dev: pandas DataFrame object - filtered development data\n",
    "    \n",
    "    Input:\n",
    "      numpy ndarray - features of train dataset and dev dataset \n",
    "    \"\"\"\n",
    "    train_X = []\n",
    "    dev_X = []\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return np.array(train_X), np.array(dev_X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef03b5d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb83dc66f70b7b65e6111cab3360b105",
     "grade": true,
     "grade_id": "cell-e66b8fcd2afdccda",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "f_train, f_dev = get_filtered_data(df_train, df_dev)\n",
    "assert f_train.shape == (3000, 300)\n",
    "assert f_dev.shape == (1000, 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55354630",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47746af31358fa1792dbe246a63c13ff",
     "grade": false,
     "grade_id": "cell-8567da4856e95208",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes classifier\n",
    "\n",
    "def GNB_classifier_filter(train_X: np.ndarray, dev_X: np.ndarray) -> Tuple[GaussianNB, float]:\n",
    "    \"\"\"\n",
    "    Initialize and train the gaussian naive bayes classifier with the calculated features\n",
    "    \n",
    "    Input:\n",
    "      train_X: numpy ndarray object - train data\n",
    "      dev_X: numpy ndarray object - development data\n",
    "      \n",
    "    Output:\n",
    "      A classifier and the accuracy on dev set \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155f53d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fa270157051d96881ff7e6c00c20dfb",
     "grade": true,
     "grade_id": "cell-ab624e9c3966807b",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "cls, acc = GNB_classifier_filter(f_train, f_dev)\n",
    "assert isinstance(cls, GaussianNB)\n",
    "assert acc > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94c3430",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb389fe11557376730d2e447b045f7b9",
     "grade": false,
     "grade_id": "cell-0c488cd699f87030",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**d)** Choose your best model from Task 3 or Task 4 and test it on the test set, print the accuracy. Why is it important to evaluate your final model on a previously unused test set? Explain it in up to 2 sentences. <br><br>\n",
    "<b>Note:</b> You should only test one model here, i.e. the best model from all models you trained in 3 and 4. If two models performed equally well choose one of them. **(1p)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73652d19",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d981d28112691f78b70b886dd2029d24",
     "grade": true,
     "grade_id": "cell-ca5ab3cbbaa74f8c",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Use your best model and print its performance on the test set here\n",
    "\n",
    "def print_best_model() -> None:\n",
    "    \"\"\"\n",
    "    You don't need to use any parameter here. Just do whatever you like to print \n",
    "    the accuracy of your best model however you like.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82225c6d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "971926c5600f0f556386f727de9bf340",
     "grade": true,
     "grade_id": "cell-d90dcb701a406695",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf937d9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c18df33621f47b9840812888000e73cf",
     "grade": false,
     "grade_id": "cell-492dbd3baca1c236",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Submission:**\n",
    "\n",
    "Please upload your submission to Moodle before the next exercise session <font color=\"red\">(Nov 29th, 23:59)</font>!\n",
    "\n",
    "Submission format: `Group_XX_Exercise_XX.zip`\n",
    "\n",
    "Your submission should contain your filled out Jupyter notebook (naming schema: `Group_XX_Exercise_XX.ipynb`) and any auxiliar files that are necessary to run your code (e.g., the datasets provided by us).\n",
    "\n",
    "Each submission must be handed in only once per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d02005-56cb-41d2-9c8c-258b2aabe7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp4web",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
